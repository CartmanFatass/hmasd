#!/usr/bin/env python3
"""
HMASDä¸¥æ ¼æŒ‰è®ºæ–‡Algorithm 1 + Appendix Eçš„å¤šçº¿ç¨‹Rollout-basedè®­ç»ƒè„šæœ¬
å®ç°è¦ç‚¹ï¼š
1. 32ä¸ªrollout threads: æŒç»­ç¯å¢ƒäº¤äº’å’Œæ•°æ®æ”¶é›†
2. 16ä¸ªtraining threads: æŒç»­ç¥ç»ç½‘ç»œè®­ç»ƒ
3. çº¿ç¨‹å®‰å…¨çš„æ•°æ®ä¼ è¾“: ä½¿ç”¨é˜Ÿåˆ—åœ¨rolloutå’Œtrainingçº¿ç¨‹é—´ä¼ è¾“æ•°æ®
4. å¼‚æ­¥è®­ç»ƒ: æ•°æ®æ”¶é›†å’Œæ¨¡å‹è®­ç»ƒå¹¶è¡Œæ‰§è¡Œ
5. ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡: 15è½®PPO + åˆ¤åˆ«å™¨è®­ç»ƒ + ç¼“å†²åŒºç®¡ç†
"""

import os
import sys
import time
import numpy as np
import torch
import argparse
import threading
import queue
import multiprocessing as mp
from datetime import datetime
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock, Event, Barrier
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# è®¾ç½®matplotlibåç«¯ï¼ˆé¿å…å¤šè¿›ç¨‹é—®é¢˜ï¼‰
import matplotlib
matplotlib.use('Agg')

from logger import get_logger, init_multiproc_logging, LOG_LEVELS, shutdown_logging
from config import Config
from hmasd.thread_safe_hmasd_agent import ThreadSafeHMASDAgent
from envs.pettingzoo.scenario1 import UAVBaseStationEnv
from envs.pettingzoo.scenario2 import UAVCooperativeNetworkEnv
from envs.pettingzoo.env_adapter import ParallelToArrayAdapter

# å¯¼å…¥ Stable Baselines3 çš„å‘é‡åŒ–ç¯å¢ƒ
from stable_baselines3.common.vec_env import SubprocVecEnv

class ThreadSafeCounter:
    """çº¿ç¨‹å®‰å…¨çš„è®¡æ•°å™¨"""
    def __init__(self, initial_value=0):
        self._value = initial_value
        self._lock = Lock()
    
    def increment(self, amount=1):
        with self._lock:
            self._value += amount
            return self._value
    
    def get(self):
        with self._lock:
            return self._value
    
    def set(self, value):
        with self._lock:
            self._value = value

class DataBuffer:
    """ã€é˜¶æ®µ2å¢å¼ºã€‘çº¿ç¨‹å®‰å…¨çš„æ•°æ®ç¼“å†²åŒº - æ”¯æŒä¼˜å…ˆçº§å¤„ç†å’ŒçŠ¶æ€ç›‘æ§"""
    def __init__(self, maxsize=10000):
        # ã€é˜¶æ®µ2æ–°å¢ã€‘ä½¿ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—ä»£æ›¿æ™®é€šé˜Ÿåˆ—
        self.high_priority_queue = queue.Queue(maxsize=maxsize//4)  # é«˜å±‚ç»éªŒä¼˜å…ˆé˜Ÿåˆ—
        self.normal_priority_queue = queue.Queue(maxsize=maxsize)   # ä½å±‚å’Œå…¶ä»–ç»éªŒé˜Ÿåˆ—
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        self.total_added = ThreadSafeCounter()
        self.total_consumed = ThreadSafeCounter()
        self.high_priority_added = ThreadSafeCounter()
        self.normal_priority_added = ThreadSafeCounter()
        self.high_priority_consumed = ThreadSafeCounter()
        self.normal_priority_consumed = ThreadSafeCounter()
        
        # ã€é˜¶æ®µ2æ–°å¢ã€‘çŠ¶æ€ç›‘æ§
        self.processing_speed_samples = deque(maxlen=100)  # ä¿ç•™æœ€è¿‘100ä¸ªå¤„ç†é€Ÿåº¦æ ·æœ¬
        self.last_monitoring_time = time.time()
        self.last_consumed_count = 0
        self.congestion_detected = False
        self.lock = Lock()
        
        # ã€é˜¶æ®µ2æ–°å¢ã€‘æ•°æ®å®Œæ•´æ€§æ ¡éªŒ
        self.checksum_errors = ThreadSafeCounter()
        self.validation_enabled = True
        
    def put(self, item, block=True, timeout=None):
        """ã€é˜¶æ®µ2å¢å¼ºã€‘æ·»åŠ æ•°æ®åˆ°ç¼“å†²åŒº - æ”¯æŒä¼˜å…ˆçº§å’Œå®Œæ•´æ€§æ ¡éªŒ"""
        try:
            # ã€æ•°æ®å®Œæ•´æ€§æ ¡éªŒã€‘
            if self.validation_enabled and not self._validate_item(item):
                self.checksum_errors.increment()
                return False
            
            # ã€ä¼˜å…ˆçº§å¤„ç†ã€‘æ ¹æ®ç»éªŒç±»å‹é€‰æ‹©é˜Ÿåˆ—
            experience_type = item.get('experience_type', 'low_level')
            
            if experience_type == 'high_level':
                # é«˜å±‚ç»éªŒä½¿ç”¨é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—
                try:
                    self.high_priority_queue.put(item, block=block, timeout=timeout)
                    self.high_priority_added.increment()
                    self.total_added.increment()
                    return True
                except queue.Full:
                    # é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—æ»¡æ—¶ï¼Œå°è¯•å¤„ç†æ‹¥å¡
                    if self._handle_high_priority_congestion(item, block, timeout):
                        return True
                    return False
            else:
                # ä½å±‚ç»éªŒå’Œå…¶ä»–æ•°æ®ä½¿ç”¨æ™®é€šé˜Ÿåˆ—
                self.normal_priority_queue.put(item, block=block, timeout=timeout)
                self.normal_priority_added.increment()
                self.total_added.increment()
                return True
                
        except queue.Full:
            # ã€é˜¶æ®µ2æ–°å¢ã€‘æ‹¥å¡æ£€æµ‹
            self._detect_congestion()
            return False
        except Exception as e:
            # è®°å½•å¼‚å¸¸ä½†ä¸æŠ›å‡ºï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§
            return False
    
    def get(self, block=True, timeout=None):
        """ã€é˜¶æ®µ2å¢å¼ºã€‘ä»ç¼“å†²åŒºè·å–æ•°æ® - ä¼˜å…ˆå¤„ç†é«˜å±‚ç»éªŒ"""
        try:
            # ã€ä¼˜å…ˆçº§å¤„ç†ã€‘å…ˆå°è¯•è·å–é«˜ä¼˜å…ˆçº§æ•°æ®
            if not self.high_priority_queue.empty():
                try:
                    item = self.high_priority_queue.get(block=False)
                    self.high_priority_consumed.increment()
                    self.total_consumed.increment()
                    self._update_processing_speed()
                    return item
                except queue.Empty:
                    pass  # é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­å¤„ç†æ™®é€šé˜Ÿåˆ—
            
            # å¤„ç†æ™®é€šä¼˜å…ˆçº§æ•°æ®
            item = self.normal_priority_queue.get(block=block, timeout=timeout)
            self.normal_priority_consumed.increment()
            self.total_consumed.increment()
            self._update_processing_speed()
            return item
            
        except queue.Empty:
            return None
    
    def qsize(self):
        """è·å–å½“å‰æ€»é˜Ÿåˆ—å¤§å°"""
        return self.high_priority_queue.qsize() + self.normal_priority_queue.qsize()
    
    def empty(self):
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©º"""
        return self.high_priority_queue.empty() and self.normal_priority_queue.empty()
    
    def get_stats(self):
        """ã€é˜¶æ®µ2å¢å¼ºã€‘è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        current_time = time.time()
        
        # è®¡ç®—å¤„ç†é€Ÿåº¦
        processing_speed = self._calculate_processing_speed()
        
        return {
            'queue_size': self.qsize(),
            'high_priority_size': self.high_priority_queue.qsize(),
            'normal_priority_size': self.normal_priority_queue.qsize(),
            'total_added': self.total_added.get(),
            'total_consumed': self.total_consumed.get(),
            'high_priority_added': self.high_priority_added.get(),
            'high_priority_consumed': self.high_priority_consumed.get(),
            'normal_priority_added': self.normal_priority_added.get(),
            'normal_priority_consumed': self.normal_priority_consumed.get(),
            'processing_speed': processing_speed,
            'congestion_detected': self.congestion_detected,
            'checksum_errors': self.checksum_errors.get(),
            'high_priority_ratio': self.high_priority_consumed.get() / max(1, self.total_consumed.get())
        }
    
    def _validate_item(self, item):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘éªŒè¯æ•°æ®é¡¹çš„å®Œæ•´æ€§"""
        try:
            # åŸºæœ¬éªŒè¯ï¼šæ£€æŸ¥å¿…éœ€å­—æ®µ
            if not isinstance(item, dict):
                return False
            
            required_fields = ['experience_type', 'worker_id']
            for field in required_fields:
                if field not in item:
                    return False
            
            # ç±»å‹ç‰¹å®šéªŒè¯
            experience_type = item.get('experience_type')
            if experience_type == 'low_level':
                required_low_level = ['state', 'actions', 'rewards', 'next_state']
                for field in required_low_level:
                    if field not in item:
                        return False
            elif experience_type == 'high_level':
                required_high_level = ['state', 'team_skill', 'accumulated_reward']
                for field in required_high_level:
                    if field not in item:
                        return False
            
            return True
            
        except Exception:
            return False
    
    def _handle_high_priority_congestion(self, item, block, timeout):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘å¤„ç†é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—æ‹¥å¡"""
        # å¦‚æœé«˜ä¼˜å…ˆçº§é˜Ÿåˆ—æ»¡äº†ï¼Œå°è¯•ä»æ™®é€šé˜Ÿåˆ—ä¸­è…¾å‡ºç©ºé—´
        retry_count = 3
        
        for i in range(retry_count):
            try:
                # å…ˆå°è¯•å¿«é€Ÿå¤„ç†ä¸€äº›æ™®é€šä¼˜å…ˆçº§çš„æ•°æ®
                if not self.normal_priority_queue.empty():
                    temp_items = []
                    # ä¸´æ—¶å–å‡ºä¸€äº›æ™®é€šä¼˜å…ˆçº§æ•°æ®
                    for _ in range(min(5, self.normal_priority_queue.qsize())):
                        try:
                            temp_item = self.normal_priority_queue.get(block=False)
                            temp_items.append(temp_item)
                        except queue.Empty:
                            break
                    
                    # å°è¯•å†æ¬¡æ”¾å…¥é«˜ä¼˜å…ˆçº§æ•°æ®
                    try:
                        self.high_priority_queue.put(item, block=False)
                        self.high_priority_added.increment()
                        self.total_added.increment()
                        
                        # å°†ä¸´æ—¶å–å‡ºçš„æ•°æ®æ”¾å›æ™®é€šé˜Ÿåˆ—
                        for temp_item in temp_items:
                            self.normal_priority_queue.put(temp_item, block=False)
                        
                        return True
                    except queue.Full:
                        # é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—ä»ç„¶æ»¡ï¼Œæ¢å¤æ™®é€šé˜Ÿåˆ—æ•°æ®
                        for temp_item in temp_items:
                            self.normal_priority_queue.put(temp_item, block=False)
                
                # çŸ­æš‚ç­‰å¾…åé‡è¯•
                time.sleep(0.01 * (i + 1))
                
            except Exception:
                continue
        
        return False
    
    def _detect_congestion(self):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘æ£€æµ‹é˜Ÿåˆ—æ‹¥å¡"""
        total_size = self.qsize()
        high_size = self.high_priority_queue.qsize()
        normal_size = self.normal_priority_queue.qsize()
        
        # æ‹¥å¡æ£€æµ‹æ¡ä»¶
        total_capacity = 10000  # å‡è®¾æ€»å®¹é‡
        congestion_threshold = 0.8  # 80%å®¹é‡è§¦å‘æ‹¥å¡è­¦å‘Š
        
        with self.lock:
            old_congestion = self.congestion_detected
            self.congestion_detected = total_size > (total_capacity * congestion_threshold)
            
            # åªåœ¨çŠ¶æ€å˜åŒ–æ—¶è®°å½•æ—¥å¿—
            if self.congestion_detected != old_congestion:
                if self.congestion_detected:
                    # æ‹¥å¡å¼€å§‹æ—¶è®°å½•è¯¦ç»†ä¿¡æ¯
                    pass  # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ‹¥å¡æ—¥å¿—ï¼Œä½†é¿å…è¿‡åº¦æ—¥å¿—
                else:
                    # æ‹¥å¡ç¼“è§£æ—¶è®°å½•
                    pass
    
    def _update_processing_speed(self):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘æ›´æ–°å¤„ç†é€Ÿåº¦ç»Ÿè®¡"""
        current_time = time.time()
        current_consumed = self.total_consumed.get()
        
        with self.lock:
            time_diff = current_time - self.last_monitoring_time
            consumed_diff = current_consumed - self.last_consumed_count
            
            if time_diff >= 1.0:  # æ¯ç§’æ›´æ–°ä¸€æ¬¡
                speed = consumed_diff / time_diff if time_diff > 0 else 0
                self.processing_speed_samples.append(speed)
                
                self.last_monitoring_time = current_time
                self.last_consumed_count = current_consumed
    
    def _calculate_processing_speed(self):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘è®¡ç®—å¹³å‡å¤„ç†é€Ÿåº¦"""
        with self.lock:
            if len(self.processing_speed_samples) == 0:
                return 0.0
            return sum(self.processing_speed_samples) / len(self.processing_speed_samples)
    
    def get_priority_status(self):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘è·å–ä¼˜å…ˆçº§é˜Ÿåˆ—çŠ¶æ€"""
        return {
            'high_priority_queue_size': self.high_priority_queue.qsize(),
            'normal_priority_queue_size': self.normal_priority_queue.qsize(),
            'high_priority_full': self.high_priority_queue.qsize() >= (self.high_priority_queue.maxsize * 0.9),
            'normal_priority_full': self.normal_priority_queue.qsize() >= (self.normal_priority_queue.maxsize * 0.9),
            'congestion_detected': self.congestion_detected
        }

class RolloutWorker:
    """å•ä¸ªrollout workerï¼Œåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œ"""
    def __init__(self, worker_id, env_factory, config, data_buffer, control_events, logger):
        self.worker_id = worker_id
        self.env_factory = env_factory
        self.config = config
        self.data_buffer = data_buffer
        self.control_events = control_events
        self.logger = logger
        
        # åˆ›å»ºç¯å¢ƒ
        self.env = env_factory()
        
        # çŠ¶æ€å˜é‡
        self.samples_collected = 0
        self.episodes_completed = 0
        self.total_reward = 0.0
        
        # ã€å…³é”®ä¿®å¤ã€‘æ·»åŠ rolloutå®Œæˆæ§åˆ¶
        self.rollout_completed = False
        self.target_rollout_steps = config.rollout_length  # æ¯ä¸ªworkerçš„ç›®æ ‡æ­¥æ•°ï¼ˆ128ï¼‰
        
        # ç¯å¢ƒçŠ¶æ€
        self.env_state = None
        self.env_observations = None
        self.episode_step = 0
        
        # ã€æ–¹æ¡ˆ2ã€‘ä¸¥æ ¼çš„æ­¥æ•°è®¡æ•°æ–¹æ³•
        self.strict_step_counter = 0  # ä¸¥æ ¼æ­¥æ•°è®¡æ•°å™¨
        self.accumulated_reward = 0.0  # 32æ­¥ç´¯ç§¯å¥–åŠ±
        self.current_team_skill = None
        self.current_agent_skills = None
        self.skill_log_probs = None
        self.high_level_experiences_generated = 0
        
        # ã€ä¿®å¤1ã€‘æ·»åŠ æ­¥æ•°éªŒè¯æ ‡å¿—
        self.step_validation_enabled = True
        self.last_reported_steps = 0
        
        # æŠ€èƒ½è®¡æ—¶å™¨åˆå§‹åŒ–
        self.skill_timer = 0
        
    def reset_environment(self):
        """é‡ç½®ç¯å¢ƒ"""
        try:
            result = self.env.reset()
            if isinstance(result, tuple):
                self.env_observations, info = result
                self.env_state = info.get('state', np.zeros(self.config.state_dim))
            else:
                self.env_observations = result
                self.env_state = np.zeros(self.config.state_dim)
            self.episode_step = 0
            return True
        except Exception as e:
            self.logger.error(f"Worker {self.worker_id}: é‡ç½®ç¯å¢ƒå¤±è´¥: {e}")
            return False
    
    def step_environment(self, actions):
        """æ‰§è¡Œç¯å¢ƒæ­¥éª¤"""
        try:
            # ä¿®å¤ï¼šå¤„ç†Gymnasium APIçš„5ä¸ªè¿”å›å€¼
            result = self.env.step(actions)
            
            if len(result) == 5:
                # Gymnasiumæ ¼å¼: observations, reward, terminated, truncated, info
                next_observations, rewards, terminated, truncated, infos = result
                dones = terminated or truncated  # åˆå¹¶ç»ˆæ­¢æ¡ä»¶
            elif len(result) == 4:
                # ä¼ ç»Ÿæ ¼å¼: observations, rewards, dones, infos
                next_observations, rewards, dones, infos = result
            else:
                raise ValueError(f"Unexpected number of return values from env.step(): {len(result)}")
            
            # ä»infoä¸­æå–next_state
            if isinstance(infos, dict):
                next_state = infos.get('next_state', np.zeros(self.config.state_dim))
            elif isinstance(infos, list) and len(infos) > 0:
                next_state = infos[0].get('next_state', np.zeros(self.config.state_dim))
            else:
                next_state = np.zeros(self.config.state_dim)
            
            self.episode_step += 1
            return next_observations, rewards, dones, next_state
            
        except Exception as e:
            self.logger.error(f"Worker {self.worker_id}: ç¯å¢ƒæ­¥éª¤å¤±è´¥: {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼è€Œä¸æ˜¯None
            n_agents = len(actions) if hasattr(actions, '__len__') else self.config.n_agents
            default_obs = np.zeros((n_agents, self.config.obs_dim))
            return default_obs, 0.0, True, np.zeros(self.config.state_dim)
    
    def run(self, agent_proxy):
        """è¿è¡Œrollout workerä¸»å¾ªç¯ - ä¿®å¤ç‰ˆæœ¬ï¼šæ·»åŠ ä¸¥æ ¼çš„æ­¥æ•°æ§åˆ¶"""
        self.logger.info(f"Rollout worker {self.worker_id} å¼€å§‹è¿è¡Œï¼Œç›®æ ‡æ”¶é›†æ­¥æ•°: {self.target_rollout_steps}")
        
        # åˆå§‹åŒ–rolloutå¼€å§‹æ—¶é—´
        self.rollout_start_time = time.time()
        
        # é‡ç½®ç¯å¢ƒ
        if not self.reset_environment():
            self.logger.error(f"Worker {self.worker_id}: åˆå§‹åŒ–å¤±è´¥")
            return
        
        try:
            # ã€å…³é”®ä¿®å¤ã€‘æ— é™å¾ªç¯è®­ç»ƒæ¨¡å¼ï¼šæ¯æ¬¡å®Œæˆä¸€ä¸ªrolloutåç­‰å¾…æ–°çš„å‘¨æœŸå¼€å§‹
            while not self.control_events['stop'].is_set():
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœ
                if self.control_events['pause'].is_set():
                    time.sleep(0.1)
                    continue
                
                # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœå½“å‰rolloutå·²å®Œæˆï¼Œç­‰å¾…æ–°çš„rolloutå‘¨æœŸ
                if self.rollout_completed:
                    time.sleep(0.1)  # ç­‰å¾…è®­ç»ƒå®Œæˆå’ŒçŠ¶æ€é‡ç½®
                    continue
                
                # ã€å…³é”®ä¿®å¤ã€‘æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°rolloutæ­¥æ•°é™åˆ¶
                if self.samples_collected >= self.target_rollout_steps:
                    self.rollout_completed = True
                    self.complete_rollout()
                    continue
                
                # æ‰§è¡Œä¸€ä¸ªrolloutæ­¥éª¤
                success = self.run_step(agent_proxy)
                if not success:
                    self.logger.warning(f"Worker {self.worker_id}: æ­¥éª¤æ‰§è¡Œå¤±è´¥ï¼Œé‡ç½®ç¯å¢ƒ")
                    if not self.reset_environment():
                        break
                
                # çŸ­æš‚ç¡çœ é¿å…è¿‡åº¦å ç”¨CPU
                time.sleep(0.001)
        
        except Exception as e:
            self.logger.error(f"Worker {self.worker_id}: è¿è¡Œå¼‚å¸¸: {e}")
        finally:
            try:
                self.env.close()
            except:
                pass
            self.logger.info(f"Rollout worker {self.worker_id} ç»“æŸè¿è¡Œ")
    
    def run_step(self, agent_proxy):
        """ã€é˜¶æ®µ3ä¿®å¤ã€‘æ‰§è¡Œå•ä¸ªrolloutæ­¥éª¤ - ç¡®å®šæ€§æ­¥æ•°è®¡æ•°å’Œé«˜å±‚ç»éªŒæ”¶é›†"""
        
        try:
            # ã€é˜¶æ®µ3ä¿®å¤ã€‘ç¡®ä¿ç¯å¢ƒçŠ¶æ€æœ‰æ•ˆ
            if self.env_state is None:
                self.logger.warning(f"Worker {self.worker_id}: env_stateä¸ºNoneï¼Œé‡ç½®ç¯å¢ƒ")
                if not self.reset_environment():
                    return False
            
            if self.env_observations is None:
                self.logger.warning(f"Worker {self.worker_id}: env_observationsä¸ºNoneï¼Œé‡ç½®ç¯å¢ƒ")
                if not self.reset_environment():
                    return False
            
            # ã€é˜¶æ®µ3ä¿®å¤ã€‘æ¯æ¬¡éƒ½é‡æ–°åˆ†é…æŠ€èƒ½ï¼Œä¿æŒç®€å•é€»è¾‘
            team_skill, agent_skills, log_probs = agent_proxy.assign_skills_for_worker(
                self.env_state, self.env_observations, self.worker_id
            )
            
            # æ›´æ–°å½“å‰æŠ€èƒ½çŠ¶æ€
            self.current_team_skill = team_skill
            self.current_agent_skills = agent_skills
            self.skill_log_probs = log_probs
            
            # ä»ä»£ç†è·å–åŠ¨ä½œ
            actions, action_logprobs = agent_proxy.get_actions_for_worker(
                self.env_state, self.env_observations, agent_skills, self.worker_id
            )
            
            # æ‰§è¡Œç¯å¢ƒæ­¥éª¤
            next_observations, rewards, dones, next_state = self.step_environment(actions)
            
            # ã€é˜¶æ®µ3æ ¸å¿ƒä¿®å¤ã€‘åŸå­æ€§æ­¥æ•°è®¡æ•° - ç¡®ä¿ä¸€è‡´æ€§
            step_before_increment = self.samples_collected
            self.samples_collected += 1
            step_after_increment = self.samples_collected
            
            # ç¡®ä¿rewardsæ˜¯æœ‰æ•ˆçš„æ•°å€¼
            if rewards is None:
                current_reward = 0.0
                self.logger.warning(f"Worker {self.worker_id}: ç¯å¢ƒæ­¥éª¤è¿”å›Noneå¥–åŠ±ï¼Œä½¿ç”¨0.0")
            else:
                current_reward = rewards if isinstance(rewards, (int, float)) else np.sum(rewards)
            
            # ç´¯ç§¯å¥–åŠ±ï¼ˆç”¨äºé«˜å±‚ç»éªŒï¼‰
            self.accumulated_reward += current_reward
            self.total_reward += current_reward
            
            # ã€é˜¶æ®µ3ä¿®å¤ã€‘å®‰å…¨å¤åˆ¶æ•°æ®ï¼Œé¿å…None.copy()é”™è¯¯
            def safe_copy(data, default_shape=None):
                if data is None:
                    if default_shape is not None:
                        return np.zeros(default_shape)
                    return None
                if hasattr(data, 'copy'):
                    return data.copy()
                return np.array(data)
            
            # å­˜å‚¨ä½å±‚ç»éªŒæ•°æ®
            low_level_experience = {
                'experience_type': 'low_level',
                'worker_id': self.worker_id,
                'state': safe_copy(self.env_state, (self.config.state_dim,)),
                'observations': safe_copy(self.env_observations, (self.config.n_agents, self.config.obs_dim)),
                'actions': safe_copy(actions, (self.config.n_agents, self.config.action_dim)),
                'rewards': current_reward,
                'next_state': safe_copy(next_state, (self.config.state_dim,)),
                'next_observations': safe_copy(next_observations, (self.config.n_agents, self.config.obs_dim)),
                'dones': dones,
                'episode_step': self.episode_step,
                'team_skill': team_skill,
                'agent_skills': safe_copy(agent_skills, (self.config.n_agents,)) if agent_skills is not None else [0] * self.config.n_agents,
                'action_logprobs': safe_copy(action_logprobs, (self.config.n_agents,)),
                'skill_log_probs': log_probs,
                'step_number': step_after_increment  # ã€é˜¶æ®µ3æ–°å¢ã€‘æ­¥éª¤ç¼–å·ç”¨äºè°ƒè¯•
            }
            
            # å°†ä½å±‚ç»éªŒæ”¾å…¥ç¼“å†²åŒº - ä½¿ç”¨æ— é™é˜»å¡ç¡®ä¿æ•°æ®ä¸ä¸¢å¤±
            success = self.data_buffer.put(low_level_experience, block=True, timeout=None)
            if success:
                self.logger.debug(f"Worker {self.worker_id}: ä½å±‚ç»éªŒå·²æ”¾å…¥ç¼“å†²åŒº - æ­¥éª¤={step_after_increment}")
            else:
                self.logger.error(f"Worker {self.worker_id}: ä½å±‚ç»éªŒæ”¾å…¥ç¼“å†²åŒºå¤±è´¥ï¼è¿™ä¸åº”è¯¥å‘ç”Ÿ")
            
            # æ„é€ StateSkillDatasetæ•°æ®
            state_skill_experience = {
                'experience_type': 'state_skill',
                'worker_id': self.worker_id,
                'state': safe_copy(next_state, (self.config.state_dim,)),
                'team_skill': team_skill,
                'observations': safe_copy(next_observations, (self.config.n_agents, self.config.obs_dim)),
                'agent_skills': safe_copy(agent_skills, (self.config.n_agents,)) if agent_skills is not None else [0] * self.config.n_agents,
                'step_number': step_after_increment  # ã€é˜¶æ®µ3æ–°å¢ã€‘æ­¥éª¤ç¼–å·
            }
            
            # å°†StateSkillDatasetæ•°æ®æ”¾å…¥ç¼“å†²åŒº
            success = self.data_buffer.put(state_skill_experience, block=True, timeout=None)
            if success:
                self.logger.debug(f"Worker {self.worker_id}: StateSkillæ•°æ®å·²æ”¾å…¥ç¼“å†²åŒº")
            else:
                self.logger.error(f"Worker {self.worker_id}: StateSkillæ•°æ®æ”¾å…¥ç¼“å†²åŒºå¤±è´¥ï¼è¿™ä¸åº”è¯¥å‘ç”Ÿ")
            
            # ã€é˜¶æ®µ3æ ¸å¿ƒä¿®å¤ã€‘ç¡®å®šæ€§é«˜å±‚ç»éªŒæ”¶é›† - ä¸¥æ ¼æŒ‰kæ­¥æ”¶é›†
            if step_after_increment % self.config.k == 0:
                self.logger.debug(f"Worker {self.worker_id}: ç¡®å®šæ€§kæ­¥æ”¶é›†é«˜å±‚ç»éªŒ - "
                               f"æ­¥æ•°={step_after_increment}, k={self.config.k}, "
                               f"ç´¯ç§¯å¥–åŠ±={self.accumulated_reward:.4f}")
                
                success = self.store_high_level_experience(f"ç¡®å®šæ€§kæ­¥æ”¶é›†(æ­¥æ•°={step_after_increment})")
                if success:
                    self.logger.debug(f"Worker {self.worker_id}: é«˜å±‚ç»éªŒæ”¶é›†æˆåŠŸ - ç¬¬{self.high_level_experiences_generated}ä¸ª")
                    # åªåœ¨æˆåŠŸå­˜å‚¨åé‡ç½®ç´¯ç§¯å¥–åŠ±
                    self.accumulated_reward = 0.0
                else:
                    self.logger.error(f"Worker {self.worker_id}: é«˜å±‚ç»éªŒå­˜å‚¨å¤±è´¥ï¼")
            
            # ã€é˜¶æ®µ3ä¿®å¤ã€‘å®‰å…¨æ›´æ–°ç¯å¢ƒçŠ¶æ€
            self.env_state = safe_copy(next_state, (self.config.state_dim,))
            self.env_observations = safe_copy(next_observations, (self.config.n_agents, self.config.obs_dim))
            
            # æ£€æŸ¥episodeæ˜¯å¦ç»“æŸ
            max_episode_length = getattr(self.config, 'rollout_max_episode_length', 5000)
            if dones or self.episode_step >= max_episode_length:
                self.episodes_completed += 1
                termination_reason = "ç¯å¢ƒè‡ªç„¶ç»ˆæ­¢" if dones else f"è¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶({max_episode_length})"
                self.logger.debug(f"Worker {self.worker_id}: Episode {self.episodes_completed} å®Œæˆ, "
                                f"æ­¥æ•°: {self.episode_step}, å¥–åŠ±: {self.total_reward:.2f}, "
                                f"ç»ˆæ­¢åŸå› : {termination_reason}")
                
                # é‡ç½®ç¯å¢ƒå’ŒæŠ€èƒ½çŠ¶æ€
                if not self.reset_environment():
                    return False
                self.reset_skill_state()
                self.total_reward = 0.0
            
            return True
            
        except Exception as e:
            self.logger.error(f"Worker {self.worker_id}: æ­¥éª¤æ‰§è¡Œå¼‚å¸¸: {e}")
            # ã€é˜¶æ®µ3ä¿®å¤ã€‘å³ä½¿å¼‚å¸¸ä¹Ÿè¦ç¡®ä¿æ­¥æ•°è®¡æ•°çš„ä¸€è‡´æ€§
            if hasattr(self, 'samples_collected'):
                self.samples_collected += 1
            return False
    
    def should_reassign_skills(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ†é…æŠ€èƒ½"""
        return (self.skill_timer >= self.config.k or 
                self.current_team_skill is None)
    
    def should_store_high_level_experience(self, dones):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦å­˜å‚¨é«˜å±‚ç»éªŒ - ä¿®å¤ç‰ˆæœ¬ï¼šåªåœ¨æŠ€èƒ½å‘¨æœŸå®Œæˆæˆ–ç¯å¢ƒç»ˆæ­¢æ—¶å­˜å‚¨"""
        # åªåœ¨ä»¥ä¸‹æƒ…å†µå­˜å‚¨é«˜å±‚ç»éªŒï¼š
        # 1. æŠ€èƒ½å‘¨æœŸå®Œæˆï¼ˆè¾¾åˆ°kæ­¥ï¼‰
        # 2. ç¯å¢ƒç»ˆæ­¢ï¼ˆepisodeç»“æŸï¼‰
        return (self.skill_timer >= self.config.k or dones)
    
    def assign_new_skills(self, agent_proxy):
        """é‡æ–°åˆ†é…æŠ€èƒ½"""
        try:
            team_skill, agent_skills, log_probs = agent_proxy.assign_skills_for_worker(
                self.env_state, self.env_observations, self.worker_id
            )
            
            self.current_team_skill = team_skill
            self.current_agent_skills = agent_skills
            self.skill_log_probs = log_probs
            self.skill_timer = 0
            self.accumulated_reward = 0.0
            self.last_skill_assignment_step = self.episode_step
            
            self.logger.debug(f"Worker {self.worker_id}: æŠ€èƒ½é‡æ–°åˆ†é… - "
                            f"team_skill={team_skill}, agent_skills={agent_skills}")
            
        except Exception as e:
            self.logger.error(f"Worker {self.worker_id}: æŠ€èƒ½åˆ†é…å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤æŠ€èƒ½ä½œä¸ºå›é€€
            self.current_team_skill = 0
            self.current_agent_skills = [0] * self.config.n_agents
            self.skill_log_probs = {'team_log_prob': 0.0, 'agent_log_probs': [0.0] * self.config.n_agents}
    
    def store_high_level_experience(self, reason="æŠ€èƒ½å‘¨æœŸå®Œæˆ"):
        """å­˜å‚¨é«˜å±‚ç»éªŒåˆ°æ•°æ®ç¼“å†²åŒº"""
        if self.current_team_skill is None or self.current_agent_skills is None:
            self.logger.warning(f"Worker {self.worker_id}: æŠ€èƒ½çŠ¶æ€æ— æ•ˆï¼Œè·³è¿‡é«˜å±‚ç»éªŒå­˜å‚¨")
            return False
        
        try:
            high_level_experience = {
                'experience_type': 'high_level',
                'worker_id': self.worker_id,
                'state': self.env_state.copy(),
                'team_skill': self.current_team_skill,
                'observations': self.env_observations.copy(),
                'agent_skills': self.current_agent_skills.copy(),
                'accumulated_reward': self.accumulated_reward,
                'skill_log_probs': self.skill_log_probs.copy() if self.skill_log_probs else None,
                'skill_timer': self.skill_timer,
                'episode_step': self.episode_step,
                'reason': reason
            }
            
            # ã€ä¿®å¤5ã€‘å°†é«˜å±‚ç»éªŒæ”¾å…¥ç¼“å†²åŒº - ä½¿ç”¨æ— é™é˜»å¡ç¡®ä¿æ•°æ®ä¸ä¸¢å¤±
            success = self.data_buffer.put(high_level_experience, block=True, timeout=None)
            if success:
                self.high_level_experiences_generated += 1
                self.logger.debug(f"Worker {self.worker_id}: é«˜å±‚ç»éªŒå·²å­˜å‚¨ - "
                                f"ç´¯ç§¯å¥–åŠ±={self.accumulated_reward:.4f}, åŸå› ={reason}, "
                                f"æ€»ç”Ÿæˆæ•°={self.high_level_experiences_generated}")
                
                # ã€æ–°å¢è°ƒè¯•ã€‘è®°å½•accumulated_rewardçš„é‡ç½®
                old_accumulated_reward = self.accumulated_reward
                self.accumulated_reward = 0.0
                self.skill_timer = 0
                self.logger.debug(f"ğŸ’° [REWARD_RESET] W{self.worker_id} accumulated_reward reset: "
                                f"{old_accumulated_reward:.4f} -> 0.0 (reason: {reason})")
                return True
            else:
                self.logger.error(f"Worker {self.worker_id}: é«˜å±‚ç»éªŒæ”¾å…¥ç¼“å†²åŒºå¤±è´¥ï¼è¿™ä¸åº”è¯¥å‘ç”Ÿ")
                return False
                
        except Exception as e:
            self.logger.error(f"Worker {self.worker_id}: å­˜å‚¨é«˜å±‚ç»éªŒå¤±è´¥: {e}")
            return False
    
    def complete_rollout(self):
        """ã€é˜¶æ®µ3ä¿®å¤ã€‘å®Œæˆå½“å‰rollout - åˆ†é˜¶æ®µéªŒè¯å’Œç¡®å®šæ€§æ•°æ®è¡¥é½"""
        completion_time = time.time()
        
        # ã€é˜¶æ®µ3æ­¥éª¤1ã€‘åŸºç¡€éªŒè¯ - ç¡®ä¿æ­¥æ•°å‡†ç¡®
        if self.samples_collected != self.target_rollout_steps:
            self.logger.warning(f"Worker {self.worker_id}: æ­¥æ•°ä¸åŒ¹é…! "
                              f"æ”¶é›†={self.samples_collected}, ç›®æ ‡={self.target_rollout_steps}")
            # ã€é˜¶æ®µ3ä¿®å¤ã€‘å¼ºåˆ¶åŒæ­¥æ­¥æ•°
            self.samples_collected = self.target_rollout_steps
        
        # ã€é˜¶æ®µ3æ­¥éª¤2ã€‘ç¡®å®šæ€§é«˜å±‚ç»éªŒè®¡ç®—
        expected_high_level = self.target_rollout_steps // self.config.k  # å¿…é¡»æ˜¯æ•´æ•°é™¤æ³•ï¼Œç¡®ä¿ç¡®å®šæ€§
        current_high_level = self.high_level_experiences_generated
        missing = expected_high_level - current_high_level
        
        self.logger.info(f"Worker {self.worker_id}: ã€é˜¶æ®µ3ã€‘Rolloutå®ŒæˆéªŒè¯ - "
                       f"ç›®æ ‡æ­¥æ•°={self.target_rollout_steps}, å®é™…æ­¥æ•°={self.samples_collected}, "
                       f"æœŸæœ›é«˜å±‚={expected_high_level} (è®¡ç®—: {self.target_rollout_steps}//{self.config.k}), "
                       f"å½“å‰é«˜å±‚={current_high_level}, ç¼ºå¤±={missing}")
        
        # ã€é˜¶æ®µ3æ­¥éª¤3ã€‘ç¡®å®šæ€§æ•°æ®è¡¥é½ - å¿…é¡»è¡¥é½åˆ°å‡†ç¡®æ•°é‡
        if missing > 0:
            self.logger.info(f"Worker {self.worker_id}: ã€é˜¶æ®µ3ã€‘å¼€å§‹ç¡®å®šæ€§è¡¥é½ {missing} ä¸ªé«˜å±‚ç»éªŒ")
            
            è¡¥é½æˆåŠŸè®¡æ•° = 0
            for i in range(missing):
                success = self.store_high_level_experience(f"ã€é˜¶æ®µ3ã€‘ç¡®å®šæ€§è¡¥é½#{i+1}")
                if success:
                    è¡¥é½æˆåŠŸè®¡æ•° += 1
                    self.logger.debug(f"Worker {self.worker_id}: ç¡®å®šæ€§è¡¥é½#{i+1}æˆåŠŸ")
                else:
                    self.logger.error(f"Worker {self.worker_id}: ç¡®å®šæ€§è¡¥é½#{i+1}å¤±è´¥ï¼")
                    break
            
            # ã€é˜¶æ®µ3éªŒè¯ã€‘ç¡®ä¿è¡¥é½æˆåŠŸ
            if è¡¥é½æˆåŠŸè®¡æ•° == missing:
                self.logger.info(f"Worker {self.worker_id}: âœ… ç¡®å®šæ€§è¡¥é½å®Œæˆ {è¡¥é½æˆåŠŸè®¡æ•°}/{missing}")
            else:
                self.logger.error(f"Worker {self.worker_id}: âŒ ç¡®å®šæ€§è¡¥é½å¤±è´¥ {è¡¥é½æˆåŠŸè®¡æ•°}/{missing}")
        
        # ã€é˜¶æ®µ3æ­¥éª¤4ã€‘æœ€ç»ˆéªŒè¯ - ç¡®ä¿æ•°æ®é‡å‡†ç¡®
        final_high_level = self.high_level_experiences_generated
        if final_high_level != expected_high_level:
            self.logger.error(f"Worker {self.worker_id}: âŒ ã€é˜¶æ®µ3ã€‘æœ€ç»ˆéªŒè¯å¤±è´¥! "
                            f"é«˜å±‚ç»éªŒ={final_high_level}, æœŸæœ›={expected_high_level}")
        else:
            self.logger.info(f"Worker {self.worker_id}: âœ… ã€é˜¶æ®µ3ã€‘æœ€ç»ˆéªŒè¯é€šè¿‡! "
                           f"é«˜å±‚ç»éªŒ={final_high_level}, æœŸæœ›={expected_high_level}")
        
        # ã€é˜¶æ®µ3æ­¥éª¤5ã€‘ç­‰å¾…æ•°æ®ä¼ è¾“å®Œæˆ - ç¡®ä¿100%ä¼ è¾“
        self.wait_for_data_transmission_complete()
        
        # è®¡ç®—rolloutç»Ÿè®¡
        if not hasattr(self, 'rollout_start_time'):
            self.rollout_start_time = completion_time - 1.0
        
        rollout_duration = completion_time - self.rollout_start_time
        speed = self.samples_collected / rollout_duration if rollout_duration > 0 else 0
        
        self.logger.info(f"Worker {self.worker_id}: ã€é˜¶æ®µ3ã€‘Rolloutå®Œæˆç»Ÿè®¡ - "
                       f"æ­¥æ•°={self.samples_collected}, é«˜å±‚ç»éªŒ={self.high_level_experiences_generated}, "
                       f"è€—æ—¶={rollout_duration:.1f}s, é€Ÿåº¦={speed:.1f}æ­¥/s")
        
        # é‡ç½®å¼€å§‹æ—¶é—´
        self.rollout_start_time = completion_time
    
    def force_collect_pending_high_level_experience(self):
        """å¼ºåˆ¶æ”¶é›†pendingçš„é«˜å±‚ç»éªŒï¼Œç¡®ä¿æ¯ä¸ªworkeréƒ½è´¡çŒ®å®Œæ•´çš„é«˜å±‚ç»éªŒ - ä¿®å¤ç‰ˆæœ¬ï¼šç»Ÿä¸€è¾¹ç•Œæ¡ä»¶"""
        # ã€ä¿®å¤2ã€‘è®¡ç®—åº”è¯¥ç”Ÿæˆçš„é«˜å±‚ç»éªŒæ€»æ•°
        expected_high_level_total = (self.samples_collected + self.config.k - 1) // self.config.k  # å‘ä¸Šå–æ•´
        current_high_level_total = self.high_level_experiences_generated
        missing_high_level = expected_high_level_total - current_high_level_total
        
        # ã€æ–°å¢è°ƒè¯•ã€‘è®°å½•è¿›å…¥è¯¥å‡½æ•°æ—¶çš„è¯¦ç»†çŠ¶æ€
        self.logger.info(f"ğŸ”§ [FORCE_COLLECT_DEBUG] W{self.worker_id} Entering force_collect_pending: "
                       f"strict_steps={self.strict_step_counter}, k={self.config.k}, "
                       f"samples_collected={self.samples_collected}, "
                       f"expected_total={expected_high_level_total}, current_total={current_high_level_total}, "
                       f"missing={missing_high_level}, acc_reward={self.accumulated_reward:.4f}")
        
        # ã€ä¿®å¤2Aã€‘åŸºäºç¼ºå¤±æ•°é‡è¿›è¡Œå¼ºåˆ¶æ”¶é›†ï¼Œè€Œä¸æ˜¯åŸºäºä½™æ•°
        if missing_high_level > 0:
            self.logger.info(f"ğŸ”§ [FORCE_COLLECT] W{self.worker_id} éœ€è¦å¼ºåˆ¶æ”¶é›† {missing_high_level} ä¸ªé«˜å±‚ç»éªŒ")
            
            # ã€ä¿®å¤2Bã€‘ä¸ºæ¯ä¸ªç¼ºå¤±çš„é«˜å±‚ç»éªŒè¿›è¡Œå¼ºåˆ¶æ”¶é›†
            for i in range(missing_high_level):
                success = self.store_high_level_experience(f"Rolloutç»“æŸå¼ºåˆ¶æ”¶é›†#{i+1}")
                if success:
                    self.logger.info(f"âœ… [FORCE_COLLECT] W{self.worker_id} å¼ºåˆ¶æ”¶é›†#{i+1}æˆåŠŸ: "
                                   f"é«˜å±‚ç»éªŒ={self.high_level_experiences_generated}/{expected_high_level_total}")
                else:
                    self.logger.error(f"âŒ [FORCE_COLLECT] W{self.worker_id} å¼ºåˆ¶æ”¶é›†#{i+1}å¤±è´¥ï¼")
                    break
            
            # ã€ä¿®å¤2Cã€‘éªŒè¯å¼ºåˆ¶æ”¶é›†ç»“æœ
            final_high_level_total = self.high_level_experiences_generated
            if final_high_level_total >= expected_high_level_total:
                self.logger.info(f"âœ… [FORCE_COLLECT] W{self.worker_id} å¼ºåˆ¶æ”¶é›†å®Œæˆ: "
                               f"é«˜å±‚ç»éªŒ={final_high_level_total}, é¢„æœŸ={expected_high_level_total}")
            else:
                remaining_missing = expected_high_level_total - final_high_level_total
                self.logger.warning(f"âš ï¸ [FORCE_COLLECT] W{self.worker_id} å¼ºåˆ¶æ”¶é›†åä»ç¼ºå¤± {remaining_missing} ä¸ªé«˜å±‚ç»éªŒ")
        else:
            self.logger.info(f"âœ… [FORCE_COLLECT_DEBUG] W{self.worker_id} æ— éœ€å¼ºåˆ¶æ”¶é›†: "
                           f"å½“å‰={current_high_level_total}, é¢„æœŸ={expected_high_level_total}")
        
        # ã€æ–°å¢è°ƒè¯•ã€‘è®°å½•ç¦»å¼€è¯¥å‡½æ•°æ—¶çš„çŠ¶æ€
        self.logger.info(f"ğŸ”§ [FORCE_COLLECT_DEBUG] W{self.worker_id} Exiting force_collect_pending: "
                       f"high_level_generated_after_force={self.high_level_experiences_generated}")
    
    def wait_for_data_transmission(self):
        """ç­‰å¾…æ•°æ®ä¼ è¾“å®Œæˆï¼Œç¡®ä¿æ‰€æœ‰ç»éªŒéƒ½è¿›å…¥ç¼“å†²åŒº"""
        max_wait_time = 5.0  # æœ€å¤šç­‰å¾…5ç§’
        wait_start = time.time()
        initial_queue_size = self.data_buffer.qsize()
        
        # ç­‰å¾…é˜Ÿåˆ—å¤„ç†å®Œæˆ
        while time.time() - wait_start < max_wait_time:
            current_queue_size = self.data_buffer.qsize()
            
            # å¦‚æœé˜Ÿåˆ—å¤§å°åœ¨å‡å°‘ï¼Œè¯´æ˜è¿˜åœ¨å¤„ç†
            if current_queue_size > 0:
                time.sleep(0.1)
            else:
                break
        
        final_wait_time = time.time() - wait_start
        final_queue_size = self.data_buffer.qsize()
        
        if final_wait_time >= max_wait_time:
            self.logger.warning(f"âš ï¸ [DATA_WAIT] W{self.worker_id} æ•°æ®ä¼ è¾“ç­‰å¾…è¶…æ—¶: "
                              f"ç­‰å¾…æ—¶é—´={final_wait_time:.2f}s, å‰©ä½™é˜Ÿåˆ—={final_queue_size}")
        else:
            self.logger.debug(f"âœ… [DATA_WAIT] W{self.worker_id} æ•°æ®ä¼ è¾“å®Œæˆ: "
                            f"ç­‰å¾…æ—¶é—´={final_wait_time:.2f}s, é˜Ÿåˆ—å˜åŒ–={initial_queue_size}â†’{final_queue_size}")
    
    def wait_for_data_transmission_complete(self):
        """ã€é˜¶æ®µ3æ–°å¢ã€‘ç­‰å¾…æ•°æ®ä¼ è¾“100%å®Œæˆ - å¢å¼ºç‰ˆæ•°æ®ä¼ è¾“ç­‰å¾…"""
        max_wait_time = 10.0  # é˜¶æ®µ3ï¼šæ›´é•¿ç­‰å¾…æ—¶é—´
        wait_start = time.time()
        initial_queue_size = self.data_buffer.qsize()
        
        self.logger.debug(f"Worker {self.worker_id}: ã€é˜¶æ®µ3ã€‘å¼€å§‹ç­‰å¾…æ•°æ®ä¼ è¾“100%å®Œæˆ - "
                        f"åˆå§‹é˜Ÿåˆ—å¤§å°={initial_queue_size}")
        
        consecutive_empty_checks = 0
        required_empty_checks = 5  # éœ€è¦è¿ç»­5æ¬¡æ£€æŸ¥é˜Ÿåˆ—ä¸ºç©º
        
        while time.time() - wait_start < max_wait_time:
            current_queue_size = self.data_buffer.qsize()
            
            if current_queue_size == 0:
                consecutive_empty_checks += 1
                if consecutive_empty_checks >= required_empty_checks:
                    # è¿ç»­å¤šæ¬¡ç¡®è®¤é˜Ÿåˆ—ä¸ºç©ºï¼Œæ•°æ®ä¼ è¾“å®Œæˆ
                    break
            else:
                consecutive_empty_checks = 0  # é‡ç½®è®¡æ•°å™¨
            
            time.sleep(0.1)
        
        final_wait_time = time.time() - wait_start
        final_queue_size = self.data_buffer.qsize()
        
        if final_queue_size == 0 and consecutive_empty_checks >= required_empty_checks:
            self.logger.debug(f"Worker {self.worker_id}: âœ… ã€é˜¶æ®µ3ã€‘æ•°æ®ä¼ è¾“100%å®Œæˆ - "
                            f"ç­‰å¾…æ—¶é—´={final_wait_time:.2f}s, è¿ç»­ç©ºæ£€æŸ¥={consecutive_empty_checks}")
        else:
            self.logger.warning(f"Worker {self.worker_id}: âš ï¸ ã€é˜¶æ®µ3ã€‘æ•°æ®ä¼ è¾“æœªå®Œå…¨å®Œæˆ - "
                              f"ç­‰å¾…æ—¶é—´={final_wait_time:.2f}s, å‰©ä½™é˜Ÿåˆ—={final_queue_size}, "
                              f"è¿ç»­ç©ºæ£€æŸ¥={consecutive_empty_checks}/{required_empty_checks}")
    
    def reset_skill_state(self):
        """é‡ç½®æŠ€èƒ½çŠ¶æ€ï¼ˆæ–¹æ¡ˆ2ï¼šä¸¥æ ¼æ­¥æ•°è®¡æ•°ï¼‰"""
        # ã€ä¿®å¤ã€‘ä¸é‡ç½®strict_step_counterï¼Œä¿æŒè¿ç»­è®¡æ•°
        # self.strict_step_counter = 0  # ç§»é™¤è¿™è¡Œï¼Œä¿æŒè®¡æ•°å™¨è¿ç»­æ€§
        self.accumulated_reward = 0.0
        self.current_team_skill = None
        self.current_agent_skills = None
        self.skill_log_probs = None
    
    def get_worker_stats(self):
        """è·å–workerç»Ÿè®¡ä¿¡æ¯"""
        return {
            'worker_id': self.worker_id,
            'samples_collected': self.samples_collected,
            'episodes_completed': self.episodes_completed,
            'high_level_experiences_generated': self.high_level_experiences_generated,
            'current_skill_timer': self.skill_timer,
            'current_accumulated_reward': self.accumulated_reward,
            'current_team_skill': self.current_team_skill,
            'current_episode_step': self.episode_step
        }

class AgentProxy:
    """ä»£ç†ä»£ç†ï¼Œä¸ºrollout workersæä¾›çº¿ç¨‹å®‰å…¨çš„ä»£ç†æ¥å£"""
    def __init__(self, agent, config, logger, data_buffer=None):
        self.agent = agent
        self.config = config
        self.logger = logger
        self.data_buffer = data_buffer
        self.lock = Lock()
        
        # å…¨å±€rolloutæ­¥æ•°è®¡æ•°å™¨ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°ï¼‰
        self.global_rollout_steps = 0
        self.high_level_experiences_stored = 0
        self.low_level_experiences_stored = 0
        
        # ã€æ–°å¢ã€‘å…¨å±€æŠ€èƒ½å‘¨æœŸç®¡ç†
        self.global_skill_cycle_step = 0  # å…¨å±€æŠ€èƒ½å‘¨æœŸæ­¥æ•°è®¡æ•°å™¨
        self.skill_cycle_length = config.k  # æŠ€èƒ½å‘¨æœŸé•¿åº¦
        self.current_global_team_skill = None  # å½“å‰å…¨å±€å›¢é˜ŸæŠ€èƒ½
        self.current_global_agent_skills = None  # å½“å‰å…¨å±€ä¸ªä½“æŠ€èƒ½
        self.current_global_skill_log_probs = None  # å½“å‰å…¨å±€æŠ€èƒ½log probs
        self.skill_assignment_lock = Lock()  # æŠ€èƒ½åˆ†é…ä¸“ç”¨é”
        
        # é«˜å±‚ç»éªŒæ”¶é›†ç»Ÿè®¡
        self.expected_high_level_experiences = 0  # é¢„æœŸé«˜å±‚ç»éªŒæ•°é‡
        self.actual_high_level_experiences = 0    # å®é™…æ”¶é›†çš„é«˜å±‚ç»éªŒæ•°é‡
    
    def assign_skills_for_worker(self, state, observations, worker_id):
        """ã€é˜¶æ®µ3ä¿®å¤ã€‘ä¸ºç‰¹å®šworkeråˆ†é…æŠ€èƒ½ - æ·»åŠ ç©ºå€¼æ£€æŸ¥å’Œå®‰å…¨å¤„ç†"""
        try:
            # ã€é˜¶æ®µ3ä¿®å¤ã€‘ç¡®ä¿è¾“å…¥æ•°æ®æœ‰æ•ˆ
            if state is None:
                state = np.zeros(self.config.state_dim)
            if observations is None:
                observations = np.zeros((self.config.n_agents, self.config.obs_dim))
            
            # ã€è®¾å¤‡ä¿®å¤ã€‘ç¡®ä¿è¾“å…¥æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            if isinstance(state, np.ndarray):
                state = torch.FloatTensor(state).to(self.agent.device)
            elif isinstance(state, torch.Tensor):
                state = state.to(self.agent.device)
            else:
                # å¤„ç†å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºnumpyå†è½¬tensor
                state = torch.FloatTensor(np.array(state)).to(self.agent.device)
            
            if isinstance(observations, np.ndarray):
                observations = torch.FloatTensor(observations).to(self.agent.device)
            elif isinstance(observations, torch.Tensor):
                observations = observations.to(self.agent.device)
            else:
                # å¤„ç†å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºnumpyå†è½¬tensor
                observations = torch.FloatTensor(np.array(observations)).to(self.agent.device)
            
            # ã€æ–¹æ¡ˆ2æ ¸å¿ƒã€‘æ¯æ¬¡éƒ½é‡æ–°åˆ†é…æŠ€èƒ½ï¼Œç§»é™¤å¤æ‚çš„å…¨å±€åŒæ­¥é€»è¾‘
            team_skill, agent_skills, log_probs = self.agent.assign_skills(
                state, observations, deterministic=False
            )
            
            # ã€å…³é”®ä¿®å¤ã€‘ç¡®ä¿è¿”å›å€¼æ˜¯PythonåŸç”Ÿç±»å‹ï¼Œé¿å…è®¾å¤‡ä¸åŒ¹é…
            if isinstance(team_skill, torch.Tensor):
                team_skill = team_skill.cpu().item()
            if isinstance(agent_skills, torch.Tensor):
                agent_skills = agent_skills.cpu().tolist()
            elif isinstance(agent_skills, list):
                agent_skills = [int(skill.cpu().item()) if isinstance(skill, torch.Tensor) else int(skill) for skill in agent_skills]
            
            # ç¡®ä¿log_probsä¸­çš„å€¼ä¹Ÿæ˜¯PythonåŸç”Ÿç±»å‹
            if log_probs:
                if 'team_log_prob' in log_probs and isinstance(log_probs['team_log_prob'], torch.Tensor):
                    log_probs['team_log_prob'] = log_probs['team_log_prob'].cpu().item()
                if 'agent_log_probs' in log_probs and isinstance(log_probs['agent_log_probs'], torch.Tensor):
                    log_probs['agent_log_probs'] = log_probs['agent_log_probs'].cpu().tolist()
                elif 'agent_log_probs' in log_probs and isinstance(log_probs['agent_log_probs'], list):
                    log_probs['agent_log_probs'] = [
                        prob.cpu().item() if isinstance(prob, torch.Tensor) else float(prob) 
                        for prob in log_probs['agent_log_probs']
                    ]
            
            self.logger.debug(f"Worker {worker_id}: æŠ€èƒ½åˆ†é…å®Œæˆ - "
                            f"team_skill={team_skill}, agent_skills={agent_skills}")
            
            return team_skill, agent_skills, log_probs
            
        except Exception as e:
            self.logger.error(f"Worker {worker_id}: æŠ€èƒ½åˆ†é…å¤±è´¥: {e}")
            import traceback
            self.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            # è¿”å›é»˜è®¤æŠ€èƒ½
            return 0, [0] * self.config.n_agents, {
                'team_log_prob': 0.0, 
                'agent_log_probs': [0.0] * self.config.n_agents
            }
    
    def should_reassign_global_skills(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ†é…å…¨å±€æŠ€èƒ½"""
        # åˆæ¬¡åˆ†é…æˆ–è¾¾åˆ°æŠ€èƒ½å‘¨æœŸé•¿åº¦æ—¶é‡åˆ†é…
        return (self.current_global_team_skill is None or 
                self.global_skill_cycle_step >= self.skill_cycle_length)
    
    def get_global_skill_cycle_info(self):
        """è·å–å…¨å±€æŠ€èƒ½å‘¨æœŸä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        return {
            'global_skill_cycle_step': self.global_skill_cycle_step,
            'skill_cycle_length': self.skill_cycle_length,
            'current_global_team_skill': self.current_global_team_skill,
            'current_global_agent_skills': self.current_global_agent_skills,
            'should_reassign': self.should_reassign_global_skills()
        }
    
    def get_actions_for_worker(self, state, observations, agent_skills, worker_id):
        """ã€é˜¶æ®µ3ä¿®å¤ã€‘ä¸ºç‰¹å®šworkerè·å–åŠ¨ä½œ - æ·»åŠ ç©ºå€¼æ£€æŸ¥å’Œå®‰å…¨å¤„ç†"""
        with self.lock:
            try:
                # ã€é˜¶æ®µ3ä¿®å¤ã€‘ç¡®ä¿è¾“å…¥æ•°æ®æœ‰æ•ˆ
                if observations is None:
                    observations = np.zeros((self.config.n_agents, self.config.obs_dim))
                if agent_skills is None:
                    agent_skills = [0] * self.config.n_agents
                
                # ã€è®¾å¤‡ä¿®å¤ã€‘ç¡®ä¿è¾“å…¥æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                if isinstance(observations, np.ndarray):
                    observations = torch.FloatTensor(observations).to(self.agent.device)
                elif isinstance(observations, torch.Tensor):
                    observations = observations.to(self.agent.device)
                else:
                    # å¤„ç†å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºnumpyå†è½¬tensor
                    observations = torch.FloatTensor(np.array(observations)).to(self.agent.device)
                
                # ã€å…³é”®ä¿®å¤ã€‘ç¡®ä¿agent_skillsæ˜¯æ­£ç¡®çš„è®¾å¤‡å’Œç±»å‹
                if isinstance(agent_skills, np.ndarray):
                    agent_skills = torch.tensor(agent_skills, dtype=torch.long, device=self.agent.device)
                elif isinstance(agent_skills, list):
                    agent_skills = torch.tensor(agent_skills, dtype=torch.long, device=self.agent.device)
                elif isinstance(agent_skills, torch.Tensor):
                    agent_skills = agent_skills.to(device=self.agent.device, dtype=torch.long)
                else:
                    # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºlistå†è½¬tensor
                    agent_skills = torch.tensor([int(skill) for skill in agent_skills], dtype=torch.long, device=self.agent.device)
                
                actions, action_logprobs = self.agent.select_action(
                    observations, agent_skills, deterministic=False, env_id=worker_id
                )
                
                # ã€å…³é”®ä¿®å¤ã€‘ç¡®ä¿è¿”å›çš„actionså’Œaction_logprobsæ˜¯numpyæ•°ç»„ï¼Œé¿å…è®¾å¤‡ä¸åŒ¹é…
                if isinstance(actions, torch.Tensor):
                    actions = actions.cpu().detach().numpy()
                if isinstance(action_logprobs, torch.Tensor):
                    action_logprobs = action_logprobs.cpu().detach().numpy()
                
                return actions, action_logprobs
                
            except Exception as e:
                self.logger.error(f"Worker {worker_id}: è·å–åŠ¨ä½œå¤±è´¥: {e}")
                import traceback
                self.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                
                # è¿”å›éšæœºåŠ¨ä½œä½œä¸ºå›é€€
                try:
                    n_agents = len(observations) if hasattr(observations, '__len__') else self.config.n_agents
                    random_actions = np.random.randn(n_agents, self.config.action_dim)
                    return random_actions, np.zeros(n_agents)
                except Exception as fallback_error:
                    self.logger.error(f"Worker {worker_id}: å›é€€åŠ¨ä½œç”Ÿæˆä¹Ÿå¤±è´¥: {fallback_error}")
                    # æœ€åçš„å®‰å…¨å›é€€
                    return np.random.randn(self.config.n_agents, self.config.action_dim), np.zeros(self.config.n_agents)
    
    def store_experience(self, experience_batch):
        """æ‰¹é‡å­˜å‚¨ç»éªŒåˆ°ä»£ç† - ä¿®å¤ç‰ˆæœ¬ï¼šç¡®ä¿æ­¥æ•°è®¡æ•°ç»Ÿä¸€"""
        with self.lock:
            # ã€æ–°å¢è°ƒè¯•ã€‘è®°å½•æ‰¹å¤„ç†å¼€å§‹æ—¶çš„çŠ¶æ€
            pre_global_steps = self.global_rollout_steps
            
            stored_count = 0
            low_level_stored = 0
            high_level_stored = 0
            low_level_failed = 0
            high_level_failed = 0
            
            for experience in experience_batch:
                try:
                    worker_id = experience['worker_id']
                    experience_type = experience.get('experience_type', 'low_level')
                    
                    if experience_type == 'high_level':
                        # å­˜å‚¨é«˜å±‚ç»éªŒ
                        success = self.store_high_level_experience(experience)
                        if success:
                            self.high_level_experiences_stored += 1
                            high_level_stored += 1
                            stored_count += 1
                            self.logger.debug(f"Worker {worker_id}: é«˜å±‚ç»éªŒå·²å­˜å‚¨åˆ°ä»£ç† - "
                                            f"ç´¯ç§¯å¥–åŠ±={experience['accumulated_reward']:.4f}")
                        else:
                            high_level_failed += 1
                            self.logger.warning(f"Worker {worker_id}: é«˜å±‚ç»éªŒå­˜å‚¨å¤±è´¥")
                    
                    elif experience_type == 'low_level':
                        # å­˜å‚¨ä½å±‚ç»éªŒ
                        success = self.store_low_level_experience(experience)
                        if success:
                            self.low_level_experiences_stored += 1
                            low_level_stored += 1
                            stored_count += 1
                            # ã€å…³é”®ä¿®å¤ã€‘æ¯ä¸ªæˆåŠŸçš„ä½å±‚ç»éªŒå¯¹åº”ä¸€ä¸ªç¯å¢ƒæ­¥éª¤
                            self.global_rollout_steps += 1
                            
                            # ã€æ–°å¢è°ƒè¯•ã€‘è®°å½•æ¯ä¸ªä½å±‚ç»éªŒçš„æ­¥æ•°å¢åŠ 
                            if low_level_stored <= 5 or low_level_stored % 50 == 0:  # è®°å½•å‰5ä¸ªå’Œæ¯50ä¸ª
                                self.logger.debug(f"ğŸ”¢ [STEP_TRACE] W{worker_id} ä½å±‚ç»éªŒ#{low_level_stored} å­˜å‚¨æˆåŠŸ, "
                                                f"global_rollout_steps: {self.global_rollout_steps-1}â†’{self.global_rollout_steps}")
                        else:
                            low_level_failed += 1
                            self.logger.warning(f"Worker {worker_id}: ä½å±‚ç»éªŒå­˜å‚¨å¤±è´¥")
                    
                    elif experience_type == 'state_skill':
                        # ã€æ–¹æ¡ˆ2æ–°å¢ã€‘å­˜å‚¨StateSkillDatasetæ•°æ®
                        success = self.store_state_skill_data(experience)
                        if success:
                            stored_count += 1
                            self.logger.debug(f"Worker {worker_id}: StateSkillæ•°æ®å·²å­˜å‚¨åˆ°ä»£ç†")
                        else:
                            self.logger.warning(f"Worker {worker_id}: StateSkillæ•°æ®å­˜å‚¨å¤±è´¥")
                    
                    else:
                        self.logger.warning(f"æœªçŸ¥ç»éªŒç±»å‹: {experience_type}")
                    
                except Exception as e:
                    self.logger.error(f"å­˜å‚¨ç»éªŒå¤±è´¥: {e}")
            
            # ã€å…³é”®ä¿®å¤ã€‘åŒæ­¥ä»£ç†çš„æ­¥æ•°è®¡æ•°å™¨
            old_steps = self.agent.steps_collected
            self.agent.steps_collected = self.global_rollout_steps
            
            # ã€æ–°å¢è°ƒè¯•ã€‘è®°å½•æ‰¹å¤„ç†ç»“æŸæ—¶çš„è¯¦ç»†çŠ¶æ€
            post_global_steps = self.global_rollout_steps
            steps_increment = post_global_steps - pre_global_steps
            
            if low_level_stored > 0:  # åªåœ¨æœ‰ä½å±‚ç»éªŒæ—¶è®°å½•
                self.logger.debug(f"ğŸ“¦ [BATCH_TRACE] æ‰¹å¤„ç†å®Œæˆ: æ‰¹æ¬¡å¤§å°={len(experience_batch)}, "
                               f"ä½å±‚æˆåŠŸ={low_level_stored}, é«˜å±‚æˆåŠŸ={high_level_stored}, "
                               f"global_rollout_steps: {pre_global_steps}â†’{post_global_steps} (+{steps_increment})")
                
                # éªŒè¯æ­¥æ•°å¢é‡ä¸ä½å±‚ç»éªŒæ•°é‡çš„ä¸€è‡´æ€§
                if steps_increment != low_level_stored:
                    self.logger.warning(f"âš ï¸ [STEP_MISMATCH] æ­¥æ•°å¢é‡ä¸ä½å±‚ç»éªŒä¸åŒ¹é…: "
                                      f"å¢é‡={steps_increment}, ä½å±‚ç»éªŒ={low_level_stored}")
            
            return stored_count
    
    def store_high_level_experience(self, experience):
        """å­˜å‚¨é«˜å±‚ç»éªŒåˆ°ä»£ç† - ä¿®å¤ç‰ˆæœ¬ï¼šæ·»åŠ åŸå­æ€§éªŒè¯å’Œé‡è¯•æœºåˆ¶"""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # è®°å½•å­˜å‚¨å‰çš„ç¼“å†²åŒºå¤§å°
                buffer_size_before = len(self.agent.high_level_buffer) if hasattr(self.agent, 'high_level_buffer') else 0
                
                # è°ƒç”¨ä»£ç†çš„é«˜å±‚ç»éªŒå­˜å‚¨æ–¹æ³•
                success = self.agent.store_high_level_transition(
                    state=experience['state'],
                    team_skill=experience['team_skill'],
                    observations=experience['observations'],
                    agent_skills=experience['agent_skills'],
                    accumulated_reward=experience['accumulated_reward'],
                    skill_log_probs=experience['skill_log_probs'],
                    worker_id=experience['worker_id']
                )
                
                if success:
                    # éªŒè¯ç¼“å†²åŒºç¡®å®å¢åŠ äº†
                    buffer_size_after = len(self.agent.high_level_buffer) if hasattr(self.agent, 'high_level_buffer') else 0
                    if buffer_size_after > buffer_size_before:
                        return True
                    else:
                        self.logger.warning(f"é«˜å±‚ç»éªŒå­˜å‚¨è¿”å›æˆåŠŸä½†ç¼“å†²åŒºæœªå¢åŠ : {buffer_size_before}â†’{buffer_size_after}")
                        success = False
                
                # å¦‚æœå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•
                if not success:
                    retry_count += 1
                    if retry_count < max_retries:
                        self.logger.warning(f"é«˜å±‚ç»éªŒå­˜å‚¨å¤±è´¥ï¼Œé‡è¯• {retry_count}/{max_retries}")
                        time.sleep(0.01)  # çŸ­æš‚ç­‰å¾…
                    continue
                else:
                    return True
                    
            except Exception as e:
                retry_count += 1
                if retry_count < max_retries:
                    self.logger.error(f"å­˜å‚¨é«˜å±‚ç»éªŒå¼‚å¸¸ï¼Œé‡è¯• {retry_count}/{max_retries}: {e}")
                    time.sleep(0.01)
                else:
                    self.logger.error(f"å­˜å‚¨é«˜å±‚ç»éªŒæœ€ç»ˆå¤±è´¥: {e}")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        return False
    
    def store_low_level_experience(self, experience):
        """å­˜å‚¨ä½å±‚ç»éªŒåˆ°ä»£ç† - ä¿®å¤ç‰ˆæœ¬ï¼šæ·»åŠ åŸå­æ€§éªŒè¯å’Œé‡è¯•æœºåˆ¶"""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # è®°å½•å­˜å‚¨å‰çš„ç¼“å†²åŒºå¤§å°
                buffer_size_before = len(self.agent.low_level_buffer) if hasattr(self.agent, 'low_level_buffer') else 0
                
                # è°ƒç”¨ä»£ç†çš„ä½å±‚ç»éªŒå­˜å‚¨æ–¹æ³•
                success = self.agent.store_low_level_transition(
                    state=experience['state'],
                    next_state=experience['next_state'],
                    observations=experience['observations'],
                    next_observations=experience['next_observations'],
                    actions=experience['actions'],
                    rewards=experience['rewards'],
                    dones=experience['dones'],
                    team_skill=experience['team_skill'],
                    agent_skills=experience['agent_skills'],
                    action_logprobs=experience['action_logprobs'],
                    skill_log_probs=experience['skill_log_probs'],
                    worker_id=experience['worker_id']
                )
                
                if success:
                    # éªŒè¯ç¼“å†²åŒºç¡®å®å¢åŠ äº†
                    buffer_size_after = len(self.agent.low_level_buffer) if hasattr(self.agent, 'low_level_buffer') else 0
                    if buffer_size_after > buffer_size_before:
                        return True
                    else:
                        self.logger.warning(f"ä½å±‚ç»éªŒå­˜å‚¨è¿”å›æˆåŠŸä½†ç¼“å†²åŒºæœªå¢åŠ : {buffer_size_before}â†’{buffer_size_after}")
                        success = False
                
                # å¦‚æœå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•
                if not success:
                    retry_count += 1
                    if retry_count < max_retries:
                        self.logger.warning(f"ä½å±‚ç»éªŒå­˜å‚¨å¤±è´¥ï¼Œé‡è¯• {retry_count}/{max_retries}")
                        time.sleep(0.01)  # çŸ­æš‚ç­‰å¾…
                    continue
                else:
                    return True
                    
            except Exception as e:
                retry_count += 1
                if retry_count < max_retries:
                    self.logger.error(f"å­˜å‚¨ä½å±‚ç»éªŒå¼‚å¸¸ï¼Œé‡è¯• {retry_count}/{max_retries}: {e}")
                    time.sleep(0.01)
                else:
                    self.logger.error(f"å­˜å‚¨ä½å±‚ç»éªŒæœ€ç»ˆå¤±è´¥: {e}")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        return False
    
    def store_state_skill_data(self, experience):
        """å­˜å‚¨StateSkillDatasetæ•°æ®åˆ°ä»£ç†ï¼ˆæ–¹æ¡ˆ2æ–°å¢ï¼‰"""
        try:
            # ç›´æ¥å­˜å‚¨åˆ°ä»£ç†çš„state_skill_dataset
            state_tensor = torch.FloatTensor(experience['state']).to(self.agent.device)
            team_skill_tensor = torch.tensor(experience['team_skill'], device=self.agent.device)
            observations_tensor = torch.FloatTensor(experience['observations']).to(self.agent.device)
            agent_skills_tensor = torch.tensor(experience['agent_skills'], device=self.agent.device)
            
            self.agent.state_skill_dataset.push(
                state_tensor,
                team_skill_tensor,
                observations_tensor,
                agent_skills_tensor
            )
            return True
        except Exception as e:
            self.logger.error(f"å­˜å‚¨StateSkillæ•°æ®å¤±è´¥: {e}")
            return False
    
    def should_update(self):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ›´æ–° - é˜¶æ®µ2å¢å¼ºç‰ˆæœ¬ï¼šå¼ºå¥çš„æ•°æ®ä¼ è¾“éªŒè¯"""
        with self.lock:
            # å¦‚æœæ²¡æœ‰rollout_workerså¼•ç”¨ï¼Œä½¿ç”¨å›é€€é€»è¾‘
            if not hasattr(self, 'rollout_workers'):
                self.agent.steps_collected = self.global_rollout_steps
                return self.agent.should_rollout_update()
            
            # åŸºæœ¬æ¡ä»¶æ£€æŸ¥
            completed_workers = sum(1 for worker in self.rollout_workers 
                                  if getattr(worker, 'rollout_completed', False))
            total_workers = len(self.rollout_workers)
            
            total_collected = sum(worker.samples_collected for worker in self.rollout_workers)
            target_steps = self.rollout_workers[0].target_rollout_steps * total_workers
            
            # åŸºæœ¬çš„å®Œæˆæ¡ä»¶
            all_workers_completed = completed_workers == total_workers
            steps_collected = total_collected >= target_steps
            
            # ç®€åŒ–çš„æ›´æ–°åˆ¤æ–­
            should_update = all_workers_completed and steps_collected
            
            # è¿›åº¦è®°å½•ï¼ˆå‡å°‘é¢‘ç‡ï¼‰
            if not hasattr(self, '_update_check_count'):
                self._update_check_count = 0
            self._update_check_count += 1
            
            if self._update_check_count % 100 == 0:  # å‡å°‘æ—¥å¿—é¢‘ç‡
                progress_pct = (total_collected / target_steps) * 100 if target_steps > 0 else 0
                self.logger.debug(f"â³ ç­‰å¾…æ•°æ®æ”¶é›†: "
                               f"è¿›åº¦={progress_pct:.1f}% ({total_collected}/{target_steps}), "
                               f"å®Œæˆworkers={completed_workers}/{total_workers}")
            
            if should_update:
                self.logger.info(f"ğŸ”„ æ»¡è¶³æ›´æ–°æ¡ä»¶: æ‰€æœ‰workerså®Œæˆä¸”æ­¥æ•°è¾¾æ ‡ "
                               f"({total_collected}/{target_steps})")
                # ã€é˜¶æ®µ2æ ¸å¿ƒã€‘ä½¿ç”¨å¢å¼ºçš„æ•°æ®ä¼ è¾“éªŒè¯
                return self._verify_data_transmission_integrity(total_collected)
            
            return False
    
    def _verify_data_transmission_integrity(self, expected_steps):
        """ã€é˜¶æ®µ2æ ¸å¿ƒã€‘å¢å¼ºçš„æ•°æ®ä¼ è¾“å®Œæ•´æ€§éªŒè¯ - æ¸è¿›å¼ç­‰å¾… + æ‰¹é‡éªŒè¯"""
        self.logger.info(f"ğŸ” [é˜¶æ®µ2] å¼€å§‹å¢å¼ºæ•°æ®ä¼ è¾“éªŒè¯: æœŸæœ›æ­¥æ•°={expected_steps}")
        
        # ã€æ¸è¿›å¼ç­‰å¾…ç­–ç•¥ã€‘å…ˆå¿«é€Ÿæ£€æŸ¥ï¼Œç„¶åé€æ­¥å¢åŠ ç­‰å¾…æ—¶é—´
        wait_phases = [
            (1.0, "å¿«é€Ÿæ£€æŸ¥"),      # 1ç§’å¿«é€Ÿæ£€æŸ¥
            (5.0, "çŸ­æœŸç­‰å¾…"),      # 5ç§’çŸ­æœŸç­‰å¾…
            (10.0, "ä¸­æœŸç­‰å¾…"),     # 10ç§’ä¸­æœŸç­‰å¾…
            (20.0, "é•¿æœŸç­‰å¾…")      # 20ç§’é•¿æœŸç­‰å¾…
        ]
        
        verification_start = time.time()
        
        for phase_time, phase_name in wait_phases:
            phase_start = time.time()
            self.logger.debug(f"ğŸ” [éªŒè¯é˜¶æ®µ] {phase_name}: æœ€å¤§ç­‰å¾…{phase_time}ç§’")
            
            # ç­‰å¾…é˜Ÿåˆ—å¤„ç†
            success = self._wait_for_queue_processing(phase_time, phase_name)
            if not success:
                self.logger.warning(f"âš ï¸ [éªŒè¯é˜¶æ®µ] {phase_name}: é˜Ÿåˆ—å¤„ç†è¶…æ—¶")
                continue  # è¿›å…¥ä¸‹ä¸€ä¸ªç­‰å¾…é˜¶æ®µ
            
            # æ‰¹é‡éªŒè¯æ•°æ®å®Œæ•´æ€§
            verification_result = self._batch_verify_data_integrity(expected_steps)
            
            phase_duration = time.time() - phase_start
            
            if verification_result['success']:
                total_duration = time.time() - verification_start
                self.logger.info(f"âœ… [é˜¶æ®µ2] æ•°æ®éªŒè¯æˆåŠŸ: {phase_name}å®Œæˆ, "
                               f"é˜¶æ®µç”¨æ—¶={phase_duration:.2f}s, æ€»ç”¨æ—¶={total_duration:.2f}s")
                self._sync_step_counters(expected_steps)
                return True
            else:
                missing_info = verification_result.get('missing_info', {})
                self.logger.warning(f"âš ï¸ [éªŒè¯é˜¶æ®µ] {phase_name}: æ•°æ®ä»ç¼ºå¤± - "
                                  f"ä½å±‚ç¼ºå¤±={missing_info.get('low_level_missing', 0)}, "
                                  f"é«˜å±‚ç¼ºå¤±={missing_info.get('high_level_missing', 0)}")
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªé˜¶æ®µï¼Œç»§ç»­ç­‰å¾…
                if phase_name != "é•¿æœŸç­‰å¾…":
                    continue
        
        # æ‰€æœ‰é˜¶æ®µéƒ½å¤±è´¥ï¼Œä½†è¿›è¡Œæ™ºèƒ½å®¹é”™å¤„ç†
        return self._intelligent_fallback_handling(expected_steps, verification_result)
    
    def _wait_for_queue_processing(self, max_wait_time, phase_name):
        """ã€é˜¶æ®µ2è¾…åŠ©ã€‘ç­‰å¾…é˜Ÿåˆ—å¤„ç†å®Œæˆ"""
        if self.data_buffer is None:
            return True
        
        wait_start = time.time()
        initial_queue_size = self.data_buffer.qsize()
        
        # ã€ä¼˜åŒ–ã€‘åªåœ¨é˜Ÿåˆ—è¾ƒå¤§æ—¶æ‰ç­‰å¾…
        if initial_queue_size <= 50:
            self.logger.debug(f"ğŸ” [{phase_name}] é˜Ÿåˆ—è¾ƒå°({initial_queue_size})ï¼Œæ— éœ€ç­‰å¾…")
            return True
        
        self.logger.debug(f"ğŸ” [{phase_name}] ç­‰å¾…é˜Ÿåˆ—å¤„ç†: åˆå§‹å¤§å°={initial_queue_size}")
        
        last_size = initial_queue_size
        stale_count = 0  # é˜Ÿåˆ—å¤§å°æœªå˜åŒ–çš„è®¡æ•°
        
        while time.time() - wait_start < max_wait_time:
            current_size = self.data_buffer.qsize()
            
            # ã€æ™ºèƒ½æ£€æµ‹ã€‘å¦‚æœé˜Ÿåˆ—å¤§å°åœ¨å‡å°‘ï¼Œè¯´æ˜æ­£åœ¨å¤„ç†
            if current_size < last_size:
                stale_count = 0  # é‡ç½®åœæ»è®¡æ•°
                last_size = current_size
            else:
                stale_count += 1
            
            # ã€æå‰é€€å‡ºæ¡ä»¶ã€‘
            if current_size <= 20:  # é˜Ÿåˆ—åŸºæœ¬æ¸…ç©º
                break
            if stale_count >= 10 and current_size < initial_queue_size * 0.5:  # é˜Ÿåˆ—å‡å°‘äº†ä¸€åŠä¸”åœæ»
                self.logger.debug(f"ğŸ” [{phase_name}] é˜Ÿåˆ—å¤„ç†åœæ»ä½†å·²å‡å°‘50%ï¼Œç»§ç»­éªŒè¯")
                break
            
            time.sleep(0.5)
        
        final_size = self.data_buffer.qsize()
        wait_duration = time.time() - wait_start
        
        # ã€æˆåŠŸæ¡ä»¶ã€‘é˜Ÿåˆ—å¤§å°æ˜¾è‘—å‡å°‘æˆ–åŸºæœ¬æ¸…ç©º
        reduction_rate = (initial_queue_size - final_size) / initial_queue_size if initial_queue_size > 0 else 1.0
        success = final_size <= 20 or reduction_rate >= 0.7  # é˜Ÿåˆ—æ¸…ç©ºæˆ–å‡å°‘70%ä»¥ä¸Š
        
        if success:
            self.logger.debug(f"âœ… [{phase_name}] é˜Ÿåˆ—å¤„ç†å®Œæˆ: {initial_queue_size}â†’{final_size}, "
                            f"å‡å°‘={reduction_rate:.1%}, ç”¨æ—¶={wait_duration:.2f}s")
        else:
            self.logger.warning(f"âš ï¸ [{phase_name}] é˜Ÿåˆ—å¤„ç†ä¸ç†æƒ³: {initial_queue_size}â†’{final_size}, "
                              f"å‡å°‘={reduction_rate:.1%}, ç”¨æ—¶={wait_duration:.2f}s")
        
        return success
    
    def _batch_verify_data_integrity(self, expected_steps):
        """ã€é˜¶æ®µ2è¾…åŠ©ã€‘æ‰¹é‡éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        verification_result = {
            'success': False,
            'missing_info': {},
            'details': {}
        }
        
        try:
            # è·å–å½“å‰ç¼“å†²åŒºçŠ¶æ€
            current_bl_size = len(self.agent.low_level_buffer) if hasattr(self.agent, 'low_level_buffer') else 0
            current_bh_size = len(self.agent.high_level_buffer) if hasattr(self.agent, 'high_level_buffer') else 0
            
            # è®¡ç®—æœŸæœ›çš„æ•°æ®é‡
            expected_low_level = expected_steps
            expected_high_level = expected_steps // self.config.k  # æ¯kæ­¥ä¸€ä¸ªé«˜å±‚ç»éªŒ
            
            # è®¡ç®—ç¼ºå¤±é‡
            low_level_missing = max(0, expected_low_level - current_bl_size)
            high_level_missing = max(0, expected_high_level - current_bh_size)
            
            # ã€æ™ºèƒ½å®¹é”™ã€‘è®¡ç®—ç¼ºå¤±ç‡
            low_level_missing_rate = low_level_missing / expected_low_level if expected_low_level > 0 else 0
            high_level_missing_rate = high_level_missing / expected_high_level if expected_high_level > 0 else 0
            
            verification_result['missing_info'] = {
                'low_level_missing': low_level_missing,
                'high_level_missing': high_level_missing,
                'low_level_missing_rate': low_level_missing_rate,
                'high_level_missing_rate': high_level_missing_rate,
                'current_bl_size': current_bl_size,
                'current_bh_size': current_bh_size,
                'expected_low_level': expected_low_level,
                'expected_high_level': expected_high_level
            }
            
            # ã€é˜¶æ®µ2æ ‡å‡†ã€‘å…è®¸å°å¹…ç¼ºå¤±ä½†è¦è®°å½•è¯¦ç»†ä¿¡æ¯
            acceptable_missing_rate = 0.02  # å…è®¸2%çš„ç¼ºå¤±ç‡
            
            low_level_acceptable = low_level_missing_rate <= acceptable_missing_rate
            high_level_acceptable = high_level_missing_rate <= acceptable_missing_rate
            
            # è®°å½•è¯¦ç»†éªŒè¯ä¿¡æ¯
            self.logger.warning(f"ğŸ” [AGENT_DATA_WAIT] æ•°æ®ä¼ è¾“éªŒè¯è¶…æ—¶:")
            self.logger.warning(f"   ä½å±‚: {current_bl_size}/{expected_low_level} (ç¼ºå¤±: {low_level_missing})")
            self.logger.warning(f"   é«˜å±‚: {current_bh_size}/{expected_high_level} (ç¼ºå¤±: {high_level_missing})")
            
            if low_level_acceptable and high_level_acceptable:
                self.logger.info(f"âœ… [é˜¶æ®µ2] æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡: "
                               f"ä½å±‚ç¼ºå¤±ç‡={low_level_missing_rate:.1%}, é«˜å±‚ç¼ºå¤±ç‡={high_level_missing_rate:.1%}")
                verification_result['success'] = True
            else:
                total_missing = low_level_missing + high_level_missing
                total_expected = expected_low_level + expected_high_level
                overall_missing_rate = total_missing / total_expected if total_expected > 0 else 0
                
                if overall_missing_rate <= 0.006:  # æ€»ä½“ç¼ºå¤±ç‡å°äº0.6%
                    self.logger.warning(f"âš ï¸ [AGENT_DATA_WAIT] æ•°æ®è½»å¾®ç¼ºå¤±({overall_missing_rate:.1%})ï¼Œåº”è¯¥ä¿®å¤")
                    verification_result['success'] = True  # è½»å¾®ç¼ºå¤±ä»ç„¶æ¥å—
                else:
                    self.logger.error(f"âŒ [é˜¶æ®µ2] æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: "
                                    f"ä½å±‚ç¼ºå¤±ç‡={low_level_missing_rate:.1%}, é«˜å±‚ç¼ºå¤±ç‡={high_level_missing_rate:.1%}")
            
            # è®°å½•ç¼“å†²åŒºè¯¦ç»†çŠ¶æ€ç”¨äºè°ƒè¯•
            self.logger.warning(f"[ROLLOUT_BUFFER_DEBUG] æ›´æ–°å‰ç¼“å†²åŒºè¯¦ç»†çŠ¶æ€:")
            self.logger.warning(f"   - B_h (é«˜å±‚): {current_bh_size} (ç›®æ ‡: {expected_high_level})")
            self.logger.warning(f"   - B_l (ä½å±‚): {current_bl_size} (ç›®æ ‡: {expected_low_level})")
            if hasattr(self.agent, 'state_skill_dataset'):
                d_size = len(self.agent.state_skill_dataset)
                self.logger.warning(f"   - D (åˆ¤åˆ«å™¨): {d_size}")
            
        except Exception as e:
            self.logger.error(f"âŒ [é˜¶æ®µ2] æ•°æ®å®Œæ•´æ€§éªŒè¯å¼‚å¸¸: {e}")
            verification_result['success'] = False
        
        return verification_result
    
    def _intelligent_fallback_handling(self, expected_steps, last_verification_result):
        """ã€é˜¶æ®µ2è¾…åŠ©ã€‘æ™ºèƒ½å›é€€å¤„ç† - å½“æ‰€æœ‰éªŒè¯é˜¶æ®µéƒ½å¤±è´¥æ—¶"""
        missing_info = last_verification_result.get('missing_info', {})
        
        self.logger.warning(f"âš ï¸ [é˜¶æ®µ2] æ‰€æœ‰éªŒè¯é˜¶æ®µå¤±è´¥ï¼Œå¯åŠ¨æ™ºèƒ½å›é€€å¤„ç†")
        
        # å°è¯•æ•°æ®ä¿®å¤
        repair_success = self._attempt_data_repair(missing_info)
        
        if repair_success:
            self.logger.info(f"âœ… [é˜¶æ®µ2] æ•°æ®ä¿®å¤æˆåŠŸï¼Œå…è®¸ç»§ç»­è®­ç»ƒ")
            self._sync_step_counters(expected_steps)
            return True
        
        # å¦‚æœä¿®å¤å¤±è´¥ï¼Œè¯„ä¼°æ˜¯å¦å¯ä»¥å®¹å¿
        total_missing_rate = (missing_info.get('low_level_missing', 0) + missing_info.get('high_level_missing', 0)) / expected_steps
        
        if total_missing_rate <= 0.05:  # æ€»ç¼ºå¤±ç‡å°äº5%
            self.logger.warning(f"âš ï¸ [é˜¶æ®µ2] æ•°æ®ä¿®å¤å¤±è´¥ï¼Œä½†ç¼ºå¤±ç‡å¯æ¥å—({total_missing_rate:.1%})ï¼Œç»§ç»­è®­ç»ƒ")
            self._sync_step_counters(expected_steps)
            return True
        else:
            self.logger.error(f"âŒ [é˜¶æ®µ2] æ•°æ®ç¼ºå¤±è¿‡å¤š({total_missing_rate:.1%})ï¼Œæ‹’ç»è®­ç»ƒæ›´æ–°")
            return False
    
    def _attempt_data_repair(self, missing_info):
        """ã€é˜¶æ®µ2è¾…åŠ©ã€‘å°è¯•ä¿®å¤ç¼ºå¤±çš„æ•°æ®"""
        repaired = 0
        
        try:
            # ä¿®å¤ç¼ºå¤±çš„é«˜å±‚ç»éªŒ
            high_level_missing = missing_info.get('high_level_missing', 0)
            if high_level_missing > 0:
                self.logger.info(f"ğŸ”§ [é˜¶æ®µ2] å°è¯•ä¿®å¤ {high_level_missing} ä¸ªç¼ºå¤±çš„é«˜å±‚ç»éªŒ")
                high_level_repaired = self._repair_missing_high_level_experiences(high_level_missing)
                repaired += high_level_repaired
                self.logger.info(f"ğŸ”§ [é˜¶æ®µ2] é«˜å±‚ç»éªŒä¿®å¤å®Œæˆ: {high_level_repaired}/{high_level_missing}")
            
            # æ³¨æ„ï¼šä½å±‚ç»éªŒé€šå¸¸ä¸éœ€è¦ä¿®å¤ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å®é™…çš„ç¯å¢ƒäº¤äº’ç»“æœ
            
            return repaired > 0
            
        except Exception as e:
            self.logger.error(f"âŒ [é˜¶æ®µ2] æ•°æ®ä¿®å¤è¿‡ç¨‹å¼‚å¸¸: {e}")
            return False
    
    def _repair_missing_high_level_experiences(self, missing_count):
        """ã€æ–¹æ¡ˆCè¾…åŠ©ã€‘ä¿®å¤ç¼ºå¤±çš„é«˜å±‚ç»éªŒ"""
        repaired = 0
        
        try:
            # æ‰¾åˆ°è´¡çŒ®é«˜å±‚ç»éªŒæœ€å°‘çš„workers
            worker_contributions = {}
            for worker in self.rollout_workers:
                worker_contributions[worker.worker_id] = worker.high_level_experiences_generated
            
            # æŒ‰è´¡çŒ®æ•°é‡æ’åºï¼Œä¼˜å…ˆä¿®å¤è´¡çŒ®æœ€å°‘çš„
            sorted_workers = sorted(worker_contributions.items(), key=lambda x: x[1])
            
            for worker_id, contribution in sorted_workers:
                if repaired >= missing_count:
                    break
                
                expected_contribution = 4  # æ¯ä¸ªworkeråº”è¯¥è´¡çŒ®4ä¸ªé«˜å±‚ç»éªŒ
                if contribution < expected_contribution:
                    worker = self.rollout_workers[worker_id]
                    
                    # ä¸ºè¿™ä¸ªworkeråˆ›å»ºç¼ºå¤±çš„é«˜å±‚ç»éªŒ
                    missing_for_worker = expected_contribution - contribution
                    for i in range(min(missing_for_worker, missing_count - repaired)):
                        success = self.create_forced_high_level_experience(worker, f"ä¼ è¾“ä¿®å¤#{i}")
                        if success:
                            repaired += 1
                            self.logger.info(f"ğŸ”§ [æ–¹æ¡ˆC] ä¸ºWorker {worker_id} ä¿®å¤é«˜å±‚ç»éªŒ #{i}")
                        else:
                            self.logger.warning(f"âš ï¸ [æ–¹æ¡ˆC] Worker {worker_id} é«˜å±‚ç»éªŒä¿®å¤å¤±è´¥")
                            break
            
        except Exception as e:
            self.logger.error(f"âŒ [æ–¹æ¡ˆC] é«˜å±‚ç»éªŒä¿®å¤è¿‡ç¨‹å¼‚å¸¸: {e}")
        
        return repaired
    
    def _sync_step_counters(self, total_collected):
        """ã€æ–¹æ¡ˆBè¾…åŠ©ã€‘åŒæ­¥æ­¥æ•°è®¡æ•°å™¨ï¼Œç¡®ä¿ä¸€è‡´æ€§"""
        old_agent_steps = self.agent.steps_collected
        old_global_steps = self.global_rollout_steps
        
        # ä½¿ç”¨æœ€å‡†ç¡®çš„workeræ€»å’Œä½œä¸ºåŸºå‡†
        self.agent.steps_collected = total_collected
        self.global_rollout_steps = total_collected
        
        # éªŒè¯åŒæ­¥ç»“æœ
        if abs(old_global_steps - total_collected) > 50:  # åªåœ¨å·®å¼‚è¾ƒå¤§æ—¶è®°å½•
            self.logger.debug(f"ğŸ”„ [æ–¹æ¡ˆB] æ­¥æ•°åŒæ­¥: "
                            f"agent: {old_agent_steps}â†’{self.agent.steps_collected}, "
                            f"global: {old_global_steps}â†’{self.global_rollout_steps}, "
                            f"workers: {total_collected}")
    
    def update(self):
        """æ‰§è¡Œæ¨¡å‹æ›´æ–° - æ–¹æ¡ˆBå¢å¼ºç‰ˆï¼šé«˜æ•ˆéªŒè¯ + æ•°æ®å®Œæ•´æ€§ä¿éšœ"""
        with self.lock:
            try:
                # ã€æ–¹æ¡ˆBæ­¥éª¤1ã€‘æœ€åçš„æ•°æ®å®Œæ•´æ€§éªŒè¯
                if not self._verify_data_integrity_before_update():
                    self.logger.warning("âš ï¸ [æ–¹æ¡ˆB] æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¿®å¤...")
                    self._emergency_data_repair()
                
                # ã€æ–¹æ¡ˆBæ­¥éª¤2ã€‘æ‰§è¡Œæ¨¡å‹æ›´æ–°
                self.logger.info("ğŸš€ [æ–¹æ¡ˆB] å¼€å§‹æ¨¡å‹æ›´æ–°...")
                update_start_time = time.time()
                
                update_info = self.agent.rollout_update()
                
                update_duration = time.time() - update_start_time
                
                # ã€æ–¹æ¡ˆBæ­¥éª¤3ã€‘æ›´æ–°åå¤„ç†
                if update_info:
                    self.logger.info(f"âœ… [æ–¹æ¡ˆB] æ¨¡å‹æ›´æ–°å®Œæˆï¼Œè€—æ—¶: {update_duration:.3f}s")
                    self.log_post_update_buffer_state()
                    self.reset_all_workers_rollout_state()
                else:
                    self.logger.warning("âš ï¸ [æ–¹æ¡ˆB] æ¨¡å‹æ›´æ–°è¿”å›None")
                
                return update_info
                
            except Exception as e:
                self.logger.error(f"âŒ [æ–¹æ¡ˆB] æ¨¡å‹æ›´æ–°å¤±è´¥: {e}")
                return None
    
    def _verify_data_integrity_before_update(self):
        """ã€æ–¹æ¡ˆBè¾…åŠ©ã€‘æ›´æ–°å‰çš„æ•°æ®å®Œæ•´æ€§éªŒè¯"""
        if not hasattr(self, 'rollout_workers'):
            return True
        
        # å¿«é€ŸéªŒè¯å…³é”®æŒ‡æ ‡
        total_collected = sum(worker.samples_collected for worker in self.rollout_workers)
        target_steps = self.rollout_workers[0].target_rollout_steps * len(self.rollout_workers)
        
        current_bl_size = len(self.agent.low_level_buffer) if hasattr(self.agent, 'low_level_buffer') else 0
        current_bh_size = len(self.agent.high_level_buffer) if hasattr(self.agent, 'high_level_buffer') else 0
        
        # éªŒè¯æ¡ä»¶
        steps_sufficient = total_collected >= target_steps
        buffer_sufficient = current_bl_size >= self.config.batch_size * 0.95  # å…è®¸5%å®¹å·®
        
        if steps_sufficient and buffer_sufficient:
            self.logger.debug(f"âœ… [æ–¹æ¡ˆB] æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡: "
                            f"æ­¥æ•°={total_collected}/{target_steps}, "
                            f"B_l={current_bl_size}/{self.config.batch_size}")
            return True
        else:
            self.logger.warning(f"âš ï¸ [æ–¹æ¡ˆB] æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: "
                              f"æ­¥æ•°={total_collected}/{target_steps} (sufficient={steps_sufficient}), "
                              f"B_l={current_bl_size}/{self.config.batch_size} (sufficient={buffer_sufficient})")
            return False
    
    def _emergency_data_repair(self):
        """ã€æ–¹æ¡ˆBè¾…åŠ©ã€‘ç´§æ€¥æ•°æ®ä¿®å¤"""
        self.logger.info("ğŸ”§ [æ–¹æ¡ˆB] æ‰§è¡Œç´§æ€¥æ•°æ®ä¿®å¤...")
        
        # å¼ºåˆ¶æ”¶é›†æ‰€æœ‰pendingçš„é«˜å±‚ç»éªŒ
        forced_count = self.force_collect_all_pending_high_level_experiences()
        
        if forced_count > 0:
            self.logger.info(f"âœ… [æ–¹æ¡ˆB] ç´§æ€¥ä¿®å¤å®Œæˆ: è¡¥å……äº† {forced_count} ä¸ªé«˜å±‚ç»éªŒ")
        else:
            self.logger.info("â„¹ï¸ [æ–¹æ¡ˆB] ç´§æ€¥ä¿®å¤å®Œæˆ: æ— éœ€è¡¥å……æ•°æ®")
    
    def force_collect_all_pending_high_level_experiences(self):
        """å¼ºåˆ¶æ”¶é›†æ‰€æœ‰pendingçš„é«˜å±‚ç»éªŒï¼Œè§£å†³æ•°æ®æ”¶é›†ä¸åŒ¹é…é—®é¢˜"""
        if not hasattr(self, 'rollout_workers'):
            return 0
        
        self.logger.info("ğŸ”§ [FORCE_COLLECT_ALL] å¼€å§‹å¼ºåˆ¶æ”¶é›†æ‰€æœ‰pendingé«˜å±‚ç»éªŒ...")
        
        total_forced = 0
        worker_details = {}
        
        for worker in self.rollout_workers:
            # åˆ†æworkerçš„é«˜å±‚ç»éªŒçŠ¶æ€
            steps_collected = worker.samples_collected
            expected_high_level = steps_collected // self.config.k
            generated_high_level = worker.high_level_experiences_generated
            missing = expected_high_level - generated_high_level
            
            worker_details[worker.worker_id] = {
                'steps': steps_collected,
                'expected': expected_high_level,
                'generated': generated_high_level,
                'missing': missing,
                'strict_counter': getattr(worker, 'strict_step_counter', 'N/A'),
                'accumulated_reward': getattr(worker, 'accumulated_reward', 0.0)
            }
            
            # ã€æ–°å¢è°ƒè¯•ã€‘è¯¦ç»†åˆ†ææ¯ä¸ªworkerçš„çŠ¶æ€
            self.logger.info(f"ğŸ”§ [PROXY_FORCE_DEBUG] W{worker.worker_id} Analyzing for global force: "
                           f"steps={steps_collected}, k={self.config.k}, "
                           f"expected_floor={expected_high_level}, generated={generated_high_level}, "
                           f"missing={missing}, acc_reward_at_proxy_check={getattr(worker, 'accumulated_reward', 0.0):.4f}, "
                           f"strict_counter={getattr(worker, 'strict_step_counter', 'N/A')}")
            
            if missing > 0:
                self.logger.info(f"ğŸ”§ Worker {worker.worker_id} éœ€è¦å¼ºåˆ¶æ”¶é›†: "
                               f"ç¼ºå¤±={missing}, ç´¯ç§¯å¥–åŠ±={worker.accumulated_reward:.4f}")
                
                # ä¸ºæ¯ä¸ªç¼ºå¤±çš„é«˜å±‚ç»éªŒåˆ›å»ºå¼ºåˆ¶æ”¶é›†
                for i in range(missing):
                    success = self.create_forced_high_level_experience(worker, i)
                    if success:
                        total_forced += 1
                        worker.high_level_experiences_generated += 1
                        self.logger.info(f"ğŸ”§ [PROXY_FORCE_DEBUG] W{worker.worker_id} Global force created experience #{i}. "
                                       f"Worker's high_level_experiences_generated incremented to {worker.high_level_experiences_generated}")
                    else:
                        self.logger.warning(f"âš ï¸ [PROXY_FORCE_DEBUG] W{worker.worker_id} Global force FAILED to create experience #{i}.")
            else:
                self.logger.info(f"âœ… [PROXY_FORCE_DEBUG] W{worker.worker_id} No missing high-level experiences, no force needed.")
        
        # è®°å½•è¯¦ç»†ç»Ÿè®¡
        self.logger.warning("ğŸ“Š [FORCE_COLLECT_ALL] å¼ºåˆ¶æ”¶é›†ç»Ÿè®¡:")
        missing_workers = []
        for worker_id, details in worker_details.items():
            if details['missing'] > 0:
                missing_workers.append(worker_id)
                self.logger.warning(f"   Worker {worker_id}: æ­¥æ•°={details['steps']}, "
                                  f"é¢„æœŸ={details['expected']}, ç”Ÿæˆ={details['generated']}, "
                                  f"ç¼ºå¤±={details['missing']}, ç´¯ç§¯å¥–åŠ±={details['accumulated_reward']:.4f}")
        
        if total_forced > 0:
            self.logger.info(f"âœ… [FORCE_COLLECT_ALL] å¼ºåˆ¶æ”¶é›†å®Œæˆ: è¡¥å……äº† {total_forced} ä¸ªé«˜å±‚ç»éªŒ")
            self.logger.info(f"   å½±å“çš„Workers: {missing_workers}")
        else:
            self.logger.info("âœ… [FORCE_COLLECT_ALL] æ‰€æœ‰Workersçš„é«˜å±‚ç»éªŒéƒ½å·²å®Œæ•´ï¼Œæ— éœ€å¼ºåˆ¶æ”¶é›†")
        
        return total_forced
    
    def create_forced_high_level_experience(self, worker, index):
        """ä¸ºworkeråˆ›å»ºå¼ºåˆ¶çš„é«˜å±‚ç»éªŒ"""
        try:
            # è·å–workerçš„å½“å‰çŠ¶æ€ä¿¡æ¯
            state = getattr(worker, 'env_state', None)
            observations = getattr(worker, 'env_observations', None)
            team_skill = getattr(worker, 'current_team_skill', 0)
            agent_skills = getattr(worker, 'current_agent_skills', [0] * self.config.n_agents)
            accumulated_reward = getattr(worker, 'accumulated_reward', 0.0)
            
            # å¦‚æœçŠ¶æ€æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼
            if state is None:
                state = np.zeros(self.config.state_dim)
            if observations is None:
                observations = np.zeros((self.config.n_agents, self.config.obs_dim))
            
            # åˆ›å»ºé«˜å±‚ç»éªŒæ•°æ®
            high_level_experience = {
                'experience_type': 'high_level',
                'worker_id': worker.worker_id,
                'state': state.copy() if hasattr(state, 'copy') else np.array(state),
                'team_skill': team_skill,
                'observations': observations.copy() if hasattr(observations, 'copy') else np.array(observations),
                'agent_skills': agent_skills.copy() if hasattr(agent_skills, 'copy') else list(agent_skills),
                'accumulated_reward': accumulated_reward,
                'skill_log_probs': getattr(worker, 'skill_log_probs', None),
                'skill_timer': getattr(worker, 'skill_timer', 0),
                'episode_step': getattr(worker, 'episode_step', 0),
                'reason': f"å¼ºåˆ¶è¡¥å……#{index}"
            }
            
            # ç›´æ¥è°ƒç”¨agentçš„é«˜å±‚ç»éªŒå­˜å‚¨æ–¹æ³•
            success = self.agent.store_high_level_transition(
                state=high_level_experience['state'],
                team_skill=high_level_experience['team_skill'],
                observations=high_level_experience['observations'],
                agent_skills=high_level_experience['agent_skills'],
                accumulated_reward=high_level_experience['accumulated_reward'],
                skill_log_probs=high_level_experience['skill_log_probs'],
                worker_id=high_level_experience['worker_id']
            )
            
            if success:
                self.high_level_experiences_stored += 1
                self.logger.debug(f"âœ… Worker {worker.worker_id} å¼ºåˆ¶é«˜å±‚ç»éªŒ #{index} åˆ›å»ºæˆåŠŸ")
            
            return success
            
        except Exception as e:
            self.logger.error(f"âŒ Worker {worker.worker_id} å¼ºåˆ¶é«˜å±‚ç»éªŒ #{index} åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def reset_all_workers_rollout_state(self):
        """é‡ç½®æ‰€æœ‰workersçš„rolloutçŠ¶æ€ï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ªrolloutå‘¨æœŸï¼ˆæ–¹æ¡ˆ2ï¼šç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        if not hasattr(self, 'rollout_workers'):
            return
        
        # ã€æ–¹æ¡ˆ2ã€‘ç§»é™¤å¤æ‚çš„å…¨å±€æŠ€èƒ½å‘¨æœŸç®¡ç†ï¼Œç®€åŒ–é‡ç½®é€»è¾‘
        
        reset_count = 0
        for worker in self.rollout_workers:
            # é‡ç½®æ¯ä¸ªworkerçš„rolloutç›¸å…³çŠ¶æ€
            worker.samples_collected = 0
            worker.rollout_completed = False
            # ã€ä¿®å¤ã€‘é‡ç½®workerçš„æŠ€èƒ½çŠ¶æ€ï¼Œä½†ä¿æŒä¸¥æ ¼æ­¥æ•°è®¡æ•°å™¨è¿ç»­æ€§
            worker.current_team_skill = None
            worker.current_agent_skills = None
            worker.skill_log_probs = None
            worker.accumulated_reward = 0.0
            # ã€å…³é”®ä¿®å¤ã€‘é‡ç½®strict_step_counterä»¥é¿å…é«˜å±‚ç»éªŒè¿‡å¤š
            worker.strict_step_counter = 0
            worker.high_level_experiences_generated = 0
            reset_count += 1
        
        # ã€å…³é”®ä¿®å¤ã€‘é‡ç½®global_rollout_stepsä»¥ä¿æŒä¸workersçš„ä¸€è‡´æ€§
        self.global_rollout_steps = 0
        
        self.logger.info(f"ğŸ”„ å·²é‡ç½® {reset_count} ä¸ªworkersçš„rolloutçŠ¶æ€ï¼Œå‡†å¤‡æ–°çš„rolloutå‘¨æœŸ")
        self.logger.info(f"ğŸ”„ å·²é‡ç½®global_rollout_steps = {self.global_rollout_steps}")
    
    def get_storage_stats(self):
        """ã€å…¼å®¹æ€§æ–¹æ³•ã€‘è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯ - ä¸ºå¢å¼ºç‰ˆè®­ç»ƒå™¨æä¾›å…¼å®¹æ€§"""
        try:
            return {
                'total_attempts': getattr(self, 'high_level_experiences_stored', 0) + getattr(self, 'low_level_experiences_stored', 0),
                'total_successes': getattr(self, 'high_level_experiences_stored', 0) + getattr(self, 'low_level_experiences_stored', 0),
                'total_failures': 0,  # åŸç‰ˆAgentProxyæ²¡æœ‰å¤±è´¥ç»Ÿè®¡
                'queue_overflows': 0,
                'validation_failures': 0,
                'high_level_stored': getattr(self, 'high_level_experiences_stored', 0),
                'low_level_stored': getattr(self, 'low_level_experiences_stored', 0),
                'state_skill_stored': 0  # åŸç‰ˆæ²¡æœ‰å•ç‹¬ç»Ÿè®¡
            }
        except Exception as e:
            self.logger.error(f"è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {
                'total_attempts': 0,
                'total_successes': 0,
                'total_failures': 0,
                'queue_overflows': 0,
                'validation_failures': 0,
                'high_level_stored': 0,
                'low_level_stored': 0,
                'state_skill_stored': 0
            }

    def log_post_update_buffer_state(self):
        """è®°å½•æ›´æ–°åçš„ç¼“å†²åŒºçŠ¶æ€ï¼Œå¸®åŠ©è¯Šæ–­ç¼“å†²åŒºæ¸…ç†é—®é¢˜"""
        try:
            # è·å–agentç¼“å†²åŒºå¤§å°
            high_level_size = len(self.agent.high_level_buffer) if hasattr(self.agent, 'high_level_buffer') else 'N/A'
            low_level_size = len(self.agent.low_level_buffer) if hasattr(self.agent, 'low_level_buffer') else 'N/A'
            state_skill_size = len(self.agent.state_skill_dataset) if hasattr(self.agent, 'state_skill_dataset') else 'N/A'
            
            # è·å–agentå†…éƒ¨ç»Ÿè®¡
            high_level_stats = getattr(self.agent, 'high_level_samples_by_env', {})
            high_level_reason_stats = getattr(self.agent, 'high_level_samples_by_reason', {})
            
            self.logger.warning("ğŸ“ˆ [POST_UPDATE_BUFFER] æ›´æ–°åç¼“å†²åŒºçŠ¶æ€:")
            self.logger.warning(f"   - B_h (é«˜å±‚): {high_level_size} (æœŸæœ›: 0 - PPOåº”æ¸…ç©º)")
            self.logger.warning(f"   - B_l (ä½å±‚): {low_level_size} (æœŸæœ›: 0 - PPOåº”æ¸…ç©º)")
            self.logger.warning(f"   - D (åˆ¤åˆ«å™¨): {state_skill_size} (æœŸæœ›: ä¿ç•™)")
            self.logger.warning(f"   - é«˜å±‚æ ·æœ¬ç»Ÿè®¡: ç¯å¢ƒè´¡çŒ®={dict(high_level_stats)}")
            self.logger.warning(f"   - æ”¶é›†åŸå› ç»Ÿè®¡: {dict(high_level_reason_stats)}")
            
            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆPPO on-policyè¦æ±‚
            if high_level_size != 0 and high_level_size != 'N/A':
                self.logger.error(f"âŒ [BUFFER_CLEAR_ISSUE] B_hæœªè¢«æ¸…ç©ºï¼æœŸæœ›=0, å®é™…={high_level_size}")
            else:
                self.logger.info(f"âœ… [BUFFER_CLEAR_OK] B_hå·²æ­£ç¡®æ¸…ç©º")
                
            if low_level_size != 0 and low_level_size != 'N/A':
                self.logger.error(f"âŒ [BUFFER_CLEAR_ISSUE] B_læœªè¢«æ¸…ç©ºï¼æœŸæœ›=0, å®é™…={low_level_size}")
            else:
                self.logger.info(f"âœ… [BUFFER_CLEAR_OK] B_lå·²æ­£ç¡®æ¸…ç©º")
                
        except Exception as e:
            self.logger.error(f"è®°å½•æ›´æ–°åç¼“å†²åŒºçŠ¶æ€å¤±è´¥: {e}")

class TrainingWorker:
    """è®­ç»ƒworkerï¼Œåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œ"""
    def __init__(self, worker_id, agent_proxy, data_buffer, control_events, logger, config, trainer):
        self.worker_id = worker_id
        self.agent_proxy = agent_proxy
        self.data_buffer = data_buffer
        self.control_events = control_events
        self.logger = logger
        self.config = config
        self.trainer = trainer  # æ–°å¢ï¼šä¿å­˜trainerå¼•ç”¨
        
        # è®­ç»ƒç»Ÿè®¡
        self.updates_performed = 0
        self.samples_processed = 0
        self.last_update_time = time.time()
        
    def run(self):
        """ã€é˜¶æ®µ2å¢å¼ºã€‘è¿è¡Œè®­ç»ƒworkerä¸»å¾ªç¯ - æ™ºèƒ½é‡è¯•ç­–ç•¥ + è‡ªåŠ¨ä¿®å¤åŠŸèƒ½"""
        self.logger.info(f"Training worker {self.worker_id} å¼€å§‹è¿è¡Œ")
        
        experience_batch = []
        batch_size = 32  # æ‰¹å¤„ç†å¤§å°
        
        # ã€é˜¶æ®µ2æ–°å¢ã€‘é”™è¯¯ç»Ÿè®¡å’Œè‡ªé€‚åº”ç­–ç•¥
        consecutive_failures = 0
        max_consecutive_failures = 10
        storage_error_types = defaultdict(int)
        adaptive_retry_count = 5
        
        try:
            while not self.control_events['stop'].is_set():
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœ
                if self.control_events['pause'].is_set():
                    time.sleep(0.1)
                    continue
                
                # ã€é˜¶æ®µ2å¢å¼ºã€‘æ£€æµ‹ç³»ç»Ÿå‹åŠ›å¹¶è‡ªé€‚åº”è°ƒæ•´
                buffer_stats = self.data_buffer.get_stats()
                system_under_pressure = self._detect_system_pressure(buffer_stats)
                
                if system_under_pressure:
                    # ç³»ç»Ÿå‹åŠ›å¤§æ—¶ï¼Œé‡‡ç”¨æ›´ç§¯æçš„å¤„ç†ç­–ç•¥
                    batch_size = min(16, batch_size)  # å‡å°æ‰¹æ¬¡å¤§å°
                    adaptive_retry_count = max(3, adaptive_retry_count - 1)  # å‡å°‘é‡è¯•æ¬¡æ•°
                else:
                    # ç³»ç»Ÿæ­£å¸¸æ—¶ï¼Œæ¢å¤æ ‡å‡†ç­–ç•¥
                    batch_size = 32
                    adaptive_retry_count = 5
                
                # ã€é˜¶æ®µ2å¢å¼ºã€‘æ™ºèƒ½æ•°æ®è·å– - æ”¯æŒä¼˜å…ˆçº§å¤„ç†
                try:
                    experience = self._intelligent_data_retrieval()
                    if experience is None:
                        if self.control_events['stop'].is_set():
                            break
                        continue
                        
                except Exception as e:
                    error_type = type(e).__name__
                    storage_error_types[error_type] += 1
                    self.logger.error(f"Training worker {self.worker_id}: è·å–æ•°æ®å¼‚å¸¸: {e}")
                    consecutive_failures += 1
                    
                    if consecutive_failures >= max_consecutive_failures:
                        self.logger.error(f"Training worker {self.worker_id}: è¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œæš‚åœå¤„ç†")
                        time.sleep(1.0)  # æš‚åœæ›´é•¿æ—¶é—´
                        consecutive_failures = 0
                    
                    time.sleep(0.01)
                    continue
                
                # æˆåŠŸè·å–æ•°æ®ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                consecutive_failures = 0
                experience_batch.append(experience)
                
                # ã€é˜¶æ®µ2å¢å¼ºã€‘æ™ºèƒ½æ‰¹å¤„ç†ç­–ç•¥ - è€ƒè™‘æ•°æ®ç±»å‹ä¼˜å…ˆçº§
                should_process_batch = self._should_process_batch(
                    experience_batch, batch_size, buffer_stats
                )
                
                if should_process_batch:
                    # ã€é˜¶æ®µ2æ ¸å¿ƒã€‘æ™ºèƒ½å­˜å‚¨é‡è¯•æœºåˆ¶
                    storage_result = self._intelligent_storage_retry(
                        experience_batch, adaptive_retry_count
                    )
                    
                    if storage_result['success']:
                        self.samples_processed += storage_result['stored_count']
                        
                        if storage_result['stored_count'] > 0:
                            self.logger.debug(f"Training worker {self.worker_id}: å¤„ç†äº† {storage_result['stored_count']} ä¸ªæ ·æœ¬ "
                                            f"(æ‰¹æ¬¡å¤§å°: {len(experience_batch)}, é˜Ÿåˆ—å‰©ä½™: {self.data_buffer.qsize()})")
                        
                        experience_batch = []  # åªæœ‰åœ¨å®Œå…¨æˆåŠŸåæ‰æ¸…ç©º
                        
                        # æ£€æŸ¥æ›´æ–°æ¡ä»¶
                        if self.agent_proxy.should_update():
                            self.perform_update()
                    else:
                        # ã€é˜¶æ®µ2æ–°å¢ã€‘å­˜å‚¨å¤±è´¥æ—¶çš„æ™ºèƒ½å¤„ç†
                        self._handle_storage_failure(experience_batch, storage_result)
                
                # çŸ­æš‚ç¡çœ é¿å…è¿‡åº¦å ç”¨CPU
                time.sleep(0.001)
        
        except Exception as e:
            self.logger.error(f"Training worker {self.worker_id}: è¿è¡Œå¼‚å¸¸: {e}")
        finally:
            # ã€é˜¶æ®µ2å¢å¼ºã€‘ç¡®ä¿å‰©ä½™ç»éªŒ100%å­˜å‚¨æˆåŠŸ
            if experience_batch:
                self._process_remaining_experiences(experience_batch)
            
            # ã€é˜¶æ®µ2æ–°å¢ã€‘è®°å½•é”™è¯¯ç»Ÿè®¡
            if storage_error_types:
                self.logger.warning(f"Training worker {self.worker_id}: é”™è¯¯ç»Ÿè®¡: {dict(storage_error_types)}")
            
            self.logger.info(f"Training worker {self.worker_id} ç»“æŸè¿è¡Œ")
    
    def _detect_system_pressure(self, buffer_stats):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘æ£€æµ‹ç³»ç»Ÿå‹åŠ›"""
        # æ£€æµ‹é˜Ÿåˆ—æ‹¥å¡
        queue_pressure = buffer_stats.get('queue_size', 0) > 1000
        
        # æ£€æµ‹å¤„ç†é€Ÿåº¦ä¸‹é™
        processing_speed = buffer_stats.get('processing_speed', 0)
        speed_pressure = processing_speed < 10  # æ¯ç§’å¤„ç†å°‘äº10ä¸ªæ ·æœ¬
        
        # æ£€æµ‹æ‹¥å¡çŠ¶æ€
        congestion_detected = buffer_stats.get('congestion_detected', False)
        
        return queue_pressure or speed_pressure or congestion_detected
    
    def _intelligent_data_retrieval(self):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘æ™ºèƒ½æ•°æ®è·å– - æ”¯æŒä¼˜å…ˆçº§å¤„ç†"""
        max_wait_attempts = 5
        wait_attempt = 0
        
        while wait_attempt < max_wait_attempts and not self.control_events['stop'].is_set():
            try:
                # ä½¿ç”¨å¢å¼ºçš„DataBufferä¼˜å…ˆçº§è·å–
                experience = self.data_buffer.get(block=True, timeout=1.0)
                if experience is not None:
                    return experience
                    
            except queue.Empty:
                wait_attempt += 1
                # ã€æ™ºèƒ½ç­‰å¾…ã€‘æ ¹æ®ç³»ç»ŸçŠ¶æ€è°ƒæ•´ç­‰å¾…ç­–ç•¥
                if wait_attempt < 3:
                    continue  # çŸ­ç­‰å¾…
                else:
                    time.sleep(0.1)  # ç¨é•¿ç­‰å¾…
            except Exception as e:
                self.logger.error(f"Training worker {self.worker_id}: æ•°æ®è·å–å¼‚å¸¸: {e}")
                return None
        
        return None
    
    def _should_process_batch(self, experience_batch, batch_size, buffer_stats):
        """ã€é˜¶æ®µ2å¢å¼ºã€‘æ™ºèƒ½æ‰¹å¤„ç†å†³ç­–"""
        current_batch_size = len(experience_batch)
        queue_size = buffer_stats.get('queue_size', 0)
        
        # ã€ä¼˜å…ˆçº§è€ƒè™‘ã€‘æ£€æŸ¥æ‰¹æ¬¡ä¸­çš„é«˜å±‚ç»éªŒæ¯”ä¾‹
        high_priority_count = sum(1 for exp in experience_batch 
                                if exp.get('experience_type') == 'high_level')
        high_priority_ratio = high_priority_count / current_batch_size if current_batch_size > 0 else 0
        
        # å¤„ç†æ¡ä»¶
        conditions = [
            current_batch_size >= batch_size,  # è¾¾åˆ°æ‰¹å¤§å°
            (current_batch_size > 0 and queue_size < 5),  # é˜Ÿåˆ—å‡ ä¹ç©ºäº†
            (current_batch_size >= 8 and queue_size < batch_size // 2),  # ä¸­ç­‰æ‰¹æ¬¡ä¸”é˜Ÿåˆ—ä¸æ»¡
            (high_priority_ratio > 0.5 and current_batch_size >= 4)  # é«˜ä¼˜å…ˆçº§æ•°æ®è¾ƒå¤š
        ]
        
        return any(conditions)
    
    def _intelligent_storage_retry(self, experience_batch, max_retries):
        """ã€é˜¶æ®µ2æ ¸å¿ƒã€‘æ™ºèƒ½å­˜å‚¨é‡è¯•æœºåˆ¶"""
        result = {
            'success': False,
            'stored_count': 0,
            'retry_count': 0,
            'error_types': [],
            'final_error': None
        }
        
        retry_count = 0
        stored_count = 0
        
        while retry_count < max_retries:
            try:
                stored_count = self.agent_proxy.store_experience(experience_batch)
                
                # éªŒè¯å­˜å‚¨æˆåŠŸ
                if stored_count == len(experience_batch):
                    result['success'] = True
                    result['stored_count'] = stored_count
                    result['retry_count'] = retry_count
                    return result
                else:
                    # éƒ¨åˆ†å­˜å‚¨æˆåŠŸ - è®°å½•ä½†ç»§ç»­é‡è¯•
                    error_msg = f"å­˜å‚¨ä¸å®Œæ•´ {stored_count}/{len(experience_batch)}"
                    result['error_types'].append(error_msg)
                    
                    if retry_count < max_retries - 1:
                        self.logger.debug(f"Training worker {self.worker_id}: {error_msg}, é‡è¯• {retry_count + 1}")
                        
                        # ã€æ™ºèƒ½ç­‰å¾…ç­–ç•¥ã€‘æ ¹æ®é‡è¯•æ¬¡æ•°è°ƒæ•´ç­‰å¾…æ—¶é—´
                        wait_time = min(0.1 * (retry_count + 1), 0.5)
                        time.sleep(wait_time)
                    
                    retry_count += 1
                    
            except Exception as e:
                error_type = type(e).__name__
                result['error_types'].append(error_type)
                result['final_error'] = str(e)
                
                if retry_count < max_retries - 1:
                    self.logger.debug(f"Training worker {self.worker_id}: å­˜å‚¨å¼‚å¸¸ {error_type}: {e}, é‡è¯• {retry_count + 1}")
                    
                    # ã€æ™ºèƒ½ç­‰å¾…ç­–ç•¥ã€‘æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´ç­‰å¾…æ—¶é—´
                    if 'timeout' in error_type.lower():
                        wait_time = 0.2 * (retry_count + 1)  # è¶…æ—¶é”™è¯¯ç­‰å¾…æ›´é•¿
                    else:
                        wait_time = 0.1 * (retry_count + 1)  # å…¶ä»–é”™è¯¯æ ‡å‡†ç­‰å¾…
                    
                    time.sleep(min(wait_time, 0.5))
                
                retry_count += 1
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        result['retry_count'] = retry_count
        result['stored_count'] = stored_count
        
        if result['error_types']:
            self.logger.error(f"Training worker {self.worker_id}: å­˜å‚¨æœ€ç»ˆå¤±è´¥! "
                            f"æˆåŠŸ={stored_count}, æ€»æ•°={len(experience_batch)}, "
                            f"é”™è¯¯ç±»å‹={result['error_types']}")
        
        return result
    
    def _handle_storage_failure(self, experience_batch, storage_result):
        """ã€é˜¶æ®µ2æ–°å¢ã€‘å¤„ç†å­˜å‚¨å¤±è´¥çš„æ™ºèƒ½ç­–ç•¥"""
        retry_count = storage_result['retry_count']
        error_types = storage_result['error_types']
        
        # ã€ç­–ç•¥1ã€‘åˆ†æé”™è¯¯ç±»å‹ï¼Œå†³å®šå¤„ç†æ–¹å¼
        persistent_errors = ['timeout', 'connection', 'memory']
        has_persistent_error = any(error_type.lower() in ' '.join(error_types).lower() 
                                 for error_type in persistent_errors)
        
        if has_persistent_error:
            # æŒç»­æ€§é”™è¯¯ - æš‚åœå¤„ç†ï¼Œé¿å…ç³»ç»Ÿè¿‡è½½
            self.logger.warning(f"Training worker {self.worker_id}: æ£€æµ‹åˆ°æŒç»­æ€§é”™è¯¯ï¼Œæš‚åœå¤„ç†")
            time.sleep(1.0)
            
            # ã€ç­–ç•¥2ã€‘å°è¯•åˆ†æ‰¹å¤„ç†
            if len(experience_batch) > 8:
                self.logger.info(f"Training worker {self.worker_id}: å°è¯•åˆ†æ‰¹å¤„ç† {len(experience_batch)} ä¸ªç»éªŒ")
                self._split_batch_processing(experience_batch)
                return
        
        # ã€ç­–ç•¥3ã€‘ä¸¥æ ¼æ¨¡å¼ - ä¸æ¸…ç©ºbatchï¼Œä½†é™åˆ¶é‡è¯•æ¬¡æ•°
        if retry_count >= 3:
            # è¶…è¿‡ä¸€å®šé‡è¯•æ¬¡æ•°ï¼Œè®°å½•å¹¶æš‚æ—¶æ”¾å¼ƒ
            self.logger.error(f"Training worker {self.worker_id}: æ”¾å¼ƒå¤„ç†å½“å‰æ‰¹æ¬¡ {len(experience_batch)} ä¸ªç»éªŒ")
            # æ¸…ç©ºbatchä»¥é¿å…æ— é™é‡è¯•
            experience_batch.clear()
        
        # ã€ç­–ç•¥4ã€‘å¦åˆ™ä¿æŒbatchä¸å˜ï¼Œç»§ç»­é‡è¯•
    
    def _split_batch_processing(self, experience_batch):
        """ã€é˜¶æ®µ2è¾…åŠ©ã€‘åˆ†æ‰¹å¤„ç†å¤§æ‰¹æ¬¡æ•°æ®"""
        batch_size = len(experience_batch)
        split_size = max(4, batch_size // 4)  # åˆ†æˆ4ä¸ªå°æ‰¹æ¬¡
        
        processed = 0
        for i in range(0, batch_size, split_size):
            sub_batch = experience_batch[i:i + split_size]
            
            try:
                storage_result = self._intelligent_storage_retry(sub_batch, 3)  # å‡å°‘é‡è¯•æ¬¡æ•°
                if storage_result['success']:
                    processed += storage_result['stored_count']
                    self.logger.debug(f"Training worker {self.worker_id}: åˆ†æ‰¹å¤„ç†æˆåŠŸ {i//split_size + 1}, "
                                    f"å¤„ç† {storage_result['stored_count']} ä¸ªç»éªŒ")
                else:
                    self.logger.warning(f"Training worker {self.worker_id}: åˆ†æ‰¹å¤„ç†å¤±è´¥ {i//split_size + 1}")
                    
            except Exception as e:
                self.logger.error(f"Training worker {self.worker_id}: åˆ†æ‰¹å¤„ç†å¼‚å¸¸: {e}")
        
        if processed > 0:
            self.samples_processed += processed
            self.logger.info(f"Training worker {self.worker_id}: åˆ†æ‰¹å¤„ç†å®Œæˆï¼Œæ€»å…±å¤„ç† {processed}/{batch_size} ä¸ªç»éªŒ")
        
        # æ¸…ç©ºåŸæ‰¹æ¬¡
        experience_batch.clear()
    
    def _process_remaining_experiences(self, experience_batch):
        """ã€é˜¶æ®µ2å¢å¼ºã€‘å¤„ç†å‰©ä½™ç»éªŒ - æ›´æ™ºèƒ½çš„æœ€ç»ˆå¤„ç†"""
        self.logger.info(f"Training worker {self.worker_id}: å¤„ç†å‰©ä½™ {len(experience_batch)} ä¸ªç»éªŒ")
        
        # ã€å¢å¼ºç­–ç•¥ã€‘æ›´å¤šé‡è¯•æ¬¡æ•°å’Œæ›´é•¿ç­‰å¾…æ—¶é—´
        max_retries = 15  # å¢åŠ é‡è¯•æ¬¡æ•°
        retry_count = 0
        
        while retry_count < max_retries and experience_batch:
            try:
                storage_result = self._intelligent_storage_retry(experience_batch, 3)
                
                if storage_result['success']:
                    self.samples_processed += storage_result['stored_count']
                    self.logger.info(f"Training worker {self.worker_id}: å‰©ä½™ç»éªŒå­˜å‚¨æˆåŠŸ")
                    break
                else:
                    # ã€æœ€ç»ˆç­–ç•¥ã€‘å°è¯•åˆ†æ‰¹å¤„ç†
                    if len(experience_batch) > 4 and retry_count > 5:
                        self.logger.info(f"Training worker {self.worker_id}: å‰©ä½™ç»éªŒå°è¯•åˆ†æ‰¹å¤„ç†")
                        self._split_batch_processing(experience_batch)
                        break
                    
                    self.logger.warning(f"Training worker {self.worker_id}: å‰©ä½™ç»éªŒå­˜å‚¨ä¸å®Œæ•´ï¼Œé‡è¯• {retry_count + 1}")
                    retry_count += 1
                    
                    # ã€æ¸è¿›ç­‰å¾…ã€‘ç­‰å¾…æ—¶é—´é€æ¸å¢åŠ 
                    wait_time = min(0.2 * retry_count, 2.0)
                    time.sleep(wait_time)
                    
            except Exception as e:
                self.logger.error(f"Training worker {self.worker_id}: å‰©ä½™ç»éªŒå­˜å‚¨å¼‚å¸¸: {e}")
                retry_count += 1
                time.sleep(0.3)
        
        if experience_batch:
            self.logger.error(f"Training worker {self.worker_id}: æœ€ç»ˆä»æœ‰ {len(experience_batch)} ä¸ªç»éªŒæœªèƒ½å­˜å‚¨!")
    
    def perform_update(self):
        """æ‰§è¡Œæ¨¡å‹æ›´æ–°"""
        try:
            update_start = time.time()
            
            # æ‰§è¡Œæ›´æ–°ï¼ˆè¿™é‡Œåªæœ‰ä¸€ä¸ªworkeræ‰§è¡Œæ›´æ–°ï¼Œå…¶ä»–workerç»§ç»­å¤„ç†æ•°æ®ï¼‰
            if self.worker_id == 0:  # åªæœ‰ç¬¬ä¸€ä¸ªtraining workeræ‰§è¡Œæ›´æ–°
                self.logger.info(f"Training worker {self.worker_id}: å¼€å§‹æ¨¡å‹æ›´æ–°")
                
                update_info = self.agent_proxy.update()
                
                if update_info:
                    self.updates_performed += 1
                    update_time = time.time() - update_start
                    self.last_update_time = time.time()
                    
                    # æ–°å¢ï¼šæ›´æ–°ç´¯è®¡æ€»æ­¥æ•°
                    steps_this_rollout = self.config.batch_size
                    self.trainer.total_steps.increment(steps_this_rollout)
                    
                    self.logger.info(f"Training worker {self.worker_id}: æ¨¡å‹æ›´æ–°å®Œæˆ "
                                   f"#{self.updates_performed}, è€—æ—¶: {update_time:.3f}s")
                    self.logger.info(f"Training worker {self.worker_id}: ç´¯è®¡æ€»æ­¥æ•°å¢åŠ  {steps_this_rollout}. "
                                   f"æ–°çš„æ€»æ­¥æ•°: {self.trainer.total_steps.get()}")
                    
                    # è®°å½•æ›´æ–°ä¿¡æ¯
                    if 'coordinator' in update_info:
                        coord_loss = update_info['coordinator'].get('coordinator_loss', 0)
                        self.logger.debug(f"Coordinator loss: {coord_loss:.6f}")
                    
                    if 'discoverer' in update_info:
                        disc_loss = update_info['discoverer'].get('discoverer_loss', 0)
                        self.logger.debug(f"Discoverer loss: {disc_loss:.6f}")
                else:
                    self.logger.warning(f"Training worker {self.worker_id}: æ¨¡å‹æ›´æ–°è¿”å›None")
        
        except Exception as e:
            self.logger.error(f"Training worker {self.worker_id}: æ¨¡å‹æ›´æ–°å¼‚å¸¸: {e}")

class ThreadedRolloutTrainer:
    """å¤šçº¿ç¨‹HMASD Rollout-basedè®­ç»ƒå™¨"""
    
    def __init__(self, config, args=None):
        """
        åˆå§‹åŒ–å¤šçº¿ç¨‹è®­ç»ƒå™¨
        
        å‚æ•°:
            config: é…ç½®å¯¹è±¡
            args: å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config
        self.args = args or argparse.Namespace()
        
        # éªŒè¯å¹¶è®¾ç½®è®­ç»ƒæ¨¡å¼
        config.rollout_based_training = True
        config.episode_based_training = False
        config.sync_training_mode = False
        
        # éªŒè¯é…ç½®
        if not config.validate_rollout_config():
            raise ValueError("Rollouté…ç½®éªŒè¯å¤±è´¥")
        
        # çº¿ç¨‹é…ç½®ï¼ˆæŒ‰ç…§è®ºæ–‡ Appendix Eï¼‰
        self.num_training_threads = getattr(args, 'training_threads', 16)
        self.num_rollout_threads = getattr(args, 'rollout_threads', 32)
        
        # è®¾ç½®è®¾å¤‡
        self.device = self._get_device()
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.log_dir = f"logs/threaded_rollout_training_{timestamp}"
        os.makedirs(self.log_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        self._init_logging()
        
        # çº¿ç¨‹æ§åˆ¶
        self.control_events = {
            'stop': Event(),
            'pause': Event()
        }
        
        # æ•°æ®ç¼“å†²åŒº
        buffer_size = getattr(args, 'buffer_size', 10000)
        self.data_buffer = DataBuffer(maxsize=buffer_size)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.start_time = None
        self.total_updates = 0
        self.total_samples = ThreadSafeCounter()
        self.total_steps = ThreadSafeCounter()  # æ·»åŠ æ€»æ­¥æ•°è®¡æ•°å™¨
        
        self.logger.info("ThreadedRolloutTraineråˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"æ—¥å¿—ç›®å½•: {self.log_dir}")
        self.logger.info(f"è®­ç»ƒçº¿ç¨‹æ•°: {self.num_training_threads}")
        self.logger.info(f"Rolloutçº¿ç¨‹æ•°: {self.num_rollout_threads}")
        self.logger.info(f"æ•°æ®ç¼“å†²åŒºå¤§å°: {buffer_size}")
        self.logger.info(config.get_rollout_summary())
    
    def _get_device(self):
        """è·å–è®¡ç®—è®¾å¤‡"""
        device_pref = getattr(self.args, 'device', 'auto')
        if device_pref == 'auto':
            return torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        elif device_pref == 'cuda':
            if torch.cuda.is_available():
                return torch.device('cuda')
            else:
                self.logger.warning("è¯·æ±‚CUDAä½†æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPU")
                return torch.device('cpu')
        else:
            return torch.device('cpu')
    
    def _init_logging(self):
        """åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ"""
        log_level = getattr(self.args, 'log_level', 'INFO')
        console_level = getattr(self.args, 'console_log_level', 'INFO')
        
        init_multiproc_logging(
            log_dir=self.log_dir,
            log_file='threaded_rollout_training.log',
            file_level=LOG_LEVELS.get(log_level.lower(), 20),
            console_level=LOG_LEVELS.get(console_level.lower(), 20)
        )
        
        self.logger = get_logger("ThreadedRolloutTrainer")
    
    def create_env_factory(self):
        """åˆ›å»ºç¯å¢ƒå·¥å‚å‡½æ•°"""
        scenario = getattr(self.args, 'scenario', 2)
        n_uavs = getattr(self.args, 'n_uavs', 5)
        n_users = getattr(self.args, 'n_users', 50)
        user_distribution = getattr(self.args, 'user_distribution', 'uniform')
        channel_model = getattr(self.args, 'channel_model', '3gpp-36777')
        max_hops = getattr(self.args, 'max_hops', 3)
        
        def make_env():
            def _init():
                env_seed = int(time.time() * 1000) % 10000  # åŸºäºæ—¶é—´çš„éšæœºç§å­
                if scenario == 1:
                    raw_env = UAVBaseStationEnv(
                        n_uavs=n_uavs,
                        n_users=n_users,
                        user_distribution=user_distribution,
                        channel_model=channel_model,
                        seed=env_seed
                    )
                elif scenario == 2:
                    raw_env = UAVCooperativeNetworkEnv(
                        n_uavs=n_uavs,
                        n_users=n_users,
                        max_hops=max_hops,
                        user_distribution=user_distribution,
                        channel_model=channel_model,
                        seed=env_seed
                    )
                else:
                    raise ValueError(f"æœªçŸ¥åœºæ™¯: {scenario}")
                
                env = ParallelToArrayAdapter(raw_env, seed=env_seed)
                return env
            return _init()
        
        return make_env
    
    def validate_environment(self):
        """éªŒè¯ç¯å¢ƒæ¥å£å…¼å®¹æ€§"""
        self.logger.info("å¼€å§‹éªŒè¯ç¯å¢ƒæ¥å£å…¼å®¹æ€§...")
        
        temp_env = self.create_env_factory()()
        try:
            # æµ‹è¯•reset
            reset_result = temp_env.reset()
            self.logger.info(f"ç¯å¢ƒreset()è¿”å›: {len(reset_result)}ä¸ªå€¼")
            
            if len(reset_result) == 2:
                observations, info = reset_result
                self.logger.info(f"ResetæˆåŠŸ: observations.shape={observations.shape}, info keys={list(info.keys()) if isinstance(info, dict) else 'not dict'}")
            else:
                self.logger.warning(f"Resetè¿”å›å€¼æ•°é‡å¼‚å¸¸: {len(reset_result)}")
            
            # æµ‹è¯•step
            dummy_actions = np.random.randn(temp_env.n_uavs, temp_env.action_dim)
            step_result = temp_env.step(dummy_actions)
            self.logger.info(f"ç¯å¢ƒstep()è¿”å›: {len(step_result)}ä¸ªå€¼")
            
            if len(step_result) == 5:
                next_obs, reward, terminated, truncated, info = step_result
                self.logger.info(f"StepæˆåŠŸ (Gymnasiumæ ¼å¼): next_obs.shape={next_obs.shape}, "
                               f"reward={reward}, terminated={terminated}, truncated={truncated}")
            elif len(step_result) == 4:
                next_obs, reward, done, info = step_result
                self.logger.info(f"StepæˆåŠŸ (ä¼ ç»Ÿæ ¼å¼): next_obs.shape={next_obs.shape}, "
                               f"reward={reward}, done={done}")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„stepè¿”å›å€¼æ•°é‡: {len(step_result)}")
            
            self.logger.info("âœ… ç¯å¢ƒæ¥å£éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ç¯å¢ƒæ¥å£éªŒè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            temp_env.close()
    
    def initialize_agent(self):
        """åˆå§‹åŒ–HMASDä»£ç†"""
        # éªŒè¯ç¯å¢ƒå…¼å®¹æ€§
        if not self.validate_environment():
            raise RuntimeError("ç¯å¢ƒæ¥å£éªŒè¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è®­ç»ƒ")
        
        # åˆ›å»ºä¸´æ—¶ç¯å¢ƒè·å–ç»´åº¦ä¿¡æ¯
        temp_env = self.create_env_factory()()
        state_dim = temp_env.state_dim
        obs_dim = temp_env.obs_dim
        n_agents = temp_env.n_uavs
        temp_env.close()
        
        # æ›´æ–°é…ç½®
        self.config.update_env_dims(state_dim, obs_dim)
        self.config.n_agents = n_agents
        
        self.logger.info(f"ç¯å¢ƒç»´åº¦: state_dim={state_dim}, obs_dim={obs_dim}, n_agents={n_agents}")
        
        # åˆ›å»ºçº¿ç¨‹å®‰å…¨ä»£ç†
        self.agent = ThreadSafeHMASDAgent(
            config=self.config,
            log_dir=self.log_dir,
            device=self.device,
            debug=getattr(self.args, 'debug', False)
        )
        
        # åˆ›å»ºä»£ç†ä»£ç†
        self.agent_proxy = AgentProxy(self.agent, self.config, self.logger, self.data_buffer)
        
        self.logger.info("HMASDä»£ç†åˆå§‹åŒ–å®Œæˆ")
    
    def start_rollout_threads(self):
        """å¯åŠ¨rolloutçº¿ç¨‹"""
        self.logger.info(f"å¯åŠ¨ {self.num_rollout_threads} ä¸ªrolloutçº¿ç¨‹")
        
        self.rollout_workers = []
        self.rollout_threads = []
        
        env_factory = self.create_env_factory()
        
        for i in range(self.num_rollout_threads):
            worker = RolloutWorker(
                worker_id=i,
                env_factory=env_factory,
                config=self.config,
                data_buffer=self.data_buffer,
                control_events=self.control_events,
                logger=self.logger
            )
            
            thread = threading.Thread(
                target=worker.run,
                args=(self.agent_proxy,),
                name=f"RolloutWorker-{i}"
            )
            thread.daemon = True
            
            self.rollout_workers.append(worker)
            self.rollout_threads.append(thread)
            thread.start()
        
        self.logger.info("æ‰€æœ‰rolloutçº¿ç¨‹å·²å¯åŠ¨")
        
        # ã€å…³é”®ä¿®å¤ã€‘è®¾ç½®AgentProxyå¯¹rollout workersçš„å¼•ç”¨
        self.agent_proxy.rollout_workers = self.rollout_workers
        
        # ã€å…³é”®ä¿®å¤ã€‘è®¾ç½®AgentProxyå¯¹rollout workersçš„å¼•ç”¨
        self.agent_proxy.rollout_workers = self.rollout_workers
    
    def start_training_threads(self):
        """å¯åŠ¨è®­ç»ƒçº¿ç¨‹"""
        self.logger.info(f"å¯åŠ¨ {self.num_training_threads} ä¸ªtrainingçº¿ç¨‹")
        
        self.training_workers = []
        self.training_threads = []
        
        for i in range(self.num_training_threads):
            worker = TrainingWorker(
                worker_id=i,
                agent_proxy=self.agent_proxy,
                data_buffer=self.data_buffer,
                control_events=self.control_events,
                logger=self.logger,
                config=self.config,
                trainer=self  # æ–°å¢ï¼šä¼ é€’trainerå®ä¾‹
            )
            
            thread = threading.Thread(
                target=worker.run,
                name=f"TrainingWorker-{i}"
            )
            thread.daemon = True
            
            self.training_workers.append(worker)
            self.training_threads.append(thread)
            thread.start()
        
        self.logger.info("æ‰€æœ‰trainingçº¿ç¨‹å·²å¯åŠ¨")
    
    def monitor_training(self, total_steps=100000):
        """ç›‘æ§è®­ç»ƒè¿›åº¦"""
        self.logger.info(f"å¼€å§‹è®­ç»ƒç›‘æ§ï¼Œç›®æ ‡æ­¥æ•°: {total_steps:,}")
        
        self.start_time = time.time()
        last_log_time = self.start_time
        last_stats_log_time = self.start_time
        last_step_count = 0
        
        try:
            while True:
                current_time = time.time()
                
                # ä½¿ç”¨æ­£ç¡®çš„ç´¯è®¡æ€»æ­¥æ•°
                cumulative_trainer_steps = self.total_steps.get()
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ­¥æ•°é™åˆ¶
                if cumulative_trainer_steps >= total_steps:
                    self.logger.info(f"è¾¾åˆ°è®­ç»ƒæ­¥æ•°é™åˆ¶ {total_steps:,} (å®é™…ç´¯è®¡: {cumulative_trainer_steps:,})ï¼Œåœæ­¢è®­ç»ƒ")
                    break
                
                # æ¯åˆ†é’Ÿè®°å½•ä¸€æ¬¡ç®€è¦è¿›åº¦
                if current_time - last_log_time >= 60:
                    self.log_progress(cumulative_trainer_steps, total_steps)
                    last_log_time = current_time
                
                # æ¯10åˆ†é’Ÿè®°å½•ä¸€æ¬¡è¯¦ç»†ç»Ÿè®¡
                if current_time - last_stats_log_time >= 600:
                    self.log_detailed_stats()
                    last_stats_log_time = current_time
                
                # æ£€æŸ¥çº¿ç¨‹å¥åº·çŠ¶æ€
                self.check_thread_health()
                
                time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
        
        except KeyboardInterrupt:
            self.logger.info("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        
        finally:
            self.stop_training()
    
    def log_progress(self, current_steps, total_steps):
        """è®°å½•è®­ç»ƒè¿›åº¦"""
        progress_percent = (current_steps / total_steps) * 100
        remaining_steps = total_steps - current_steps
        
        # è®¡ç®—æ—¶é—´ç»Ÿè®¡
        elapsed_time = time.time() - self.start_time
        if current_steps > 0:
            estimated_total_time = elapsed_time * total_steps / current_steps
            remaining_time = estimated_total_time - elapsed_time
        else:
            remaining_time = 0
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        buffer_stats = self.data_buffer.get_stats()
        
        # è®¡ç®—rollout workersç»Ÿè®¡
        total_samples = sum(worker.samples_collected for worker in self.rollout_workers)
        total_episodes = sum(worker.episodes_completed for worker in self.rollout_workers)
        total_high_level_exp = sum(worker.high_level_experiences_generated for worker in self.rollout_workers)
        
        # è®¡ç®—training workersç»Ÿè®¡
        total_updates = sum(worker.updates_performed for worker in self.training_workers)
        total_processed = sum(worker.samples_processed for worker in self.training_workers)
        
        # è·å–ä»£ç†ç»Ÿè®¡
        high_level_stored = self.agent_proxy.high_level_experiences_stored
        low_level_stored = self.agent_proxy.low_level_experiences_stored
        
        # è®¡ç®—æ­¥æ•°é€Ÿåº¦
        steps_per_second = current_steps / elapsed_time if elapsed_time > 0 else 0
        
        self.logger.debug(f"è®­ç»ƒè¿›åº¦: {progress_percent:.1f}% "
                        f"({current_steps:,} / {total_steps:,} æ­¥), "
                        f"å‰©ä½™: {remaining_steps:,} æ­¥")
        self.logger.debug(f"æ—¶é—´: å·²ç”¨={elapsed_time/3600:.1f}h, é¢„è®¡å‰©ä½™={remaining_time/3600:.1f}h, "
                        f"é€Ÿåº¦={steps_per_second:.1f} æ­¥/ç§’")
        self.logger.debug(f"Rollout: æ ·æœ¬={total_samples:,}, Episodes={total_episodes:,}, "
                        f"é«˜å±‚ç»éªŒ={total_high_level_exp:,}")
        self.logger.debug(f"Training: æ›´æ–°={total_updates}, å¤„ç†æ ·æœ¬={total_processed:,}")
        self.logger.debug(f"ç»éªŒå­˜å‚¨: é«˜å±‚={high_level_stored:,}, ä½å±‚={low_level_stored:,}")
        self.logger.debug(f"Buffer: é˜Ÿåˆ—={buffer_stats['queue_size']}, "
                        f"æ·»åŠ ={buffer_stats['total_added']:,}, "
                        f"æ¶ˆè´¹={buffer_stats['total_consumed']:,}")
    
    def log_detailed_stats(self):
        """è®°å½•è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        self.logger.info("=== è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ ===")
        
        # Rollout workersç»Ÿè®¡
        self.logger.info("Rollout Workers:")
        for i, worker in enumerate(self.rollout_workers[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            stats = worker.get_worker_stats()
            self.logger.info(f"  Worker {i}: æ ·æœ¬={stats['samples_collected']}, "
                           f"Episodes={stats['episodes_completed']}, "
                           f"é«˜å±‚ç»éªŒ={stats['high_level_experiences_generated']}, "
                           f"å½“å‰æŠ€èƒ½={stats['current_team_skill']}, "
                           f"æŠ€èƒ½è®¡æ—¶å™¨={stats['current_skill_timer']}, "
                           f"ç´¯ç§¯å¥–åŠ±={stats['current_accumulated_reward']:.3f}")
        if len(self.rollout_workers) > 5:
            self.logger.info(f"  ... è¿˜æœ‰ {len(self.rollout_workers) - 5} ä¸ªworkers")
        
        # Training workersç»Ÿè®¡
        self.logger.info("Training Workers:")
        for i, worker in enumerate(self.training_workers[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            self.logger.info(f"  Worker {i}: æ›´æ–°={worker.updates_performed}, "
                           f"å¤„ç†æ ·æœ¬={worker.samples_processed}")
        if len(self.training_workers) > 5:
            self.logger.info(f"  ... è¿˜æœ‰ {len(self.training_workers) - 5} ä¸ªworkers")
        
        # æŠ€èƒ½å‘¨æœŸç»Ÿè®¡
        total_high_level_exp = sum(worker.high_level_experiences_generated for worker in self.rollout_workers)
        active_skills = [worker.current_team_skill for worker in self.rollout_workers if worker.current_team_skill is not None]
        skill_distribution = {}
        for skill in active_skills:
            skill_distribution[skill] = skill_distribution.get(skill, 0) + 1
        
        self.logger.info(f"æŠ€èƒ½å‘¨æœŸç»Ÿè®¡: æ€»é«˜å±‚ç»éªŒ={total_high_level_exp}, "
                        f"æ´»è·ƒæŠ€èƒ½åˆ†å¸ƒ={skill_distribution}")
        
        # ä»£ç†ç»éªŒå­˜å‚¨ç»Ÿè®¡
        self.logger.info(f"ä»£ç†ç»éªŒå­˜å‚¨: é«˜å±‚={self.agent_proxy.high_level_experiences_stored}, "
                        f"ä½å±‚={self.agent_proxy.low_level_experiences_stored}")
        
        # ç¼“å†²åŒºè¯¦ç»†ç»Ÿè®¡
        buffer_stats = self.data_buffer.get_stats()
        self.logger.info(f"Data Buffer: {buffer_stats}")
        
        # GPUå†…å­˜ä½¿ç”¨ï¼ˆå¦‚æœæœ‰GPUï¼‰
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated(self.device) / 1024**3
            memory_reserved = torch.cuda.memory_reserved(self.device) / 1024**3
            self.logger.info(f"GPUå†…å­˜: å·²åˆ†é…={memory_allocated:.2f}GB, å·²ä¿ç•™={memory_reserved:.2f}GB")
    
    def check_thread_health(self):
        """æ£€æŸ¥çº¿ç¨‹å¥åº·çŠ¶æ€"""
        # æ£€æŸ¥rolloutçº¿ç¨‹
        dead_rollout_threads = [i for i, thread in enumerate(self.rollout_threads) if not thread.is_alive()]
        if dead_rollout_threads:
            self.logger.warning(f"å‘ç° {len(dead_rollout_threads)} ä¸ªæ­»äº¡çš„rolloutçº¿ç¨‹: {dead_rollout_threads}")
        
        # æ£€æŸ¥trainingçº¿ç¨‹
        dead_training_threads = [i for i, thread in enumerate(self.training_threads) if not thread.is_alive()]
        if dead_training_threads:
            self.logger.warning(f"å‘ç° {len(dead_training_threads)} ä¸ªæ­»äº¡çš„trainingçº¿ç¨‹: {dead_training_threads}")
        
        # æ£€æŸ¥æ•°æ®æµæ˜¯å¦æ­£å¸¸
        buffer_stats = self.data_buffer.get_stats()
        if buffer_stats['total_added'] == getattr(self, '_last_total_added', 0):
            self.logger.warning("æ•°æ®ç¼“å†²åŒºæ·»åŠ æ•°é‡æœªå¢åŠ ï¼Œå¯èƒ½rolloutçº¿ç¨‹æœ‰é—®é¢˜")
        if buffer_stats['total_consumed'] == getattr(self, '_last_total_consumed', 0):
            self.logger.warning("æ•°æ®ç¼“å†²åŒºæ¶ˆè´¹æ•°é‡æœªå¢åŠ ï¼Œå¯èƒ½trainingçº¿ç¨‹æœ‰é—®é¢˜")
        
        self._last_total_added = buffer_stats['total_added']
        self._last_total_consumed = buffer_stats['total_consumed']
    
    def stop_training(self):
        """åœæ­¢è®­ç»ƒ"""
        self.logger.info("åœæ­¢è®­ç»ƒ...")
        
        # è®¾ç½®åœæ­¢äº‹ä»¶
        self.control_events['stop'].set()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
        self.logger.info("ç­‰å¾…rolloutçº¿ç¨‹ç»“æŸ...")
        for i, thread in enumerate(self.rollout_threads):
            thread.join(timeout=10)
            if thread.is_alive():
                self.logger.warning(f"Rolloutçº¿ç¨‹ {i} æœªèƒ½åœ¨10ç§’å†…ç»“æŸ")
        
        self.logger.info("ç­‰å¾…trainingçº¿ç¨‹ç»“æŸ...")
        for i, thread in enumerate(self.training_threads):
            thread.join(timeout=10)
            if thread.is_alive():
                self.logger.warning(f"Trainingçº¿ç¨‹ {i} æœªèƒ½åœ¨10ç§’å†…ç»“æŸ")
        
        self.logger.info("æ‰€æœ‰çº¿ç¨‹å·²åœæ­¢")
    
    def save_final_model(self):
        """ä¿å­˜æœ€ç»ˆæ¨¡å‹"""
        try:
            final_model_path = os.path.join(self.log_dir, 'final_model.pt')
            self.agent.save_model(final_model_path)
            self.logger.info(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜æœ€ç»ˆæ¨¡å‹å¤±è´¥: {e}")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # 1. åœæ­¢è®­ç»ƒï¼ˆå¦‚æœè¿˜æ²¡åœæ­¢ï¼‰
            if not self.control_events['stop'].is_set():
                self.stop_training()
            
            # 2. å…³é—­TensorBoard writer
            if hasattr(self.agent, 'writer') and self.agent.writer:
                try:
                    self.agent.writer.close()
                    self.logger.info("TensorBoard writerå·²å…³é—­")
                except Exception as e:
                    self.logger.warning(f"å…³é—­TensorBoard writeræ—¶å‡ºé”™: {e}")
            
            # 3. æ¸…ç†ä»£ç†ç¼“å†²åŒº
            if hasattr(self.agent, 'high_level_buffer'):
                self.agent.high_level_buffer.clear()
            if hasattr(self.agent, 'low_level_buffer'):
                self.agent.low_level_buffer.clear()
            if hasattr(self.agent, 'state_skill_dataset'):
                self.agent.state_skill_dataset.clear()
            
            self.logger.info("æ‰€æœ‰èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
    
    def train(self, total_steps=100000):
        """
        æ‰§è¡Œå®Œæ•´çš„å¤šçº¿ç¨‹rollout-basedè®­ç»ƒ
        
        å‚æ•°:
            total_steps: è®­ç»ƒæ€»æ­¥æ•°
        """
        self.logger.info(f"å¼€å§‹HMASDå¤šçº¿ç¨‹Rollout-basedè®­ç»ƒ: {total_steps:,} æ­¥")
        self.logger.info(f"é…ç½®: {self.num_training_threads} è®­ç»ƒçº¿ç¨‹, {self.num_rollout_threads} rolloutçº¿ç¨‹")
        
        try:
            # åˆå§‹åŒ–ä»£ç†
            self.initialize_agent()
            
            # å¯åŠ¨rolloutçº¿ç¨‹
            self.start_rollout_threads()
            
            # ç­‰å¾…rolloutçº¿ç¨‹å¼€å§‹æ”¶é›†æ•°æ®
            time.sleep(5)
            
            # å¯åŠ¨trainingçº¿ç¨‹
            self.start_training_threads()
            
            # å¼€å§‹ç›‘æ§è®­ç»ƒ
            self.monitor_training(total_steps)
            
        except KeyboardInterrupt:
            self.logger.info("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            self.logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            self.save_final_model()
            
            # æ¸…ç†èµ„æº
            self.cleanup()
        
        # è®­ç»ƒå®Œæˆ
        if self.start_time:
            total_time = time.time() - self.start_time
            final_steps = sum(worker.samples_collected for worker in self.rollout_workers)
            self.logger.info(f"\nè®­ç»ƒå®Œæˆï¼")
            self.logger.info(f"æ€»æ—¶é—´: {total_time/3600:.2f}å°æ—¶")
            self.logger.info(f"æ€»æ­¥æ•°: {final_steps:,}")
            
            # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
            total_samples = sum(worker.samples_collected for worker in self.rollout_workers)
            total_episodes = sum(worker.episodes_completed for worker in self.rollout_workers)
            total_updates = sum(worker.updates_performed for worker in self.training_workers)
            
            self.logger.info(f"æ€»æ ·æœ¬æ•°: {total_samples:,}")
            self.logger.info(f"æ€»Episodes: {total_episodes:,}")
            self.logger.info(f"æ€»æ›´æ–°æ•°: {total_updates}")
            
            if total_time > 0:
                self.logger.info(f"æ ·æœ¬æ”¶é›†é€Ÿåº¦: {total_samples/total_time:.1f} æ ·æœ¬/ç§’")
                self.logger.info(f"Episodeå®Œæˆé€Ÿåº¦: {total_episodes/total_time:.1f} episodes/ç§’")
                self.logger.info(f"æ­¥æ•°å®Œæˆé€Ÿåº¦: {final_steps/total_time:.1f} æ­¥/ç§’")

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='HMASDå¤šçº¿ç¨‹Rollout-basedè®­ç»ƒï¼ˆæŒ‰è®ºæ–‡Appendix Eï¼‰')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--steps', type=int, default=None, help='è®­ç»ƒæ€»æ­¥æ•°ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œå°†ä»config.pyä¸­è¯»å–ï¼‰')
    parser.add_argument('--device', type=str, default='auto', choices=['auto', 'cpu', 'cuda'])
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    
    # çº¿ç¨‹é…ç½®ï¼ˆæŒ‰ç…§è®ºæ–‡ Appendix Eï¼‰
    parser.add_argument('--training_threads', type=int, default=16, help='è®­ç»ƒçº¿ç¨‹æ•°ï¼ˆè®ºæ–‡é»˜è®¤16ï¼‰')
    parser.add_argument('--rollout_threads', type=int, default=32, help='Rolloutçº¿ç¨‹æ•°ï¼ˆè®ºæ–‡é»˜è®¤32ï¼‰')
    parser.add_argument('--buffer_size', type=int, default=10000, help='æ•°æ®ç¼“å†²åŒºå¤§å°')
    
    # ç¯å¢ƒå‚æ•°
    parser.add_argument('--scenario', type=int, default=2, choices=[1, 2], help='åœºæ™¯é€‰æ‹©')
    parser.add_argument('--n_uavs', type=int, default=5, help='æ— äººæœºæ•°é‡')
    parser.add_argument('--n_users', type=int, default=50, help='ç”¨æˆ·æ•°é‡')
    parser.add_argument('--user_distribution', type=str, default='uniform', 
                       choices=['uniform', 'cluster', 'hotspot'])
    parser.add_argument('--channel_model', type=str, default='3gpp-36777',
                       choices=['free_space', 'urban', 'suburban', '3gpp-36777'])
    parser.add_argument('--max_hops', type=int, default=3, help='æœ€å¤§è·³æ•°ï¼ˆä»…åœºæ™¯2ï¼‰')
    
    # æ—¥å¿—å‚æ•°
    parser.add_argument('--log_level', type=str, default='INFO',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'])
    parser.add_argument('--console_log_level', type=str, default='INFO',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'])
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # åˆ›å»ºé…ç½®
    config = Config()
    
    # ç¡®å®šè®­ç»ƒæ­¥æ•°ï¼šä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
    if args.steps is not None:
        total_steps = args.steps
        print(f"ğŸ“ˆ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„è®­ç»ƒæ­¥æ•°: {total_steps:,}")
    else:
        total_steps = int(config.total_timesteps)
        print(f"ğŸ“ˆ ä»config.pyè¯»å–è®­ç»ƒæ­¥æ•°: {total_steps:,}")
    
    print("ğŸš€ HMASDå¤šçº¿ç¨‹Rollout-basedè®­ç»ƒï¼ˆä¸¥æ ¼æŒ‰è®ºæ–‡å®ç°ï¼‰")
    print("=" * 60)
    print(f"ğŸ“Š çº¿ç¨‹é…ç½®: {args.training_threads} è®­ç»ƒçº¿ç¨‹ + {args.rollout_threads} rolloutçº¿ç¨‹")
    print(f"ğŸ¯ è®­ç»ƒæ­¥æ•°: {total_steps:,}")
    print(f"ğŸ—‚ï¸ ç¼“å†²åŒºå¤§å°: {args.buffer_size}")
    
    # éªŒè¯å¹¶æ‰“å°é…ç½®
    config.validate_training_mode()
    config.validate_rollout_config()
    print(config.get_rollout_summary())
    
    try:
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = ThreadedRolloutTrainer(config, args)
        
        # å¼€å§‹è®­ç»ƒ
        trainer.train(total_steps=total_steps)
        
        print("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        try:
            shutdown_logging()
        except:
            pass

if __name__ == "__main__":
    main()

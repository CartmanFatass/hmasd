# MAPPOè®­ç»ƒè„šæœ¬ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨åŸºäºMAPPOï¼ˆMulti-Agent Proximal Policy Optimizationï¼‰çš„å¢å¼ºè®­ç»ƒè„šæœ¬è¿›è¡Œæ— äººæœºç½‘ç»œä¼˜åŒ–è®­ç»ƒã€‚

## ğŸ†š MAPPO vs IPPO

- **IPPO (Independent PPO)**: `train_ppo_enhanced_tracking.py` - æ¯ä¸ªæ™ºèƒ½ä½“ç‹¬ç«‹è®­ç»ƒ
- **MAPPO (Multi-Agent PPO)**: `train_mappo_enhanced_tracking.py` - å¤šæ™ºèƒ½ä½“åä½œè®­ç»ƒï¼ˆæ¨èï¼‰

### ä¸»è¦åŒºåˆ«

| ç‰¹æ€§ | IPPO | MAPPO |
|------|------|-------|
| ç½‘ç»œç»“æ„ | ç‹¬ç«‹Actor-Critic | å…±äº«Criticï¼Œç‹¬ç«‹Actor |
| çŠ¶æ€ä¿¡æ¯ | å±€éƒ¨è§‚æµ‹ | å…¨å±€çŠ¶æ€ + å±€éƒ¨è§‚æµ‹ |
| åè°ƒæœºåˆ¶ | éšå¼ï¼ˆé€šè¿‡ç¯å¢ƒï¼‰ | æ˜¾å¼ï¼ˆé€šè¿‡å…±äº«Criticï¼‰ |
| è®­ç»ƒç¨³å®šæ€§ | è¾ƒä½ | è¾ƒé«˜ |
| å¤šæ™ºèƒ½ä½“åä½œ | å¼± | å¼º |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š

```bash
pip install torch
pip install numpy
pip install pandas
pip install matplotlib
pip install tensorboard
```

### 2. åŸºæœ¬è®­ç»ƒ

è¿è¡ŒåŸºæœ¬çš„MAPPOè®­ç»ƒï¼š

```bash
python train_mappo_enhanced_tracking.py --mode train --scenario 2
```

### 3. æµ‹è¯•è„šæœ¬

åˆ›å»ºMAPPOæµ‹è¯•è„šæœ¬éªŒè¯ç¯å¢ƒé…ç½®ï¼š

```bash
python test_mappo_training.py
```

## ğŸ“‹ å‘½ä»¤è¡Œå‚æ•°

### åŸºæœ¬å‚æ•°

- `--mode`: è¿è¡Œæ¨¡å¼ (`train` æˆ– `eval`)
- `--scenario`: åœºæ™¯é€‰æ‹© (1=åŸºç«™æ¨¡å¼, 2=åä½œç»„ç½‘æ¨¡å¼)
- `--model_path`: æ¨¡å‹ä¿å­˜/åŠ è½½è·¯å¾„ (é»˜è®¤: `models/mappo_enhanced_tracking.pt`)
- `--log_dir`: æ—¥å¿—ç›®å½• (é»˜è®¤: `logs`)
- `--device`: è®¡ç®—è®¾å¤‡ (`auto`, `cuda`, `cpu`)

### ç¯å¢ƒå‚æ•°

- `--n_uavs`: æ— äººæœºæ•°é‡ (é»˜è®¤: 5)
- `--n_users`: ç”¨æˆ·æ•°é‡ (é»˜è®¤: 50)
- `--max_hops`: æœ€å¤§è·³æ•°ï¼Œä»…åœºæ™¯2ä½¿ç”¨ (é»˜è®¤: 3)
- `--user_distribution`: ç”¨æˆ·åˆ†å¸ƒ (`uniform`, `cluster`, `hotspot`)
- `--channel_model`: ä¿¡é“æ¨¡å‹ (`free_space`, `urban`, `suburban`, `3gpp-36777`)

### MAPPOè¶…å‚æ•°

- `--learning_rate`: å­¦ä¹ ç‡ (é»˜è®¤: 3e-4)
- `--gamma`: æŠ˜æ‰£å› å­ (é»˜è®¤: 0.99)
- `--gae_lambda`: GAEå‚æ•° (é»˜è®¤: 0.95)
- `--clip_epsilon`: PPOè£å‰ªå‚æ•° (é»˜è®¤: 0.2)
- `--entropy_coef`: ç†µç³»æ•° (é»˜è®¤: 0.01)
- `--max_grad_norm`: æœ€å¤§æ¢¯åº¦èŒƒæ•° (é»˜è®¤: 0.5)
- `--ppo_epochs`: PPOæ›´æ–°è½®æ•° (é»˜è®¤: 10)
- `--buffer_size`: ç¼“å†²åŒºå¤§å° (é»˜è®¤: 2048)

### å¹¶è¡ŒåŒ–å‚æ•°

- `--num_envs`: å¹¶è¡Œç¯å¢ƒæ•°é‡ (é»˜è®¤: 8)

### æ•°æ®æ”¶é›†å‚æ•°

- `--export_interval`: æ•°æ®å¯¼å‡ºé—´éš”æ­¥æ•° (é»˜è®¤: 1000)
- `--detailed_logging`: å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŸºæœ¬MAPPOè®­ç»ƒ

```bash
python train_mappo_enhanced_tracking.py \
  --mode train \
  --scenario 2 \
  --n_uavs 5 \
  --n_users 50 \
  --learning_rate 3e-4 \
  --num_envs 8
```

### ç¤ºä¾‹2ï¼šé«˜æ€§èƒ½MAPPOè®­ç»ƒ

```bash
python train_mappo_enhanced_tracking.py \
  --mode train \
  --scenario 2 \
  --n_uavs 8 \
  --n_users 100 \
  --learning_rate 5e-4 \
  --num_envs 16 \
  --buffer_size 4096 \
  --ppo_epochs 15 \
  --device cuda
```

### ç¤ºä¾‹3ï¼šMAPPOæ¨¡å‹è¯„ä¼°

```bash
python train_mappo_enhanced_tracking.py \
  --mode eval \
  --scenario 2 \
  --model_path models/mappo_enhanced_tracking.pt \
  --eval_episodes 50 \
  --render
```

### ç¤ºä¾‹4ï¼šè°ƒè¯•æ¨¡å¼

```bash
python train_mappo_enhanced_tracking.py \
  --mode train \
  --scenario 1 \
  --n_uavs 3 \
  --n_users 10 \
  --num_envs 2 \
  --export_interval 100 \
  --detailed_logging \
  --log_level debug
```

## ğŸ“Š è¾“å‡ºæ–‡ä»¶ç»“æ„

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
logs/mappo_enhanced_tracking_YYYYMMDD-HHMMSS/
â”œâ”€â”€ paper_data/                        # è®ºæ–‡æ•°æ®
â”‚   â”œâ”€â”€ episode_rewards_step_*.csv
â”‚   â”œâ”€â”€ agent_coordination_step_*.csv  # MAPPOç‰¹æœ‰
â”‚   â”œâ”€â”€ mappo_training_progress_step_*.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ training_summary.json              # è®­ç»ƒæ‘˜è¦
â”œâ”€â”€ mappo_enhanced_tracking_*.log      # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ events.out.tfevents.*              # TensorBoardæ—¥å¿—
â””â”€â”€ runs/                               # TensorBoardè¿è¡Œæ•°æ®

models/
â”œâ”€â”€ mappo_enhanced_tracking.pt          # æœ€ç»ˆæ¨¡å‹
â””â”€â”€ ...
```

## ğŸ—ï¸ MAPPOç½‘ç»œæ¶æ„

### Actorç½‘ç»œ
```
è§‚æµ‹ (obs_dim) â†’ FC(64) â†’ ReLU â†’ FC(64) â†’ ReLU â†’ FC(action_dim) â†’ åŠ¨ä½œå‡å€¼
                                                 â†“
                                            å­¦ä¹ çš„log_std â†’ åŠ¨ä½œæ ‡å‡†å·®
```

### Criticç½‘ç»œ
```
å…¨å±€çŠ¶æ€ (state_dim) â†’ FC(64) â†’ ReLU â†’ FC(64) â†’ ReLU â†’ FC(1) â†’ çŠ¶æ€å€¼
```

### å…³é”®ç‰¹æ€§
- **å…±äº«Critic**: ä½¿ç”¨å…¨å±€çŠ¶æ€ä¿¡æ¯ï¼Œæä¾›æ›´å¥½çš„å€¼å‡½æ•°ä¼°è®¡
- **ç‹¬ç«‹Actor**: æ¯ä¸ªæ™ºèƒ½ä½“æœ‰ç‹¬ç«‹çš„ç­–ç•¥ç½‘ç»œ
- **GAEä¼˜åŠ¿ä¼°è®¡**: ä½¿ç”¨Generalized Advantage Estimation
- **PPOå‰ªè£**: é˜²æ­¢ç­–ç•¥æ›´æ–°è¿‡å¤§

## ğŸ“ˆ ç›‘æ§è®­ç»ƒè¿‡ç¨‹

### TensorBoard

å¯åŠ¨TensorBoardç›‘æ§MAPPOè®­ç»ƒè¿‡ç¨‹ï¼š

```bash
tensorboard --logdir=logs/mappo_enhanced_tracking_YYYYMMDD-HHMMSS
```

ä¸»è¦æŒ‡æ ‡ï¼š
- `Training/Actor_Loss`: Actorç½‘ç»œæŸå¤±
- `Training/Critic_Loss`: Criticç½‘ç»œæŸå¤±
- `Training/Entropy`: ç­–ç•¥ç†µï¼ˆæ¢ç´¢åº¦ï¼‰
- `Training/Clip_Fraction`: PPOè£å‰ªæ¯”ä¾‹
- `Training/KL_Divergence`: ç­–ç•¥å˜åŒ–ç¨‹åº¦

### å®æ—¶æ—¥å¿—

è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…³é”®ä¿¡æ¯ï¼š

```
MAPPOæ¨¡å‹å·²åˆ›å»ºï¼Œè®¾å¤‡: cuda
å¼€å§‹è®­ç»ƒï¼Œæ€»æ—¶é—´æ­¥æ•°: 3000000
Episode 1: ç¯å¢ƒ0, å¥–åŠ±=85.34, é•¿åº¦=245
æ­¥éª¤ 2048: ActoræŸå¤±=0.0234, CriticæŸå¤±=0.1567
æ™ºèƒ½ä½“åè°ƒæŒ‡æ ‡: 0.847
Episode 2: ç¯å¢ƒ1, å¥–åŠ±=92.15, é•¿åº¦=312
...
```

## ğŸ¯ ä¸å…¶ä»–ç®—æ³•çš„æ¯”è¾ƒ

| ç‰¹æ€§ | HMASD | IPPO | MAPPO |
|------|-------|------|-------|
| ç®—æ³•ç±»å‹ | åˆ†å±‚æŠ€èƒ½å‘ç° | ç‹¬ç«‹ç­–ç•¥ä¼˜åŒ– | å¤šæ™ºèƒ½ä½“ç­–ç•¥ä¼˜åŒ– |
| æŠ€èƒ½å‘ç° | âœ… æ”¯æŒ | âŒ ä¸æ”¯æŒ | âŒ ä¸æ”¯æŒ |
| å¤šæ™ºèƒ½ä½“åè°ƒ | æ˜¾å¼å±‚æ¬¡ç»“æ„ | éšå¼å­¦ä¹  | å…±äº«Criticåè°ƒ |
| å®ç°å¤æ‚åº¦ | é«˜ | ä½ | ä¸­ç­‰ |
| è®­ç»ƒç¨³å®šæ€§ | ä¸­ç­‰ | ä¸­ç­‰ | é«˜ |
| æ”¶æ•›é€Ÿåº¦ | æ…¢ | å¿« | ä¸­ç­‰ |
| åä½œæ•ˆæœ | å¼º | å¼± | å¼º |

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```
   RuntimeError: CUDA out of memory
   ```
   è§£å†³æ–¹æ¡ˆï¼š
   - å‡å°‘ `--num_envs` æˆ– `--buffer_size`
   - ä½¿ç”¨ `--device cpu`

2. **è®­ç»ƒä¸ç¨³å®š**
   ```
   ActoræŸå¤±å‰§çƒˆæ³¢åŠ¨
   ```
   è§£å†³æ–¹æ¡ˆï¼š
   - é™ä½å­¦ä¹ ç‡
   - å¢åŠ  `--ppo_epochs`
   - è°ƒæ•´ `--clip_epsilon`

3. **æ™ºèƒ½ä½“åè°ƒå·®**
   ```
   åè°ƒæŒ‡æ ‡æŒç»­å¾ˆä½
   ```
   è§£å†³æ–¹æ¡ˆï¼š
   - æ£€æŸ¥å¥–åŠ±å‡½æ•°è®¾è®¡
   - å¢åŠ å…¨å±€çŠ¶æ€ä¿¡æ¯
   - è°ƒæ•´ç½‘ç»œæ¶æ„

### MAPPOç‰¹å®šä¼˜åŒ–å»ºè®®

1. **å…±äº«Criticæ•ˆæœ**ï¼šç¡®ä¿å…¨å±€çŠ¶æ€åŒ…å«è¶³å¤Ÿçš„ç¯å¢ƒä¿¡æ¯
2. **ç­–ç•¥åŒæ­¥**ï¼šä½¿ç”¨ç›¸åŒçš„éšæœºç§å­ç¡®ä¿ç­–ç•¥ä¸€è‡´æ€§
3. **ç»éªŒæ”¶é›†**ï¼šå¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨ï¼Œè°ƒæ•´ç†µç³»æ•°
4. **ç½‘ç»œæ›´æ–°**ï¼šä½¿ç”¨é€‚å½“çš„æ›´æ–°é¢‘ç‡å’Œæ‰¹æ¬¡å¤§å°

## ğŸ“ å¼€å‘æ³¨æ„äº‹é¡¹

### æ‰©å±•MAPPOè„šæœ¬

å¦‚éœ€æ·»åŠ æ–°çš„åŠŸèƒ½ï¼š

1. **è‡ªå®šä¹‰ç½‘ç»œæ¶æ„**ï¼šä¿®æ”¹`MAPPOActor`å’Œ`MAPPOCritic`ç±»
2. **æ–°çš„åè°ƒæœºåˆ¶**ï¼šæ‰©å±•å…±äº«Criticçš„è¾“å…¥ä¿¡æ¯
3. **ä¸åŒçš„å¥–åŠ±è®¾è®¡**ï¼šè°ƒæ•´ç¯å¢ƒçš„å¥–åŠ±å‡½æ•°
4. **è¯„ä¼°æŒ‡æ ‡**ï¼šæ‰©å±•`EnhancedRewardTracker`ç±»

### è°ƒè¯•æŠ€å·§

1. ä½¿ç”¨å°çš„å‚æ•°å€¼è¿›è¡Œå¿«é€Ÿæµ‹è¯•
2. ç›‘æ§æ™ºèƒ½ä½“åè°ƒæŒ‡æ ‡
3. æ£€æŸ¥Actorå’ŒCriticæŸå¤±çš„å˜åŒ–è¶‹åŠ¿
4. ä½¿ç”¨TensorBoardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹

## ğŸ”¬ å®éªŒå»ºè®®

### è¶…å‚æ•°è°ƒä¼˜

1. **å­¦ä¹ ç‡**: ä»1e-4åˆ°1e-3èŒƒå›´å†…è°ƒæ•´
2. **è£å‰ªå‚æ•°**: 0.1-0.3ä¹‹é—´å°è¯•ä¸åŒå€¼
3. **ç†µç³»æ•°**: æ ¹æ®æ¢ç´¢éœ€æ±‚è°ƒæ•´
4. **æ›´æ–°è½®æ•°**: 5-15è½®ä¹‹é—´é€‰æ‹©

### æ€§èƒ½åŸºå‡†

å»ºè®®åœ¨ä»¥ä¸‹é…ç½®ä¸‹è¿›è¡Œæ€§èƒ½æµ‹è¯•ï¼š
- 5ä¸ªæ— äººæœºï¼Œ50ä¸ªç”¨æˆ·
- 8ä¸ªå¹¶è¡Œç¯å¢ƒ
- åœºæ™¯2ï¼ˆåä½œç»„ç½‘ï¼‰
- è®­ç»ƒ300ä¸‡æ­¥

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªä¸ä¸»é¡¹ç›®ç›¸åŒçš„è®¸å¯è¯ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤é—®é¢˜æŠ¥å‘Šå’Œæ”¹è¿›å»ºè®®ï¼ç‰¹åˆ«æ˜¯å…³äºMAPPOç®—æ³•ä¼˜åŒ–çš„å»ºè®®ã€‚

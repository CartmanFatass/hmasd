#!/usr/bin/env python3
"""
ã€é˜¶æ®µ4ã€‘çº¿ç¨‹å®‰å…¨çš„HMASD Agentå®ç°
ç»§æ‰¿åŸæœ‰HMASDAgentå¹¶æ·»åŠ çº¿ç¨‹å®‰å…¨åŠŸèƒ½

æ ¸å¿ƒç‰¹æ€§ï¼š
1. ç»§æ‰¿æ‰€æœ‰åŸæœ‰åŠŸèƒ½
2. çº¿ç¨‹å®‰å…¨çš„bufferæ“ä½œ
3. åŸå­æ€§å­˜å‚¨éªŒè¯
4. æ•°æ®å®Œæ•´æ€§ä¿éšœ
"""

import time
import numpy as np
from hmasd.agent import HMASDAgent
from hmasd.thread_safe_agent import ThreadSafeAgentMixin
from logger import get_logger

class ThreadSafeHMASDAgent(HMASDAgent, ThreadSafeAgentMixin):
    """ã€é˜¶æ®µ4ã€‘çº¿ç¨‹å®‰å…¨çš„HMASD Agent
    
    ç»§æ‰¿HMASDAgentçš„æ‰€æœ‰åŠŸèƒ½ï¼Œå¹¶æ·»åŠ çº¿ç¨‹å®‰å…¨æ”¯æŒ
    """
    
    def __init__(self, config, log_dir='logs', device=None, debug=False):
        """åˆå§‹åŒ–çº¿ç¨‹å®‰å…¨çš„HMASD Agent"""
        # é¦–å…ˆåˆå§‹åŒ–çˆ¶ç±»
        super().__init__(config, log_dir, device, debug)
        
        # ç„¶ååˆå§‹åŒ–çº¿ç¨‹å®‰å…¨ç»„ä»¶
        self.__init_thread_safety__()
        
        self.logger = get_logger("ThreadSafeHMASDAgent")
        self.logger.info("çº¿ç¨‹å®‰å…¨HMASD Agentåˆå§‹åŒ–å®Œæˆ")
    
    def store_high_level_transition(self, state, team_skill, observations, agent_skills, 
                                   accumulated_reward, skill_log_probs=None, worker_id=0):
        """ã€é˜¶æ®µ4é‡å†™ã€‘ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„é«˜å±‚ç»éªŒå­˜å‚¨"""
        return self.store_high_level_transition_safe(
            state, team_skill, observations, agent_skills, 
            accumulated_reward, skill_log_probs, worker_id
        )
    
    def store_low_level_transition(self, state, next_state, observations, next_observations,
                                 actions, rewards, dones, team_skill, agent_skills, 
                                 action_logprobs, skill_log_probs=None, worker_id=0):
        """ã€é˜¶æ®µ4é‡å†™ã€‘ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„ä½å±‚ç»éªŒå­˜å‚¨"""
        return self.store_low_level_transition_safe(
            state, next_state, observations, next_observations,
            actions, rewards, dones, team_skill, agent_skills, 
            action_logprobs, skill_log_probs, worker_id
        )
    
    def rollout_update(self):
        """ã€é˜¶æ®µ4å¢å¼ºã€‘çº¿ç¨‹å®‰å…¨çš„rolloutæ›´æ–°"""
        if not self.rollout_based_training:
            raise ValueError("rollout_updateåªèƒ½åœ¨rollout_based_trainingæ¨¡å¼ä¸‹ä½¿ç”¨")
        
        update_start_time = time.time()
        steps_for_update = self.steps_collected
        target_samples = self.rollout_length * self.num_parallel_envs
        
        self.logger.info(f"ğŸ”„ å¼€å§‹çº¿ç¨‹å®‰å…¨Rolloutæ›´æ–° #{self.rollout_count + 1}")
        self.logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: æ”¶é›†æ­¥æ•°={steps_for_update}, ç›®æ ‡æ ·æœ¬={target_samples}, "
                        f"å¹¶è¡Œç¯å¢ƒ={self.num_parallel_envs}")
        
        # ã€é˜¶æ®µ4å¢å¼ºã€‘çº¿ç¨‹å®‰å…¨çš„æ•°æ®å®Œæ•´æ€§éªŒè¯
        data_integrity_verified = self._thread_safe_data_verification(target_samples)
        
        if not data_integrity_verified:
            self.logger.error("âŒ çº¿ç¨‹å®‰å…¨æ•°æ®éªŒè¯å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¬¡æ›´æ–°")
            return None
        
        # è®°å½•æ›´æ–°å‰çš„ç¼“å†²åŒºçŠ¶æ€ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        high_level_size_before = len(self.high_level_buffer)
        low_level_size_before = len(self.low_level_buffer)
        state_skill_size_before = len(self.state_skill_dataset)
        
        # ã€çº¿ç¨‹å®‰å…¨ç»Ÿè®¡ã€‘
        thread_safety_stats = self.get_thread_safety_stats()
        self.logger.info(f"ğŸ“ˆ çº¿ç¨‹å®‰å…¨ç»Ÿè®¡: {thread_safety_stats['storage_stats']}")
        
        # æ‰§è¡Œ15è½®PPOè®­ç»ƒï¼ˆä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„bufferï¼‰
        self.logger.info(f"ğŸ¯ å¼€å§‹{self.ppo_epochs}è½®çº¿ç¨‹å®‰å…¨PPOè®­ç»ƒ")
        
        coordinator_losses = []
        discoverer_losses = []
        discriminator_losses = []
        
        for epoch in range(self.ppo_epochs):
            epoch_start_time = time.time()
            self.logger.debug(f"   è½®æ¬¡ {epoch + 1}/{self.ppo_epochs}")
            
            # 1. æ›´æ–°é«˜å±‚ç­–ç•¥ï¼ˆä½¿ç”¨çº¿ç¨‹å®‰å…¨bufferï¼‰
            coordinator_info = self._thread_safe_update_coordinator()
            coordinator_losses.append(coordinator_info)
            
            # 2. æ›´æ–°ä½å±‚ç­–ç•¥ï¼ˆä½¿ç”¨çº¿ç¨‹å®‰å…¨bufferï¼‰
            discoverer_info = self._thread_safe_update_discoverer()
            discoverer_losses.append(discoverer_info)
            
            # 3. æ›´æ–°åˆ¤åˆ«å™¨ï¼ˆä½¿ç”¨çº¿ç¨‹å®‰å…¨datasetï¼‰
            discriminator_loss = self._thread_safe_update_discriminators()
            discriminator_losses.append(discriminator_loss)
            
            epoch_time = time.time() - epoch_start_time
            
            if epoch % 5 == 0 or epoch == self.ppo_epochs - 1:
                self.logger.debug(f"   è½®æ¬¡ {epoch + 1} å®Œæˆï¼Œè€—æ—¶: {epoch_time:.3f}s")
        
        # ã€é˜¶æ®µ4å…³é”®ã€‘çº¿ç¨‹å®‰å…¨çš„ç¼“å†²åŒºæ¸…ç©º
        self.logger.info("ğŸ§¹ çº¿ç¨‹å®‰å…¨æ¸…ç©ºPPOç¼“å†²åŒº")
        clear_success = self.clear_buffers_safe()
        
        if not clear_success:
            self.logger.error("âŒ çº¿ç¨‹å®‰å…¨ç¼“å†²åŒºæ¸…ç©ºå¤±è´¥ï¼")
        else:
            self.logger.info("âœ… çº¿ç¨‹å®‰å…¨ç¼“å†²åŒºæ¸…ç©ºæˆåŠŸ")
        
        # éªŒè¯æ¸…ç©ºç»“æœ
        high_level_size_after = len(self.high_level_buffer)
        low_level_size_after = len(self.low_level_buffer)
        state_skill_size_after = len(self.state_skill_dataset)
        
        # é‡ç½®rolloutçŠ¶æ€
        steps_before_reset = self.steps_collected
        self.steps_collected = 0
        self.rollout_count += 1
        self.total_steps_collected += steps_for_update
        update_duration = time.time() - update_start_time
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_coordinator_info = self._average_update_info(coordinator_losses)
        avg_discoverer_info = self._average_update_info(discoverer_losses)
        avg_discriminator_loss = np.mean(discriminator_losses) if discriminator_losses else 0.0
        
        # è®¡ç®—æ ·æœ¬ä½¿ç”¨æ•ˆç‡
        samples_per_second = target_samples / update_duration if update_duration > 0 else 0
        
        self.logger.info(f"ğŸ‰ çº¿ç¨‹å®‰å…¨Rolloutæ›´æ–° #{self.rollout_count} å®Œæˆ")
        self.logger.info(f"â±ï¸ è€—æ—¶: {update_duration:.2f}s, æ•ˆç‡: {samples_per_second:.0f} æ ·æœ¬/ç§’")
        self.logger.info(f"ğŸ“ˆ ç´¯è®¡: rollouts={self.rollout_count}, æ€»æ­¥æ•°={self.total_steps_collected:,}")
        
        # æ„å»ºè¯¦ç»†çš„æ›´æ–°ä¿¡æ¯
        update_info = {
            'update_type': 'thread_safe_rollout_batch',
            'rollout_count': self.rollout_count,
            'steps_used': steps_for_update,
            'target_samples': target_samples,
            'total_steps': self.total_steps_collected,
            'ppo_epochs': self.ppo_epochs,
            'num_parallel_envs': self.num_parallel_envs,
            'update_duration': update_duration,
            'samples_per_second': samples_per_second,
            'buffer_changes': {
                'high_level': (high_level_size_before, high_level_size_after),
                'low_level': (low_level_size_before, low_level_size_after),
                'state_skill': (state_skill_size_before, state_skill_size_after)
            },
            'coordinator': avg_coordinator_info,
            'discoverer': avg_discoverer_info,
            'discriminator': {'discriminator_loss': avg_discriminator_loss},
            'thread_safety': {
                'buffer_cleared_safely': clear_success,
                'data_integrity_verified': data_integrity_verified,
                'thread_safety_stats': thread_safety_stats
            }
        }
        
        return update_info
    
    def _thread_safe_data_verification(self, target_samples):
        """ã€é˜¶æ®µ4æ–°å¢ã€‘çº¿ç¨‹å®‰å…¨çš„æ•°æ®å®Œæ•´æ€§éªŒè¯"""
        max_wait_time = 15.0
        wait_start = time.time()
        
        self.logger.info(f"ğŸ” [çº¿ç¨‹å®‰å…¨] å¼€å§‹æ•°æ®å®Œæ•´æ€§éªŒè¯: æœŸæœ›æ­¥æ•°={target_samples}")
        
        expected_high_level = target_samples // self.config.k
        
        verification_attempts = 0
        max_verification_attempts = 10
        
        while verification_attempts < max_verification_attempts and time.time() - wait_start < max_wait_time:
            # çº¿ç¨‹å®‰å…¨åœ°è·å–ç¼“å†²åŒºçŠ¶æ€
            current_low_level = len(self.low_level_buffer)
            current_high_level = len(self.high_level_buffer)
            
            self.logger.debug(f"ğŸ” [çº¿ç¨‹å®‰å…¨] éªŒè¯#{verification_attempts + 1}: "
                           f"ä½å±‚={current_low_level}/{target_samples}, "
                           f"é«˜å±‚={current_high_level}/{expected_high_level}")
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            low_level_sufficient = current_low_level >= target_samples * 0.98
            high_level_sufficient = current_high_level >= expected_high_level * 0.95
            
            if low_level_sufficient and high_level_sufficient:
                wait_time = time.time() - wait_start
                self.logger.info(f"âœ… [çº¿ç¨‹å®‰å…¨] æ•°æ®éªŒè¯é€šè¿‡ï¼Œç­‰å¾…æ—¶é—´: {wait_time:.2f}s")
                return True
            
            verification_attempts += 1
            if verification_attempts < max_verification_attempts:
                time.sleep(1.0)
        
        # æœ€ç»ˆæ£€æŸ¥
        final_low_level = len(self.low_level_buffer)
        final_high_level = len(self.high_level_buffer)
        
        low_level_missing = target_samples - final_low_level
        high_level_missing = expected_high_level - final_high_level
        
        self.logger.warning(f"âš ï¸ [çº¿ç¨‹å®‰å…¨] æ•°æ®éªŒè¯è¶…æ—¶:")
        self.logger.warning(f"   ä½å±‚: {final_low_level}/{target_samples} (ç¼ºå¤±: {low_level_missing})")
        self.logger.warning(f"   é«˜å±‚: {final_high_level}/{expected_high_level} (ç¼ºå¤±: {high_level_missing})")
        
        # è®¡ç®—ç¼ºå¤±ç™¾åˆ†æ¯”
        total_missing = low_level_missing + high_level_missing
        total_expected = target_samples + expected_high_level
        missing_pct = (total_missing / total_expected) * 100 if total_expected > 0 else 0
        
        if missing_pct <= 3.0:  # å…è®¸3%çš„ç¼ºå¤±
            self.logger.warning(f"âš ï¸ [çº¿ç¨‹å®‰å…¨] æ•°æ®è½»å¾®ç¼ºå¤±({missing_pct:.1%})ï¼Œå…è®¸ç»§ç»­è®­ç»ƒ")
            return True
        else:
            self.logger.error(f"âŒ [çº¿ç¨‹å®‰å…¨] æ•°æ®ä¸¥é‡ç¼ºå¤±({missing_pct:.1%})ï¼Œæ‹’ç»æ­¤æ¬¡æ›´æ–°")
            return False
    
    def _thread_safe_update_coordinator(self):
        """ã€é˜¶æ®µ4æ–°å¢ã€‘çº¿ç¨‹å®‰å…¨çš„åè°ƒå™¨æ›´æ–°"""
        # ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„bufferè¿›è¡Œæ›´æ–°
        required_batch_size = self.config.high_level_batch_size
        current_buffer_size = len(self.high_level_buffer)
        
        if current_buffer_size == 0:
            self.logger.debug(f"[çº¿ç¨‹å®‰å…¨åè°ƒå™¨] é«˜å±‚ç¼“å†²åŒºä¸ºç©ºï¼Œè·³è¿‡æ›´æ–°")
            return self._get_default_coordinator_info()
        
        if current_buffer_size < required_batch_size:
            self.logger.warning(f"[çº¿ç¨‹å®‰å…¨åè°ƒå™¨] é«˜å±‚ç¼“å†²åŒºä¸è¶³ï¼Œéœ€è¦{required_batch_size}ä¸ªæ ·æœ¬ï¼Œ"
                              f"ä½†åªæœ‰{current_buffer_size}ä¸ªã€‚è·³è¿‡æ­¤è½®æ›´æ–°ã€‚")
            return self._get_default_coordinator_info()
        
        # è°ƒç”¨åŸæœ‰çš„åè°ƒå™¨æ›´æ–°é€»è¾‘ï¼ˆç°åœ¨ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„bufferï¼‰
        return self._update_coordinator_with_all_buffer()
    
    def _thread_safe_update_discoverer(self):
        """ã€é˜¶æ®µ4æ–°å¢ã€‘çº¿ç¨‹å®‰å…¨çš„å‘ç°å™¨æ›´æ–°"""
        if len(self.low_level_buffer) == 0:
            return self._get_default_discoverer_info()
        
        # è°ƒç”¨åŸæœ‰çš„å‘ç°å™¨æ›´æ–°é€»è¾‘ï¼ˆç°åœ¨ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„bufferï¼‰
        return self._update_discoverer_with_all_buffer()
    
    def _thread_safe_update_discriminators(self):
        """ã€é˜¶æ®µ4æ–°å¢ã€‘çº¿ç¨‹å®‰å…¨çš„åˆ¤åˆ«å™¨æ›´æ–°"""
        if len(self.state_skill_dataset) < self.config.batch_size:
            self.logger.warning(f"[çº¿ç¨‹å®‰å…¨åˆ¤åˆ«å™¨] æ•°æ®é›†ä¸è¶³ï¼Œéœ€è¦{self.config.batch_size}ä¸ªæ ·æœ¬ï¼Œ"
                               f"ä½†åªæœ‰{len(self.state_skill_dataset)}ä¸ªã€‚è·³è¿‡æ›´æ–°ã€‚")
            return 0.0
        
        # è°ƒç”¨åŸæœ‰çš„åˆ¤åˆ«å™¨æ›´æ–°é€»è¾‘ï¼ˆç°åœ¨ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„datasetï¼‰
        return self.update_discriminators()

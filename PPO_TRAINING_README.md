# PPOè®­ç»ƒè„šæœ¬ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨åŸºäºPPOï¼ˆProximal Policy Optimizationï¼‰çš„å¢å¼ºè®­ç»ƒè„šæœ¬è¿›è¡Œæ— äººæœºç½‘ç»œä¼˜åŒ–è®­ç»ƒã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š

```bash
pip install stable-baselines3[extra]
pip install torch
pip install numpy
pip install pandas
pip install matplotlib
pip install tensorboard
```

### 2. åŸºæœ¬è®­ç»ƒ

è¿è¡ŒåŸºæœ¬çš„PPOè®­ç»ƒï¼š

```bash
python train_ppo_enhanced_tracking.py --mode train --scenario 2
```

### 3. æµ‹è¯•è„šæœ¬

åœ¨å¼€å§‹æ­£å¼è®­ç»ƒå‰ï¼Œå»ºè®®è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯ç¯å¢ƒé…ç½®ï¼š

```bash
python test_ppo_training.py
```

## ğŸ“‹ å‘½ä»¤è¡Œå‚æ•°

### åŸºæœ¬å‚æ•°

- `--mode`: è¿è¡Œæ¨¡å¼ (`train` æˆ– `eval`)
- `--scenario`: åœºæ™¯é€‰æ‹© (1=åŸºç«™æ¨¡å¼, 2=åä½œç»„ç½‘æ¨¡å¼)
- `--model_path`: æ¨¡å‹ä¿å­˜/åŠ è½½è·¯å¾„ (é»˜è®¤: `models/ppo_enhanced_tracking.zip`)
- `--log_dir`: æ—¥å¿—ç›®å½• (é»˜è®¤: `logs`)
- `--device`: è®¡ç®—è®¾å¤‡ (`auto`, `cuda`, `cpu`)

### ç¯å¢ƒå‚æ•°

- `--n_uavs`: æ— äººæœºæ•°é‡ (é»˜è®¤: 5)
- `--n_users`: ç”¨æˆ·æ•°é‡ (é»˜è®¤: 50)
- `--max_hops`: æœ€å¤§è·³æ•°ï¼Œä»…åœºæ™¯2ä½¿ç”¨ (é»˜è®¤: 3)
- `--user_distribution`: ç”¨æˆ·åˆ†å¸ƒ (`uniform`, `cluster`, `hotspot`)
- `--channel_model`: ä¿¡é“æ¨¡å‹ (`free_space`, `urban`, `suburban`, `3gpp-36777`)

### PPOè¶…å‚æ•°

- `--learning_rate`: å­¦ä¹ ç‡ (é»˜è®¤: 3e-4)
- `--gamma`: æŠ˜æ‰£å› å­ (é»˜è®¤: 0.99)
- `--gae_lambda`: GAEå‚æ•° (é»˜è®¤: 0.95)
- `--clip_range`: PPOè£å‰ªå‚æ•° (é»˜è®¤: 0.2)
- `--ent_coef`: ç†µç³»æ•° (é»˜è®¤: 0.01)
- `--vf_coef`: å€¼å‡½æ•°æŸå¤±ç³»æ•° (é»˜è®¤: 0.5)
- `--max_grad_norm`: æœ€å¤§æ¢¯åº¦èŒƒæ•° (é»˜è®¤: 0.5)
- `--n_steps`: æ¯æ¬¡æ›´æ–°æ”¶é›†çš„æ­¥æ•° (é»˜è®¤: 2048)
- `--batch_size`: å°æ‰¹é‡å¤§å° (é»˜è®¤: 64)
- `--n_epochs`: æ¯æ¬¡æ›´æ–°çš„ä¼˜åŒ–è½®æ•° (é»˜è®¤: 10)

### å¹¶è¡ŒåŒ–å‚æ•°

- `--num_envs`: å¹¶è¡Œç¯å¢ƒæ•°é‡ (0=ä½¿ç”¨é…ç½®æ–‡ä»¶å€¼)
- `--eval_rollout_threads`: è¯„ä¼°å¹¶è¡Œçº¿ç¨‹æ•° (0=ä½¿ç”¨é…ç½®æ–‡ä»¶å€¼)

### æ•°æ®æ”¶é›†å‚æ•°

- `--export_interval`: æ•°æ®å¯¼å‡ºé—´éš”æ­¥æ•° (é»˜è®¤: 1000)
- `--detailed_logging`: å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŸºæœ¬è®­ç»ƒ

```bash
python train_ppo_enhanced_tracking.py \
  --mode train \
  --scenario 2 \
  --n_uavs 5 \
  --n_users 50 \
  --learning_rate 3e-4 \
  --num_envs 8
```

### ç¤ºä¾‹2ï¼šé«˜æ€§èƒ½è®­ç»ƒ

```bash
python train_ppo_enhanced_tracking.py \
  --mode train \
  --scenario 2 \
  --n_uavs 8 \
  --n_users 100 \
  --learning_rate 5e-4 \
  --num_envs 16 \
  --n_steps 4096 \
  --batch_size 128 \
  --device cuda
```

### ç¤ºä¾‹3ï¼šæ¨¡å‹è¯„ä¼°

```bash
python train_ppo_enhanced_tracking.py \
  --mode eval \
  --scenario 2 \
  --model_path models/ppo_enhanced_tracking.zip \
  --eval_episodes 50 \
  --render
```

### ç¤ºä¾‹4ï¼šè°ƒè¯•æ¨¡å¼

```bash
python train_ppo_enhanced_tracking.py \
  --mode train \
  --scenario 1 \
  --n_uavs 3 \
  --n_users 10 \
  --num_envs 2 \
  --export_interval 100 \
  --detailed_logging \
  --log_level debug
```

## ğŸ“Š è¾“å‡ºæ–‡ä»¶ç»“æ„

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
logs/ppo_enhanced_tracking_YYYYMMDD-HHMMSS/
â”œâ”€â”€ paper_data/                    # è®ºæ–‡æ•°æ®
â”‚   â”œâ”€â”€ episode_rewards_step_*.csv
â”‚   â”œâ”€â”€ ppo_training_progress_step_*.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ training_summary.json          # è®­ç»ƒæ‘˜è¦
â”œâ”€â”€ ppo_enhanced_tracking_*.log    # è®­ç»ƒæ—¥å¿—
â””â”€â”€ tensorboard logs/              # TensorBoardæ—¥å¿—

models/
â”œâ”€â”€ ppo_enhanced_tracking.zip      # æœ€ç»ˆæ¨¡å‹
â””â”€â”€ best_model.zip                 # æœ€ä½³æ¨¡å‹
```

## ğŸ”§ è‡ªå®šä¹‰ç½‘ç»œæ¶æ„

å¯ä»¥é€šè¿‡ä¿®æ”¹ `CustomActorCriticPolicy` ç±»æ¥è‡ªå®šä¹‰ç½‘ç»œæ¶æ„ï¼š

```python
class CustomActorCriticPolicy(ActorCriticPolicy):
    def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):
        # è‡ªå®šä¹‰ç½‘ç»œæ¶æ„
        kwargs['net_arch'] = dict(
            pi=[128, 128, 64],  # Actorç½‘ç»œå±‚
            vf=[128, 128, 64]   # Criticç½‘ç»œå±‚
        )
        kwargs['activation_fn'] = nn.ReLU
        
        super(CustomActorCriticPolicy, self).__init__(
            observation_space, action_space, lr_schedule, *args, **kwargs
        )
```

## ğŸ“ˆ ç›‘æ§è®­ç»ƒè¿‡ç¨‹

### TensorBoard

å¯åŠ¨TensorBoardç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼š

```bash
tensorboard --logdir=logs/ppo_enhanced_tracking_YYYYMMDD-HHMMSS
```

ä¸»è¦æŒ‡æ ‡ï¼š
- `rollout/ep_len_mean`: å¹³å‡episodeé•¿åº¦
- `rollout/ep_rew_mean`: å¹³å‡episodeå¥–åŠ±
- `train/policy_gradient_loss`: ç­–ç•¥æ¢¯åº¦æŸå¤±
- `train/value_loss`: å€¼å‡½æ•°æŸå¤±
- `train/entropy_loss`: ç†µæŸå¤±

### å®æ—¶æ—¥å¿—

è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…³é”®ä¿¡æ¯ä¼šå®æ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ—¥å¿—æ–‡ä»¶ï¼š

```
PPOæ¨¡å‹å·²åˆ›å»ºï¼Œè®¾å¤‡: cuda
å¼€å§‹è®­ç»ƒï¼Œæ€»æ—¶é—´æ­¥æ•°: 3000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1.24e+03  |
|    ep_rew_mean     | -156      |
| time/              |           |
|    fps             | 1893      |
|    iterations      | 1         |
|    time_elapsed    | 1         |
|    total_timesteps | 2048      |
| train/             |           |
|    approx_kl       | 0.016281  |
|    clip_fraction   | 0.281     |
|    clip_range      | 0.2       |
|    entropy_loss    | -1.41     |
|    explained_var   | -0.0402   |
|    learning_rate   | 0.0003    |
|    loss            | 3.58      |
|    policy_gradient_loss| -0.0185|
|    value_loss      | 7.39      |
----------------------------------
```

## ğŸ¯ ä¸HMASDè®­ç»ƒçš„æ¯”è¾ƒ

| ç‰¹æ€§ | HMASDè®­ç»ƒ | PPOè®­ç»ƒ |
|------|-----------|---------|
| ç®—æ³•ç±»å‹ | åˆ†å±‚å¤šæ™ºèƒ½ä½“æŠ€èƒ½å‘ç° | è¿‘ç«¯ç­–ç•¥ä¼˜åŒ– |
| æŠ€èƒ½å‘ç° | âœ… æ”¯æŒ | âŒ ä¸æ”¯æŒ |
| å®ç°å¤æ‚åº¦ | é«˜ | ä¸­ç­‰ |
| è®­ç»ƒç¨³å®šæ€§ | ä¸­ç­‰ | é«˜ |
| è¶…å‚æ•°è°ƒèŠ‚ | å¤æ‚ | ç›¸å¯¹ç®€å• |
| å¤šæ™ºèƒ½ä½“åè°ƒ | æ˜¾å¼å±‚æ¬¡ç»“æ„ | éšå¼å­¦ä¹  |
| æ”¶æ•›é€Ÿåº¦ | è¾ƒæ…¢ | è¾ƒå¿« |

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```
   RuntimeError: CUDA out of memory
   ```
   è§£å†³æ–¹æ¡ˆï¼š
   - å‡å°‘ `--num_envs` æˆ– `--batch_size`
   - ä½¿ç”¨ `--device cpu`

2. **ç¯å¢ƒåˆ›å»ºå¤±è´¥**
   ```
   ValueError: æœªçŸ¥çš„åœºæ™¯: X
   ```
   è§£å†³æ–¹æ¡ˆï¼š
   - ç¡®ä¿ `--scenario` å‚æ•°ä¸º1æˆ–2
   - æ£€æŸ¥ç¯å¢ƒæ¨¡å—å¯¼å…¥

3. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```
   FileNotFoundError: No such file or directory
   ```
   è§£å†³æ–¹æ¡ˆï¼š
   - æ£€æŸ¥ `--model_path` è·¯å¾„æ˜¯å¦æ­£ç¡®
   - ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å¹¶è¡Œç¯å¢ƒæ•°é‡**ï¼šé€šå¸¸è®¾ç½®ä¸ºCPUæ ¸å¿ƒæ•°çš„1-2å€
2. **æ‰¹æ¬¡å¤§å°**ï¼šæ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼Œé€šå¸¸32-512ä¹‹é—´
3. **å­¦ä¹ ç‡**ï¼šä»3e-4å¼€å§‹ï¼Œæ ¹æ®æ”¶æ•›æƒ…å†µè°ƒæ•´
4. **é‡‡æ ·æ­¥æ•°**ï¼šå¢å¤§`n_steps`å¯ä»¥æé«˜æ ·æœ¬æ•ˆç‡ä½†éœ€è¦æ›´å¤šå†…å­˜

## ğŸ“ å¼€å‘æ³¨æ„äº‹é¡¹

### æ‰©å±•è®­ç»ƒè„šæœ¬

å¦‚éœ€æ·»åŠ æ–°çš„åŠŸèƒ½ï¼š

1. **è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°**ï¼šä¿®æ”¹ç¯å¢ƒçš„å¥–åŠ±è®¡ç®—é€»è¾‘
2. **æ–°çš„å›è°ƒå‡½æ•°**ï¼šç»§æ‰¿`BaseCallback`å®ç°è‡ªå®šä¹‰å›è°ƒ
3. **ä¸åŒçš„ç­–ç•¥ç½‘ç»œ**ï¼šä¿®æ”¹`CustomActorCriticPolicy`ç±»
4. **æ–°çš„è¯„ä¼°æŒ‡æ ‡**ï¼šæ‰©å±•`EnhancedRewardTracker`ç±»

### è°ƒè¯•æŠ€å·§

1. ä½¿ç”¨å°çš„å‚æ•°å€¼è¿›è¡Œå¿«é€Ÿæµ‹è¯•
2. å¯ç”¨`--detailed_logging`è·å–æ›´å¤šä¿¡æ¯
3. è¿è¡Œ`test_ppo_training.py`éªŒè¯ç¯å¢ƒé…ç½®
4. ä½¿ç”¨TensorBoardç›‘æ§è®­ç»ƒæŒ‡æ ‡

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªä¸ä¸»é¡¹ç›®ç›¸åŒçš„è®¸å¯è¯ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤é—®é¢˜æŠ¥å‘Šå’Œæ”¹è¿›å»ºè®®ï¼

#!/usr/bin/env python3
"""
å¿«é€ŸéªŒè¯å¤šç¯å¢ƒæ”¯æŒçš„ç®€å•æµ‹è¯•è„šæœ¬
"""

import os
import sys
import numpy as np
import torch
import tempfile
import shutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config_1 import Config
from hmasd.agent import HMASDAgent

def quick_test():
    """å¿«é€Ÿæµ‹è¯•å¤šç¯å¢ƒæ”¯æŒ"""
    print("ğŸš€ å¼€å§‹å¿«é€ŸéªŒè¯HMASDå¤šç¯å¢ƒæ”¯æŒ...")
    
    # åˆ›å»ºé…ç½®
    config = Config()
    config.state_dim = 8
    config.obs_dim = 6
    config.n_agents = 3
    config.action_dim = 4
    config.k = 4
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    
    try:
        # åˆ›å»ºä»£ç†
        agent = HMASDAgent(config, log_dir=temp_dir, device=torch.device('cpu'))
        
        # æµ‹è¯•æ•°æ®
        state = np.random.randn(config.state_dim)
        observations = np.random.randn(config.n_agents, config.obs_dim)
        
        print("âœ… ä»£ç†åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•1: ç¯å¢ƒçŠ¶æ€åˆå§‹åŒ–
        print("\nğŸ“‹ æµ‹è¯•1: ç¯å¢ƒçŠ¶æ€åˆå§‹åŒ–")
        assert hasattr(agent, 'env_team_skills'), "ç¼ºå°‘env_team_skillså±æ€§"
        assert hasattr(agent, 'env_agent_skills'), "ç¼ºå°‘env_agent_skillså±æ€§"
        assert hasattr(agent, 'env_timers'), "ç¼ºå°‘env_timerså±æ€§"
        print("âœ… ç¯å¢ƒçŠ¶æ€å­—å…¸å·²æ­£ç¡®åˆå§‹åŒ–")
        
        # æµ‹è¯•2: å¤šç¯å¢ƒstepè°ƒç”¨
        print("\nğŸ“‹ æµ‹è¯•2: å¤šç¯å¢ƒstepè°ƒç”¨")
        num_test_envs = 4
        env_results = {}
        
        for env_id in range(num_test_envs):
            actions, info = agent.step(state, observations, 0, deterministic=False, env_id=env_id)
            env_results[env_id] = {
                'actions': actions,
                'team_skill': info['team_skill'],
                'agent_skills': info['agent_skills'],
                'env_id': info['env_id']
            }
            
            # éªŒè¯è¿”å›å€¼
            assert actions.shape == (config.n_agents, config.action_dim), f"åŠ¨ä½œå½¢çŠ¶é”™è¯¯: {actions.shape}"
            assert info['env_id'] == env_id, f"ç¯å¢ƒIDä¸åŒ¹é…: {info['env_id']} != {env_id}"
            
        print(f"âœ… æˆåŠŸæµ‹è¯•{num_test_envs}ä¸ªç¯å¢ƒçš„stepè°ƒç”¨")
        
        # æ˜¾ç¤ºæ¯ä¸ªç¯å¢ƒçš„æŠ€èƒ½åˆ†é…
        for env_id, result in env_results.items():
            print(f"  ç¯å¢ƒ{env_id}: å›¢é˜ŸæŠ€èƒ½={result['team_skill']}, ä¸ªä½“æŠ€èƒ½={result['agent_skills']}")
        
        # æµ‹è¯•3: æŠ€èƒ½è®¡æ—¶å™¨
        print("\nğŸ“‹ æµ‹è¯•3: æŠ€èƒ½è®¡æ—¶å™¨ç®¡ç†")
        env_id = 0
        
        for step in range(config.k + 1):
            actions, info = agent.step(state, observations, step, deterministic=False, env_id=env_id)
            skill_changed = info['skill_changed']
            skill_timer = info['skill_timer']
            
            if step == 0:
                assert skill_changed, f"ç¬¬ä¸€æ­¥åº”è¯¥åˆ†é…æŠ€èƒ½"
            
            print(f"  æ­¥éª¤{step}: æŠ€èƒ½å˜åŒ–={skill_changed}, è®¡æ—¶å™¨={skill_timer}")
        
        print("âœ… æŠ€èƒ½è®¡æ—¶å™¨ç®¡ç†æ­£ç¡®")
        
        # æµ‹è¯•4: ç»éªŒå­˜å‚¨
        print("\nğŸ“‹ æµ‹è¯•4: ç»éªŒå­˜å‚¨")
        
        # å‡†å¤‡å­˜å‚¨æ•°æ®
        next_state = np.random.randn(config.state_dim)
        next_observations = np.random.randn(config.n_agents, config.obs_dim)
        actions = np.random.randn(config.n_agents, config.action_dim)
        rewards = 1.0
        dones = False
        
        initial_buffer_size = len(agent.low_level_buffer)
        
        # ä¸ºå¤šä¸ªç¯å¢ƒå­˜å‚¨ç»éªŒ
        for env_id in range(num_test_envs):
            # è·å–æŠ€èƒ½ä¿¡æ¯
            _, info = agent.step(state, observations, 0, deterministic=False, env_id=env_id)
            
            # å­˜å‚¨è½¬æ¢
            agent.store_transition(
                state, next_state, observations, next_observations,
                actions, rewards, dones,
                info['team_skill'], info['agent_skills'], info['action_logprobs'],
                log_probs=info['log_probs'], skill_timer_for_env=0, env_id=env_id
            )
        
        final_buffer_size = len(agent.low_level_buffer)
        expected_increase = num_test_envs * config.n_agents
        actual_increase = final_buffer_size - initial_buffer_size
        
        assert actual_increase == expected_increase, f"ç»éªŒå­˜å‚¨æ•°é‡é”™è¯¯: æœŸæœ›{expected_increase}, å®é™…{actual_increase}"
        print(f"âœ… ç»éªŒå­˜å‚¨æ­£ç¡®ï¼Œå¢åŠ äº†{actual_increase}ä¸ªä½å±‚ç»éªŒ")
        
        # æµ‹è¯•5: å‘åå…¼å®¹æ€§
        print("\nğŸ“‹ æµ‹è¯•5: å‘åå…¼å®¹æ€§")
        
        # ä¸ä¼ é€’env_idå‚æ•°
        actions1, info1 = agent.step(state, observations, 0, deterministic=False)
        # ä¼ é€’env_id=0
        actions2, info2 = agent.step(state, observations, 1, deterministic=False, env_id=0)
        
        assert actions1.shape == actions2.shape, "å‘åå…¼å®¹æ€§æµ‹è¯•å¤±è´¥"
        assert 'team_skill' in info1 and 'team_skill' in info2, "ä¿¡æ¯ç»“æ„ä¸ä¸€è‡´"
        
        print("âœ… å‘åå…¼å®¹æ€§æ­£ç¡®")
        
        print("\nğŸ‰ æ‰€æœ‰å¿«é€Ÿæµ‹è¯•é€šè¿‡ï¼å¤šç¯å¢ƒæ”¯æŒå®ç°æ­£ç¡®ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # æ¸…ç†
        if hasattr(agent, 'writer'):
            agent.writer.close()
        shutil.rmtree(temp_dir, ignore_errors=True)

def main():
    """ä¸»å‡½æ•°"""
    print("HMASDå¤šç¯å¢ƒæ”¯æŒå¿«é€ŸéªŒè¯")
    print("=" * 40)
    
    success = quick_test()
    
    if success:
        print("\nâœ… éªŒè¯ç»“è®º: å¤šç¯å¢ƒæ”¯æŒå®ç°æ­£ç¡®ï¼")
        print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print("  # åœ¨è®­ç»ƒå¾ªç¯ä¸­ä¸ºæ¯ä¸ªç¯å¢ƒè°ƒç”¨:")
        print("  actions, info = agent.step(state, obs, step, env_id=env_id)")
        print("  agent.store_transition(..., env_id=env_id)")
        print("\nğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹å¤šç¯å¢ƒå¹¶è¡Œè®­ç»ƒäº†ï¼")
        return 0
    else:
        print("\nâŒ éªŒè¯å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°ï¼")
        return 1

if __name__ == "__main__":
    sys.exit(main())
